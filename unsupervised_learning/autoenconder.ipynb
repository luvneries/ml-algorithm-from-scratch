{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make this notebook compatible for Python 2 and 3\n",
    "from __future__ import division, print_function\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import progressbar\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to import module from parent directory\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Dataset API from sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learning.optimizers import Adam\n",
    "from deep_learning.loss_functions import CrossEntropy, SquareLoss\n",
    "from deep_learning.layers import Dense, Dropout, Flatten, Activation, Reshape, BatchNormalization \n",
    "from deep_learning.neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------+\n",
      "| Variational Autoencoder |\n",
      "+-------------------------+\n",
      "Input Shape: (784,)\n",
      "+------------------------+------------+--------------+\n",
      "| Layer Type             | Parameters | Output Shape |\n",
      "+------------------------+------------+--------------+\n",
      "| Dense                  | 401920     | (512,)       |\n",
      "| Activation (LeakyReLU) | 0          | (512,)       |\n",
      "| BatchNormalization     | 1024       | (512,)       |\n",
      "| Dense                  | 131328     | (256,)       |\n",
      "| Activation (LeakyReLU) | 0          | (256,)       |\n",
      "| BatchNormalization     | 512        | (256,)       |\n",
      "| Dense                  | 32896      | (128,)       |\n",
      "| Dense                  | 33024      | (256,)       |\n",
      "| Activation (LeakyReLU) | 0          | (256,)       |\n",
      "| BatchNormalization     | 512        | (256,)       |\n",
      "| Dense                  | 131584     | (512,)       |\n",
      "| Activation (LeakyReLU) | 0          | (512,)       |\n",
      "| BatchNormalization     | 1024       | (512,)       |\n",
      "| Dense                  | 402192     | (784,)       |\n",
      "| Activation (TanH)      | 0          | (784,)       |\n",
      "+------------------------+------------+--------------+\n",
      "Total Parameters: 1136016\n",
      "\n",
      "0 [D loss: 0.562230]\n",
      "1 [D loss: 0.553967]\n",
      "2 [D loss: 0.545364]\n",
      "3 [D loss: 0.537212]\n",
      "4 [D loss: 0.529560]\n",
      "5 [D loss: 0.521411]\n",
      "6 [D loss: 0.515279]\n",
      "7 [D loss: 0.509218]\n",
      "8 [D loss: 0.503353]\n",
      "9 [D loss: 0.493033]\n",
      "10 [D loss: 0.496837]\n",
      "11 [D loss: 0.489696]\n",
      "12 [D loss: 0.482826]\n",
      "13 [D loss: 0.474383]\n",
      "14 [D loss: 0.479328]\n",
      "15 [D loss: 0.470744]\n",
      "16 [D loss: 0.469344]\n",
      "17 [D loss: 0.469268]\n",
      "18 [D loss: 0.464187]\n",
      "19 [D loss: 0.456459]\n",
      "20 [D loss: 0.455769]\n",
      "21 [D loss: 0.458676]\n",
      "22 [D loss: 0.458963]\n",
      "23 [D loss: 0.452444]\n",
      "24 [D loss: 0.455671]\n",
      "25 [D loss: 0.449387]\n",
      "26 [D loss: 0.441510]\n",
      "27 [D loss: 0.441853]\n",
      "28 [D loss: 0.449701]\n",
      "29 [D loss: 0.441719]\n",
      "30 [D loss: 0.447992]\n",
      "31 [D loss: 0.454855]\n",
      "32 [D loss: 0.438114]\n",
      "33 [D loss: 0.430646]\n",
      "34 [D loss: 0.438529]\n",
      "35 [D loss: 0.436365]\n",
      "36 [D loss: 0.431767]\n",
      "37 [D loss: 0.432432]\n",
      "38 [D loss: 0.425937]\n",
      "39 [D loss: 0.423368]\n",
      "40 [D loss: 0.425900]\n",
      "41 [D loss: 0.420741]\n",
      "42 [D loss: 0.430781]\n",
      "43 [D loss: 0.435355]\n",
      "44 [D loss: 0.432739]\n",
      "45 [D loss: 0.418410]\n",
      "46 [D loss: 0.422911]\n",
      "47 [D loss: 0.423208]\n",
      "48 [D loss: 0.420242]\n",
      "49 [D loss: 0.421002]\n",
      "50 [D loss: 0.418339]\n",
      "51 [D loss: 0.416392]\n",
      "52 [D loss: 0.410856]\n",
      "53 [D loss: 0.419553]\n",
      "54 [D loss: 0.417417]\n",
      "55 [D loss: 0.412535]\n",
      "56 [D loss: 0.412952]\n",
      "57 [D loss: 0.413215]\n",
      "58 [D loss: 0.408415]\n",
      "59 [D loss: 0.416310]\n",
      "60 [D loss: 0.414038]\n",
      "61 [D loss: 0.415505]\n",
      "62 [D loss: 0.415283]\n",
      "63 [D loss: 0.402539]\n",
      "64 [D loss: 0.406906]\n",
      "65 [D loss: 0.401272]\n",
      "66 [D loss: 0.415822]\n",
      "67 [D loss: 0.403032]\n",
      "68 [D loss: 0.398924]\n",
      "69 [D loss: 0.404292]\n",
      "70 [D loss: 0.405586]\n",
      "71 [D loss: 0.403338]\n",
      "72 [D loss: 0.400115]\n",
      "73 [D loss: 0.394706]\n",
      "74 [D loss: 0.401319]\n",
      "75 [D loss: 0.407858]\n",
      "76 [D loss: 0.395853]\n",
      "77 [D loss: 0.413286]\n",
      "78 [D loss: 0.402700]\n",
      "79 [D loss: 0.395453]\n",
      "80 [D loss: 0.393646]\n",
      "81 [D loss: 0.392139]\n",
      "82 [D loss: 0.408048]\n",
      "83 [D loss: 0.400006]\n",
      "84 [D loss: 0.398547]\n",
      "85 [D loss: 0.415301]\n",
      "86 [D loss: 0.396438]\n",
      "87 [D loss: 0.399755]\n",
      "88 [D loss: 0.398055]\n",
      "89 [D loss: 0.395158]\n",
      "90 [D loss: 0.398954]\n",
      "91 [D loss: 0.388857]\n",
      "92 [D loss: 0.394654]\n",
      "93 [D loss: 0.397323]\n",
      "94 [D loss: 0.414021]\n",
      "95 [D loss: 0.396097]\n",
      "96 [D loss: 0.385794]\n",
      "97 [D loss: 0.388798]\n",
      "98 [D loss: 0.399403]\n",
      "99 [D loss: 0.390928]\n",
      "100 [D loss: 0.388620]\n",
      "101 [D loss: 0.384501]\n",
      "102 [D loss: 0.382879]\n",
      "103 [D loss: 0.382029]\n",
      "104 [D loss: 0.381972]\n",
      "105 [D loss: 0.382572]\n",
      "106 [D loss: 0.376823]\n",
      "107 [D loss: 0.381409]\n",
      "108 [D loss: 0.370846]\n",
      "109 [D loss: 0.380729]\n",
      "110 [D loss: 0.380973]\n",
      "111 [D loss: 0.377179]\n",
      "112 [D loss: 0.376160]\n",
      "113 [D loss: 0.385786]\n",
      "114 [D loss: 0.377086]\n",
      "115 [D loss: 0.377285]\n",
      "116 [D loss: 0.378330]\n",
      "117 [D loss: 0.387051]\n",
      "118 [D loss: 0.371915]\n",
      "119 [D loss: 0.379422]\n",
      "120 [D loss: 0.372522]\n",
      "121 [D loss: 0.371335]\n",
      "122 [D loss: 0.374175]\n",
      "123 [D loss: 0.373139]\n",
      "124 [D loss: 0.374192]\n",
      "125 [D loss: 0.365552]\n",
      "126 [D loss: 0.373017]\n",
      "127 [D loss: 0.367384]\n",
      "128 [D loss: 0.373246]\n",
      "129 [D loss: 0.364657]\n",
      "130 [D loss: 0.367779]\n",
      "131 [D loss: 0.365513]\n",
      "132 [D loss: 0.371138]\n",
      "133 [D loss: 0.376942]\n",
      "134 [D loss: 0.371565]\n",
      "135 [D loss: 0.372263]\n",
      "136 [D loss: 0.372761]\n",
      "137 [D loss: 0.376904]\n",
      "138 [D loss: 0.374827]\n",
      "139 [D loss: 0.370882]\n",
      "140 [D loss: 0.371670]\n",
      "141 [D loss: 0.367614]\n",
      "142 [D loss: 0.360436]\n",
      "143 [D loss: 0.359767]\n",
      "144 [D loss: 0.367061]\n",
      "145 [D loss: 0.371356]\n",
      "146 [D loss: 0.358220]\n",
      "147 [D loss: 0.365250]\n",
      "148 [D loss: 0.361290]\n",
      "149 [D loss: 0.359468]\n",
      "150 [D loss: 0.353105]\n",
      "151 [D loss: 0.363183]\n",
      "152 [D loss: 0.360483]\n",
      "153 [D loss: 0.367455]\n",
      "154 [D loss: 0.357037]\n",
      "155 [D loss: 0.362254]\n",
      "156 [D loss: 0.350756]\n",
      "157 [D loss: 0.352329]\n",
      "158 [D loss: 0.366236]\n",
      "159 [D loss: 0.359317]\n",
      "160 [D loss: 0.353485]\n",
      "161 [D loss: 0.359435]\n",
      "162 [D loss: 0.360954]\n",
      "163 [D loss: 0.358347]\n",
      "164 [D loss: 0.371556]\n",
      "165 [D loss: 0.350897]\n",
      "166 [D loss: 0.363227]\n",
      "167 [D loss: 0.367759]\n",
      "168 [D loss: 0.355781]\n",
      "169 [D loss: 0.355397]\n",
      "170 [D loss: 0.355806]\n",
      "171 [D loss: 0.364520]\n",
      "172 [D loss: 0.359764]\n",
      "173 [D loss: 0.371410]\n",
      "174 [D loss: 0.357812]\n",
      "175 [D loss: 0.361635]\n",
      "176 [D loss: 0.346591]\n",
      "177 [D loss: 0.347112]\n",
      "178 [D loss: 0.347512]\n",
      "179 [D loss: 0.358855]\n",
      "180 [D loss: 0.354566]\n",
      "181 [D loss: 0.367693]\n",
      "182 [D loss: 0.345134]\n",
      "183 [D loss: 0.353517]\n",
      "184 [D loss: 0.346558]\n",
      "185 [D loss: 0.347383]\n",
      "186 [D loss: 0.388042]\n",
      "187 [D loss: 0.344624]\n",
      "188 [D loss: 0.351119]\n",
      "189 [D loss: 0.350944]\n",
      "190 [D loss: 0.353820]\n",
      "191 [D loss: 0.356637]\n",
      "192 [D loss: 0.365351]\n",
      "193 [D loss: 0.351914]\n",
      "194 [D loss: 0.349629]\n",
      "195 [D loss: 0.338129]\n",
      "196 [D loss: 0.352266]\n",
      "197 [D loss: 0.359668]\n",
      "198 [D loss: 0.349466]\n",
      "199 [D loss: 0.344975]\n",
      "200 [D loss: 0.370179]\n",
      "201 [D loss: 0.359428]\n",
      "202 [D loss: 0.349697]\n",
      "203 [D loss: 0.348725]\n",
      "204 [D loss: 0.336530]\n",
      "205 [D loss: 0.352760]\n",
      "206 [D loss: 0.348962]\n",
      "207 [D loss: 0.356486]\n",
      "208 [D loss: 0.335537]\n",
      "209 [D loss: 0.342732]\n",
      "210 [D loss: 0.337006]\n",
      "211 [D loss: 0.342547]\n",
      "212 [D loss: 0.341216]\n",
      "213 [D loss: 0.335157]\n",
      "214 [D loss: 0.336817]\n",
      "215 [D loss: 0.351614]\n",
      "216 [D loss: 0.345918]\n",
      "217 [D loss: 0.341745]\n",
      "218 [D loss: 0.337482]\n",
      "219 [D loss: 0.336457]\n",
      "220 [D loss: 0.346330]\n",
      "221 [D loss: 0.342438]\n",
      "222 [D loss: 0.333919]\n",
      "223 [D loss: 0.329682]\n",
      "224 [D loss: 0.341744]\n",
      "225 [D loss: 0.333857]\n",
      "226 [D loss: 0.336769]\n",
      "227 [D loss: 0.330131]\n",
      "228 [D loss: 0.340024]\n",
      "229 [D loss: 0.333031]\n",
      "230 [D loss: 0.332108]\n",
      "231 [D loss: 0.341124]\n",
      "232 [D loss: 0.358756]\n",
      "233 [D loss: 0.331437]\n",
      "234 [D loss: 0.334142]\n",
      "235 [D loss: 0.341275]\n",
      "236 [D loss: 0.341751]\n",
      "237 [D loss: 0.323389]\n",
      "238 [D loss: 0.331890]\n",
      "239 [D loss: 0.347008]\n",
      "240 [D loss: 0.344980]\n",
      "241 [D loss: 0.340329]\n",
      "242 [D loss: 0.336414]\n",
      "243 [D loss: 0.322315]\n",
      "244 [D loss: 0.338344]\n",
      "245 [D loss: 0.329459]\n",
      "246 [D loss: 0.331564]\n",
      "247 [D loss: 0.323124]\n",
      "248 [D loss: 0.334108]\n",
      "249 [D loss: 0.325135]\n",
      "250 [D loss: 0.325201]\n",
      "251 [D loss: 0.331951]\n",
      "252 [D loss: 0.341776]\n",
      "253 [D loss: 0.319334]\n",
      "254 [D loss: 0.331613]\n",
      "255 [D loss: 0.338145]\n",
      "256 [D loss: 0.327049]\n",
      "257 [D loss: 0.331050]\n",
      "258 [D loss: 0.336233]\n",
      "259 [D loss: 0.340087]\n",
      "260 [D loss: 0.328720]\n",
      "261 [D loss: 0.326249]\n",
      "262 [D loss: 0.324143]\n",
      "263 [D loss: 0.324151]\n",
      "264 [D loss: 0.330218]\n",
      "265 [D loss: 0.334083]\n",
      "266 [D loss: 0.332645]\n",
      "267 [D loss: 0.340081]\n",
      "268 [D loss: 0.319663]\n",
      "269 [D loss: 0.318110]\n",
      "270 [D loss: 0.327033]\n",
      "271 [D loss: 0.342727]\n",
      "272 [D loss: 0.340406]\n",
      "273 [D loss: 0.324580]\n",
      "274 [D loss: 0.326084]\n",
      "275 [D loss: 0.328773]\n",
      "276 [D loss: 0.327161]\n",
      "277 [D loss: 0.332554]\n",
      "278 [D loss: 0.331183]\n",
      "279 [D loss: 0.326499]\n",
      "280 [D loss: 0.326162]\n",
      "281 [D loss: 0.324981]\n",
      "282 [D loss: 0.323971]\n",
      "283 [D loss: 0.329935]\n",
      "284 [D loss: 0.327199]\n",
      "285 [D loss: 0.336532]\n",
      "286 [D loss: 0.328959]\n",
      "287 [D loss: 0.312926]\n",
      "288 [D loss: 0.324897]\n",
      "289 [D loss: 0.327447]\n",
      "290 [D loss: 0.314696]\n",
      "291 [D loss: 0.321304]\n",
      "292 [D loss: 0.323912]\n",
      "293 [D loss: 0.329150]\n",
      "294 [D loss: 0.323397]\n",
      "295 [D loss: 0.321996]\n",
      "296 [D loss: 0.322014]\n",
      "297 [D loss: 0.371599]\n",
      "298 [D loss: 0.324347]\n",
      "299 [D loss: 0.325490]\n",
      "300 [D loss: 0.328855]\n",
      "301 [D loss: 0.321105]\n",
      "302 [D loss: 0.328456]\n",
      "303 [D loss: 0.326085]\n",
      "304 [D loss: 0.329357]\n",
      "305 [D loss: 0.324305]\n",
      "306 [D loss: 0.320789]\n",
      "307 [D loss: 0.314927]\n",
      "308 [D loss: 0.330365]\n",
      "309 [D loss: 0.324980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 [D loss: 0.330981]\n",
      "311 [D loss: 0.314899]\n",
      "312 [D loss: 0.330760]\n",
      "313 [D loss: 0.324923]\n",
      "314 [D loss: 0.332062]\n",
      "315 [D loss: 0.314893]\n",
      "316 [D loss: 0.321148]\n",
      "317 [D loss: 0.318560]\n",
      "318 [D loss: 0.322350]\n",
      "319 [D loss: 0.314662]\n",
      "320 [D loss: 0.308637]\n",
      "321 [D loss: 0.323957]\n",
      "322 [D loss: 0.317947]\n",
      "323 [D loss: 0.317813]\n",
      "324 [D loss: 0.309265]\n",
      "325 [D loss: 0.320596]\n",
      "326 [D loss: 0.319668]\n",
      "327 [D loss: 0.310394]\n",
      "328 [D loss: 0.317836]\n",
      "329 [D loss: 0.314485]\n",
      "330 [D loss: 0.312452]\n",
      "331 [D loss: 0.313244]\n",
      "332 [D loss: 0.326952]\n",
      "333 [D loss: 0.308411]\n",
      "334 [D loss: 0.312797]\n",
      "335 [D loss: 0.310896]\n",
      "336 [D loss: 0.316527]\n",
      "337 [D loss: 0.315982]\n",
      "338 [D loss: 0.318197]\n",
      "339 [D loss: 0.317702]\n",
      "340 [D loss: 0.304638]\n",
      "341 [D loss: 0.313145]\n",
      "342 [D loss: 0.319059]\n",
      "343 [D loss: 0.315048]\n",
      "344 [D loss: 0.307954]\n",
      "345 [D loss: 0.305742]\n",
      "346 [D loss: 0.319870]\n",
      "347 [D loss: 0.322255]\n",
      "348 [D loss: 0.310462]\n",
      "349 [D loss: 0.320925]\n",
      "350 [D loss: 0.307745]\n",
      "351 [D loss: 0.307101]\n",
      "352 [D loss: 0.325724]\n",
      "353 [D loss: 0.317045]\n",
      "354 [D loss: 0.321993]\n",
      "355 [D loss: 0.310850]\n",
      "356 [D loss: 0.317621]\n",
      "357 [D loss: 0.302967]\n",
      "358 [D loss: 0.310698]\n",
      "359 [D loss: 0.311982]\n",
      "360 [D loss: 0.319692]\n",
      "361 [D loss: 0.322116]\n",
      "362 [D loss: 0.327367]\n",
      "363 [D loss: 0.316305]\n",
      "364 [D loss: 0.311637]\n",
      "365 [D loss: 0.322911]\n",
      "366 [D loss: 0.305798]\n",
      "367 [D loss: 0.313194]\n",
      "368 [D loss: 0.308090]\n",
      "369 [D loss: 0.328257]\n",
      "370 [D loss: 0.301957]\n",
      "371 [D loss: 0.334455]\n",
      "372 [D loss: 0.317016]\n",
      "373 [D loss: 0.311113]\n",
      "374 [D loss: 0.321663]\n",
      "375 [D loss: 0.343585]\n",
      "376 [D loss: 0.303557]\n",
      "377 [D loss: 0.310218]\n",
      "378 [D loss: 0.310678]\n",
      "379 [D loss: 0.320331]\n",
      "380 [D loss: 0.319940]\n",
      "381 [D loss: 0.310742]\n",
      "382 [D loss: 0.301750]\n",
      "383 [D loss: 0.310539]\n",
      "384 [D loss: 0.295417]\n",
      "385 [D loss: 0.324169]\n",
      "386 [D loss: 0.315022]\n",
      "387 [D loss: 0.310636]\n",
      "388 [D loss: 0.310647]\n",
      "389 [D loss: 0.309126]\n",
      "390 [D loss: 0.302091]\n",
      "391 [D loss: 0.307940]\n",
      "392 [D loss: 0.304068]\n",
      "393 [D loss: 0.306330]\n",
      "394 [D loss: 0.305028]\n",
      "395 [D loss: 0.307292]\n",
      "396 [D loss: 0.313793]\n",
      "397 [D loss: 0.309069]\n",
      "398 [D loss: 0.307868]\n",
      "399 [D loss: 0.305928]\n",
      "400 [D loss: 0.308499]\n",
      "401 [D loss: 0.298262]\n",
      "402 [D loss: 0.306993]\n",
      "403 [D loss: 0.305869]\n",
      "404 [D loss: 0.300055]\n",
      "405 [D loss: 0.312012]\n",
      "406 [D loss: 0.302587]\n",
      "407 [D loss: 0.301419]\n",
      "408 [D loss: 0.297939]\n",
      "409 [D loss: 0.300928]\n",
      "410 [D loss: 0.307717]\n",
      "411 [D loss: 0.317050]\n",
      "412 [D loss: 0.300226]\n",
      "413 [D loss: 0.315152]\n",
      "414 [D loss: 0.314641]\n",
      "415 [D loss: 0.314942]\n",
      "416 [D loss: 0.292777]\n",
      "417 [D loss: 0.300439]\n",
      "418 [D loss: 0.291907]\n",
      "419 [D loss: 0.305404]\n",
      "420 [D loss: 0.311459]\n",
      "421 [D loss: 0.305335]\n",
      "422 [D loss: 0.379059]\n",
      "423 [D loss: 0.297839]\n",
      "424 [D loss: 0.298063]\n",
      "425 [D loss: 0.309926]\n",
      "426 [D loss: 0.302499]\n",
      "427 [D loss: 0.298808]\n",
      "428 [D loss: 0.298303]\n",
      "429 [D loss: 0.301571]\n",
      "430 [D loss: 0.294277]\n",
      "431 [D loss: 0.301037]\n",
      "432 [D loss: 0.309794]\n",
      "433 [D loss: 0.295569]\n",
      "434 [D loss: 0.297780]\n",
      "435 [D loss: 0.302363]\n",
      "436 [D loss: 0.301371]\n",
      "437 [D loss: 0.293017]\n",
      "438 [D loss: 0.318193]\n",
      "439 [D loss: 0.317012]\n",
      "440 [D loss: 0.293609]\n",
      "441 [D loss: 0.307206]\n",
      "442 [D loss: 0.315974]\n",
      "443 [D loss: 0.310043]\n",
      "444 [D loss: 0.307499]\n",
      "445 [D loss: 0.299450]\n",
      "446 [D loss: 0.313752]\n",
      "447 [D loss: 0.299494]\n",
      "448 [D loss: 0.294119]\n",
      "449 [D loss: 0.299649]\n",
      "450 [D loss: 0.297209]\n",
      "451 [D loss: 0.296252]\n",
      "452 [D loss: 0.304249]\n",
      "453 [D loss: 0.301908]\n",
      "454 [D loss: 0.292021]\n",
      "455 [D loss: 0.303991]\n",
      "456 [D loss: 0.291348]\n",
      "457 [D loss: 0.288253]\n",
      "458 [D loss: 0.292242]\n",
      "459 [D loss: 0.346472]\n",
      "460 [D loss: 0.287702]\n",
      "461 [D loss: 0.303502]\n",
      "462 [D loss: 0.294151]\n",
      "463 [D loss: 0.293637]\n",
      "464 [D loss: 0.294916]\n",
      "465 [D loss: 0.290724]\n",
      "466 [D loss: 0.290085]\n",
      "467 [D loss: 0.315219]\n",
      "468 [D loss: 0.288553]\n",
      "469 [D loss: 0.302602]\n",
      "470 [D loss: 0.290792]\n",
      "471 [D loss: 0.294812]\n",
      "472 [D loss: 0.298044]\n",
      "473 [D loss: 0.305657]\n",
      "474 [D loss: 0.298956]\n",
      "475 [D loss: 0.286874]\n",
      "476 [D loss: 0.294592]\n",
      "477 [D loss: 0.297284]\n",
      "478 [D loss: 0.292611]\n",
      "479 [D loss: 0.286017]\n",
      "480 [D loss: 0.290372]\n",
      "481 [D loss: 0.293153]\n",
      "482 [D loss: 0.305805]\n",
      "483 [D loss: 0.308578]\n",
      "484 [D loss: 0.295557]\n",
      "485 [D loss: 0.288620]\n",
      "486 [D loss: 0.296359]\n",
      "487 [D loss: 0.289022]\n",
      "488 [D loss: 0.291096]\n",
      "489 [D loss: 0.287920]\n",
      "490 [D loss: 0.305375]\n",
      "491 [D loss: 0.292404]\n",
      "492 [D loss: 0.286807]\n",
      "493 [D loss: 0.298825]\n",
      "494 [D loss: 0.289873]\n",
      "495 [D loss: 0.299267]\n",
      "496 [D loss: 0.296246]\n",
      "497 [D loss: 0.292963]\n",
      "498 [D loss: 0.285401]\n",
      "499 [D loss: 0.284262]\n",
      "500 [D loss: 0.292642]\n",
      "501 [D loss: 0.299542]\n",
      "502 [D loss: 0.305653]\n",
      "503 [D loss: 0.283732]\n",
      "504 [D loss: 0.282703]\n",
      "505 [D loss: 0.285194]\n",
      "506 [D loss: 0.290990]\n",
      "507 [D loss: 0.288246]\n",
      "508 [D loss: 0.293757]\n",
      "509 [D loss: 0.280675]\n",
      "510 [D loss: 0.294604]\n",
      "511 [D loss: 0.299717]\n",
      "512 [D loss: 0.295437]\n",
      "513 [D loss: 0.280078]\n",
      "514 [D loss: 0.282173]\n",
      "515 [D loss: 0.284832]\n",
      "516 [D loss: 0.282685]\n",
      "517 [D loss: 0.282824]\n",
      "518 [D loss: 0.278189]\n",
      "519 [D loss: 0.284809]\n",
      "520 [D loss: 0.282853]\n",
      "521 [D loss: 0.289953]\n",
      "522 [D loss: 0.292373]\n",
      "523 [D loss: 0.296936]\n",
      "524 [D loss: 0.289341]\n",
      "525 [D loss: 0.287855]\n",
      "526 [D loss: 0.286772]\n",
      "527 [D loss: 0.296617]\n",
      "528 [D loss: 0.276129]\n",
      "529 [D loss: 0.292383]\n",
      "530 [D loss: 0.287225]\n",
      "531 [D loss: 0.278751]\n",
      "532 [D loss: 0.285191]\n",
      "533 [D loss: 0.282442]\n",
      "534 [D loss: 0.289116]\n",
      "535 [D loss: 0.293650]\n",
      "536 [D loss: 0.287343]\n",
      "537 [D loss: 0.285007]\n",
      "538 [D loss: 0.287969]\n",
      "539 [D loss: 0.317771]\n",
      "540 [D loss: 0.294781]\n",
      "541 [D loss: 0.283936]\n",
      "542 [D loss: 0.293645]\n",
      "543 [D loss: 0.284697]\n",
      "544 [D loss: 0.293358]\n",
      "545 [D loss: 0.282275]\n",
      "546 [D loss: 0.281467]\n",
      "547 [D loss: 0.289884]\n",
      "548 [D loss: 0.280758]\n",
      "549 [D loss: 0.284051]\n",
      "550 [D loss: 0.288233]\n",
      "551 [D loss: 0.290607]\n",
      "552 [D loss: 0.281649]\n",
      "553 [D loss: 0.275435]\n",
      "554 [D loss: 0.274134]\n",
      "555 [D loss: 0.307270]\n",
      "556 [D loss: 0.290056]\n",
      "557 [D loss: 0.329263]\n",
      "558 [D loss: 0.282195]\n",
      "559 [D loss: 0.295652]\n",
      "560 [D loss: 0.281697]\n",
      "561 [D loss: 0.283284]\n",
      "562 [D loss: 0.284919]\n",
      "563 [D loss: 0.277639]\n",
      "564 [D loss: 0.283681]\n",
      "565 [D loss: 0.278417]\n",
      "566 [D loss: 0.281164]\n",
      "567 [D loss: 0.273071]\n",
      "568 [D loss: 0.279086]\n",
      "569 [D loss: 0.282324]\n",
      "570 [D loss: 0.277049]\n",
      "571 [D loss: 0.276823]\n",
      "572 [D loss: 0.270058]\n",
      "573 [D loss: 0.284291]\n",
      "574 [D loss: 0.276277]\n",
      "575 [D loss: 0.267431]\n",
      "576 [D loss: 0.273428]\n",
      "577 [D loss: 0.281093]\n",
      "578 [D loss: 0.279507]\n",
      "579 [D loss: 0.283049]\n",
      "580 [D loss: 0.278167]\n",
      "581 [D loss: 0.267813]\n",
      "582 [D loss: 0.280721]\n",
      "583 [D loss: 0.283832]\n",
      "584 [D loss: 0.292997]\n",
      "585 [D loss: 0.274852]\n",
      "586 [D loss: 0.271049]\n",
      "587 [D loss: 0.283508]\n",
      "588 [D loss: 0.275967]\n",
      "589 [D loss: 0.273991]\n",
      "590 [D loss: 0.270805]\n",
      "591 [D loss: 0.291057]\n",
      "592 [D loss: 0.272991]\n",
      "593 [D loss: 0.280348]\n",
      "594 [D loss: 0.274431]\n",
      "595 [D loss: 0.265311]\n",
      "596 [D loss: 0.276157]\n",
      "597 [D loss: 0.271891]\n",
      "598 [D loss: 0.325990]\n",
      "599 [D loss: 0.275857]\n",
      "600 [D loss: 0.273619]\n",
      "601 [D loss: 0.288983]\n",
      "602 [D loss: 0.274993]\n",
      "603 [D loss: 0.263952]\n",
      "604 [D loss: 0.277133]\n",
      "605 [D loss: 0.284040]\n",
      "606 [D loss: 0.291307]\n",
      "607 [D loss: 0.278938]\n",
      "608 [D loss: 0.265273]\n",
      "609 [D loss: 0.273969]\n",
      "610 [D loss: 0.264063]\n",
      "611 [D loss: 0.271901]\n",
      "612 [D loss: 0.274611]\n",
      "613 [D loss: 0.282091]\n",
      "614 [D loss: 0.269390]\n",
      "615 [D loss: 0.268246]\n",
      "616 [D loss: 0.279931]\n",
      "617 [D loss: 0.272838]\n",
      "618 [D loss: 0.266839]\n",
      "619 [D loss: 0.281909]\n",
      "620 [D loss: 0.268951]\n",
      "621 [D loss: 0.274197]\n",
      "622 [D loss: 0.275527]\n",
      "623 [D loss: 0.273227]\n",
      "624 [D loss: 0.270400]\n",
      "625 [D loss: 0.273011]\n",
      "626 [D loss: 0.271073]\n",
      "627 [D loss: 0.265515]\n",
      "628 [D loss: 0.270844]\n",
      "629 [D loss: 0.265372]\n",
      "630 [D loss: 0.282249]\n",
      "631 [D loss: 0.268956]\n",
      "632 [D loss: 0.265654]\n",
      "633 [D loss: 0.272573]\n",
      "634 [D loss: 0.279099]\n",
      "635 [D loss: 0.268671]\n",
      "636 [D loss: 0.267236]\n",
      "637 [D loss: 0.276857]\n",
      "638 [D loss: 0.277284]\n",
      "639 [D loss: 0.266328]\n",
      "640 [D loss: 0.268594]\n",
      "641 [D loss: 0.278516]\n",
      "642 [D loss: 0.266724]\n",
      "643 [D loss: 0.275398]\n",
      "644 [D loss: 0.262088]\n",
      "645 [D loss: 0.272894]\n",
      "646 [D loss: 0.266906]\n",
      "647 [D loss: 0.274945]\n",
      "648 [D loss: 0.272551]\n",
      "649 [D loss: 0.271770]\n",
      "650 [D loss: 0.270641]\n",
      "651 [D loss: 0.270163]\n",
      "652 [D loss: 0.266186]\n",
      "653 [D loss: 0.263732]\n",
      "654 [D loss: 0.273429]\n",
      "655 [D loss: 0.268208]\n",
      "656 [D loss: 0.273380]\n",
      "657 [D loss: 0.280806]\n",
      "658 [D loss: 0.259470]\n",
      "659 [D loss: 0.260421]\n",
      "660 [D loss: 0.266456]\n",
      "661 [D loss: 0.261239]\n",
      "662 [D loss: 0.260858]\n",
      "663 [D loss: 0.257756]\n",
      "664 [D loss: 0.264186]\n",
      "665 [D loss: 0.287937]\n",
      "666 [D loss: 0.363364]\n",
      "667 [D loss: 0.263031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668 [D loss: 0.266248]\n",
      "669 [D loss: 0.270703]\n",
      "670 [D loss: 0.265600]\n",
      "671 [D loss: 0.272191]\n",
      "672 [D loss: 0.318701]\n",
      "673 [D loss: 0.262886]\n",
      "674 [D loss: 0.261353]\n",
      "675 [D loss: 0.265153]\n",
      "676 [D loss: 0.264942]\n",
      "677 [D loss: 0.266125]\n",
      "678 [D loss: 0.266397]\n",
      "679 [D loss: 0.262858]\n",
      "680 [D loss: 0.259541]\n",
      "681 [D loss: 0.270350]\n",
      "682 [D loss: 0.267079]\n",
      "683 [D loss: 0.267645]\n",
      "684 [D loss: 0.284718]\n",
      "685 [D loss: 0.252535]\n",
      "686 [D loss: 0.266327]\n",
      "687 [D loss: 0.266572]\n",
      "688 [D loss: 0.257200]\n",
      "689 [D loss: 0.275976]\n",
      "690 [D loss: 0.266376]\n",
      "691 [D loss: 0.269848]\n",
      "692 [D loss: 0.259641]\n",
      "693 [D loss: 0.265617]\n",
      "694 [D loss: 0.263667]\n",
      "695 [D loss: 0.287400]\n",
      "696 [D loss: 0.266186]\n",
      "697 [D loss: 0.272100]\n",
      "698 [D loss: 0.265068]\n",
      "699 [D loss: 0.268523]\n",
      "700 [D loss: 0.258919]\n",
      "701 [D loss: 0.253631]\n",
      "702 [D loss: 0.267419]\n",
      "703 [D loss: 0.270785]\n",
      "704 [D loss: 0.262081]\n",
      "705 [D loss: 0.262285]\n",
      "706 [D loss: 0.278156]\n",
      "707 [D loss: 0.250528]\n",
      "708 [D loss: 0.259005]\n",
      "709 [D loss: 0.265866]\n",
      "710 [D loss: 0.263519]\n",
      "711 [D loss: 0.258637]\n",
      "712 [D loss: 0.265959]\n",
      "713 [D loss: 0.262801]\n",
      "714 [D loss: 0.256827]\n",
      "715 [D loss: 0.263740]\n",
      "716 [D loss: 0.257062]\n",
      "717 [D loss: 0.263341]\n",
      "718 [D loss: 0.257971]\n",
      "719 [D loss: 0.265009]\n",
      "720 [D loss: 0.251752]\n",
      "721 [D loss: 0.261861]\n",
      "722 [D loss: 0.255710]\n",
      "723 [D loss: 0.257879]\n",
      "724 [D loss: 0.254021]\n",
      "725 [D loss: 0.260540]\n",
      "726 [D loss: 0.269453]\n",
      "727 [D loss: 0.255957]\n",
      "728 [D loss: 0.255269]\n",
      "729 [D loss: 0.272440]\n",
      "730 [D loss: 0.261589]\n",
      "731 [D loss: 0.269536]\n",
      "732 [D loss: 0.253107]\n",
      "733 [D loss: 0.257501]\n",
      "734 [D loss: 0.266822]\n",
      "735 [D loss: 0.261036]\n",
      "736 [D loss: 0.257356]\n",
      "737 [D loss: 0.260223]\n",
      "738 [D loss: 0.266257]\n",
      "739 [D loss: 0.255190]\n",
      "740 [D loss: 0.250368]\n",
      "741 [D loss: 0.259384]\n",
      "742 [D loss: 0.259621]\n",
      "743 [D loss: 0.252934]\n",
      "744 [D loss: 0.256237]\n",
      "745 [D loss: 0.249537]\n",
      "746 [D loss: 0.264532]\n",
      "747 [D loss: 0.257332]\n",
      "748 [D loss: 0.255741]\n",
      "749 [D loss: 0.258424]\n",
      "750 [D loss: 0.276322]\n",
      "751 [D loss: 0.259980]\n",
      "752 [D loss: 0.252265]\n",
      "753 [D loss: 0.252296]\n",
      "754 [D loss: 0.255214]\n",
      "755 [D loss: 0.252735]\n",
      "756 [D loss: 0.253158]\n",
      "757 [D loss: 0.294735]\n",
      "758 [D loss: 0.292492]\n",
      "759 [D loss: 0.245142]\n",
      "760 [D loss: 0.258588]\n",
      "761 [D loss: 0.268110]\n",
      "762 [D loss: 0.251005]\n",
      "763 [D loss: 0.350231]\n",
      "764 [D loss: 0.247014]\n",
      "765 [D loss: 0.259761]\n",
      "766 [D loss: 0.252385]\n",
      "767 [D loss: 0.247899]\n",
      "768 [D loss: 0.253975]\n",
      "769 [D loss: 0.249038]\n",
      "770 [D loss: 0.259550]\n",
      "771 [D loss: 0.262750]\n",
      "772 [D loss: 0.250955]\n",
      "773 [D loss: 0.247571]\n",
      "774 [D loss: 0.248761]\n",
      "775 [D loss: 0.253690]\n",
      "776 [D loss: 0.258730]\n",
      "777 [D loss: 0.243140]\n",
      "778 [D loss: 0.264512]\n",
      "779 [D loss: 0.256236]\n",
      "780 [D loss: 0.255901]\n",
      "781 [D loss: 0.242777]\n",
      "782 [D loss: 0.249863]\n",
      "783 [D loss: 0.256874]\n",
      "784 [D loss: 0.249524]\n",
      "785 [D loss: 0.250761]\n",
      "786 [D loss: 0.242059]\n",
      "787 [D loss: 0.262303]\n",
      "788 [D loss: 0.254628]\n",
      "789 [D loss: 0.250975]\n",
      "790 [D loss: 0.247910]\n",
      "791 [D loss: 0.251108]\n",
      "792 [D loss: 0.264443]\n",
      "793 [D loss: 0.255028]\n",
      "794 [D loss: 0.251226]\n",
      "795 [D loss: 0.249668]\n",
      "796 [D loss: 0.266171]\n",
      "797 [D loss: 0.260599]\n",
      "798 [D loss: 0.261812]\n",
      "799 [D loss: 0.249037]\n",
      "800 [D loss: 0.246140]\n",
      "801 [D loss: 0.246944]\n",
      "802 [D loss: 0.253003]\n",
      "803 [D loss: 0.234773]\n",
      "804 [D loss: 0.250155]\n",
      "805 [D loss: 0.265352]\n",
      "806 [D loss: 0.244297]\n",
      "807 [D loss: 0.250273]\n",
      "808 [D loss: 0.245414]\n",
      "809 [D loss: 0.253282]\n",
      "810 [D loss: 0.237204]\n",
      "811 [D loss: 0.240742]\n",
      "812 [D loss: 0.245531]\n",
      "813 [D loss: 0.256460]\n",
      "814 [D loss: 0.246138]\n",
      "815 [D loss: 0.243384]\n",
      "816 [D loss: 0.248160]\n",
      "817 [D loss: 0.255481]\n",
      "818 [D loss: 0.245482]\n",
      "819 [D loss: 0.249897]\n",
      "820 [D loss: 0.260802]\n",
      "821 [D loss: 0.240129]\n",
      "822 [D loss: 0.242257]\n",
      "823 [D loss: 0.246589]\n",
      "824 [D loss: 0.244810]\n",
      "825 [D loss: 0.241063]\n",
      "826 [D loss: 0.248772]\n",
      "827 [D loss: 0.241372]\n",
      "828 [D loss: 0.255845]\n",
      "829 [D loss: 0.248441]\n",
      "830 [D loss: 0.253526]\n",
      "831 [D loss: 0.243666]\n",
      "832 [D loss: 0.240460]\n",
      "833 [D loss: 0.240418]\n",
      "834 [D loss: 0.245825]\n",
      "835 [D loss: 0.251311]\n",
      "836 [D loss: 0.239348]\n",
      "837 [D loss: 0.237033]\n",
      "838 [D loss: 0.243075]\n",
      "839 [D loss: 0.239308]\n",
      "840 [D loss: 0.240033]\n",
      "841 [D loss: 0.238504]\n",
      "842 [D loss: 0.234797]\n",
      "843 [D loss: 0.241426]\n",
      "844 [D loss: 0.243324]\n",
      "845 [D loss: 0.239031]\n",
      "846 [D loss: 0.242320]\n",
      "847 [D loss: 0.235616]\n",
      "848 [D loss: 0.240187]\n",
      "849 [D loss: 0.246599]\n",
      "850 [D loss: 0.237291]\n",
      "851 [D loss: 0.240981]\n",
      "852 [D loss: 0.234800]\n",
      "853 [D loss: 0.230832]\n",
      "854 [D loss: 0.243637]\n",
      "855 [D loss: 0.231352]\n",
      "856 [D loss: 0.234055]\n",
      "857 [D loss: 0.241784]\n",
      "858 [D loss: 0.241839]\n",
      "859 [D loss: 0.234060]\n",
      "860 [D loss: 0.236974]\n",
      "861 [D loss: 0.242140]\n",
      "862 [D loss: 0.239585]\n",
      "863 [D loss: 0.235738]\n",
      "864 [D loss: 0.256065]\n",
      "865 [D loss: 0.235607]\n",
      "866 [D loss: 0.247866]\n",
      "867 [D loss: 0.239776]\n",
      "868 [D loss: 0.249639]\n",
      "869 [D loss: 0.232954]\n",
      "870 [D loss: 0.232414]\n",
      "871 [D loss: 0.245305]\n",
      "872 [D loss: 0.244580]\n",
      "873 [D loss: 0.256021]\n",
      "874 [D loss: 0.247328]\n",
      "875 [D loss: 0.238354]\n",
      "876 [D loss: 0.242087]\n",
      "877 [D loss: 0.235528]\n",
      "878 [D loss: 0.237780]\n",
      "879 [D loss: 0.240503]\n",
      "880 [D loss: 0.228425]\n",
      "881 [D loss: 0.239984]\n",
      "882 [D loss: 0.230665]\n",
      "883 [D loss: 0.228242]\n",
      "884 [D loss: 0.247029]\n",
      "885 [D loss: 0.230551]\n",
      "886 [D loss: 0.232642]\n",
      "887 [D loss: 0.231737]\n",
      "888 [D loss: 0.237915]\n",
      "889 [D loss: 0.230604]\n",
      "890 [D loss: 0.238406]\n",
      "891 [D loss: 0.237362]\n",
      "892 [D loss: 0.235949]\n",
      "893 [D loss: 0.238440]\n",
      "894 [D loss: 0.225447]\n",
      "895 [D loss: 0.242895]\n",
      "896 [D loss: 0.239659]\n",
      "897 [D loss: 0.227091]\n",
      "898 [D loss: 0.231593]\n",
      "899 [D loss: 0.233369]\n",
      "900 [D loss: 0.242083]\n",
      "901 [D loss: 0.234055]\n",
      "902 [D loss: 0.262428]\n",
      "903 [D loss: 0.224103]\n",
      "904 [D loss: 0.227685]\n",
      "905 [D loss: 0.229624]\n",
      "906 [D loss: 0.230985]\n",
      "907 [D loss: 0.233349]\n",
      "908 [D loss: 0.231418]\n",
      "909 [D loss: 0.229486]\n",
      "910 [D loss: 0.230601]\n",
      "911 [D loss: 0.232191]\n",
      "912 [D loss: 0.221655]\n",
      "913 [D loss: 0.239595]\n",
      "914 [D loss: 0.232850]\n",
      "915 [D loss: 0.229483]\n",
      "916 [D loss: 0.238850]\n",
      "917 [D loss: 0.237873]\n",
      "918 [D loss: 0.227699]\n",
      "919 [D loss: 0.234671]\n",
      "920 [D loss: 0.232786]\n",
      "921 [D loss: 0.232238]\n",
      "922 [D loss: 0.222315]\n",
      "923 [D loss: 0.226656]\n",
      "924 [D loss: 0.232070]\n",
      "925 [D loss: 0.236162]\n",
      "926 [D loss: 0.224287]\n",
      "927 [D loss: 0.230895]\n",
      "928 [D loss: 0.238494]\n",
      "929 [D loss: 0.244233]\n",
      "930 [D loss: 0.232285]\n",
      "931 [D loss: 0.237837]\n",
      "932 [D loss: 0.233023]\n",
      "933 [D loss: 0.225976]\n",
      "934 [D loss: 0.225381]\n",
      "935 [D loss: 0.231828]\n",
      "936 [D loss: 0.225266]\n",
      "937 [D loss: 0.223646]\n",
      "938 [D loss: 0.228589]\n",
      "939 [D loss: 0.233324]\n",
      "940 [D loss: 0.226637]\n",
      "941 [D loss: 0.237090]\n",
      "942 [D loss: 0.216809]\n",
      "943 [D loss: 0.238930]\n",
      "944 [D loss: 0.229334]\n",
      "945 [D loss: 0.225132]\n",
      "946 [D loss: 0.224783]\n",
      "947 [D loss: 0.231758]\n",
      "948 [D loss: 0.226222]\n",
      "949 [D loss: 0.239797]\n",
      "950 [D loss: 0.232502]\n",
      "951 [D loss: 0.224717]\n",
      "952 [D loss: 0.224957]\n",
      "953 [D loss: 0.220372]\n",
      "954 [D loss: 0.227788]\n",
      "955 [D loss: 0.222811]\n",
      "956 [D loss: 0.233065]\n",
      "957 [D loss: 0.216075]\n",
      "958 [D loss: 0.224979]\n",
      "959 [D loss: 0.228293]\n",
      "960 [D loss: 0.222174]\n",
      "961 [D loss: 0.234245]\n",
      "962 [D loss: 0.220505]\n",
      "963 [D loss: 0.242343]\n",
      "964 [D loss: 0.231276]\n",
      "965 [D loss: 0.215809]\n",
      "966 [D loss: 0.218093]\n",
      "967 [D loss: 0.221190]\n",
      "968 [D loss: 0.237663]\n",
      "969 [D loss: 0.224051]\n",
      "970 [D loss: 0.222766]\n",
      "971 [D loss: 0.235152]\n",
      "972 [D loss: 0.217843]\n",
      "973 [D loss: 0.226987]\n",
      "974 [D loss: 0.230308]\n",
      "975 [D loss: 0.217713]\n",
      "976 [D loss: 0.226648]\n",
      "977 [D loss: 0.232290]\n",
      "978 [D loss: 0.228907]\n",
      "979 [D loss: 0.218554]\n",
      "980 [D loss: 0.217252]\n",
      "981 [D loss: 0.221814]\n",
      "982 [D loss: 0.220967]\n",
      "983 [D loss: 0.227131]\n",
      "984 [D loss: 0.221940]\n",
      "985 [D loss: 0.223500]\n",
      "986 [D loss: 0.224202]\n",
      "987 [D loss: 0.216909]\n",
      "988 [D loss: 0.216220]\n",
      "989 [D loss: 0.219697]\n",
      "990 [D loss: 0.224370]\n",
      "991 [D loss: 0.228152]\n",
      "992 [D loss: 0.220143]\n",
      "993 [D loss: 0.219701]\n",
      "994 [D loss: 0.230109]\n",
      "995 [D loss: 0.220880]\n",
      "996 [D loss: 0.212203]\n",
      "997 [D loss: 0.219778]\n",
      "998 [D loss: 0.216989]\n",
      "999 [D loss: 0.211750]\n",
      "1000 [D loss: 0.217658]\n",
      "1001 [D loss: 0.228595]\n",
      "1002 [D loss: 0.226582]\n",
      "1003 [D loss: 0.211261]\n",
      "1004 [D loss: 0.223069]\n",
      "1005 [D loss: 0.218813]\n",
      "1006 [D loss: 0.211421]\n",
      "1007 [D loss: 0.222374]\n",
      "1008 [D loss: 0.223902]\n",
      "1009 [D loss: 0.220479]\n",
      "1010 [D loss: 0.221952]\n",
      "1011 [D loss: 0.220614]\n",
      "1012 [D loss: 0.210668]\n",
      "1013 [D loss: 0.228278]\n",
      "1014 [D loss: 0.230238]\n",
      "1015 [D loss: 0.212372]\n",
      "1016 [D loss: 0.222882]\n",
      "1017 [D loss: 0.221597]\n",
      "1018 [D loss: 0.219872]\n",
      "1019 [D loss: 0.219570]\n",
      "1020 [D loss: 0.224150]\n",
      "1021 [D loss: 0.210139]\n",
      "1022 [D loss: 0.224256]\n",
      "1023 [D loss: 0.216707]\n",
      "1024 [D loss: 0.219576]\n",
      "1025 [D loss: 0.219580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026 [D loss: 0.225626]\n",
      "1027 [D loss: 0.221823]\n",
      "1028 [D loss: 0.218433]\n",
      "1029 [D loss: 0.220307]\n",
      "1030 [D loss: 0.211908]\n",
      "1031 [D loss: 0.209995]\n",
      "1032 [D loss: 0.217651]\n",
      "1033 [D loss: 0.210062]\n",
      "1034 [D loss: 0.215570]\n",
      "1035 [D loss: 0.213503]\n",
      "1036 [D loss: 0.224599]\n",
      "1037 [D loss: 0.215067]\n",
      "1038 [D loss: 0.214599]\n",
      "1039 [D loss: 0.226404]\n",
      "1040 [D loss: 0.215161]\n",
      "1041 [D loss: 0.212181]\n",
      "1042 [D loss: 0.212074]\n",
      "1043 [D loss: 0.212778]\n",
      "1044 [D loss: 0.215298]\n",
      "1045 [D loss: 0.214949]\n",
      "1046 [D loss: 0.219698]\n",
      "1047 [D loss: 0.221258]\n",
      "1048 [D loss: 0.239405]\n",
      "1049 [D loss: 0.211642]\n",
      "1050 [D loss: 0.211435]\n",
      "1051 [D loss: 0.201970]\n",
      "1052 [D loss: 0.209836]\n",
      "1053 [D loss: 0.219132]\n",
      "1054 [D loss: 0.208751]\n",
      "1055 [D loss: 0.201959]\n",
      "1056 [D loss: 0.202528]\n",
      "1057 [D loss: 0.214745]\n",
      "1058 [D loss: 0.225659]\n",
      "1059 [D loss: 0.204885]\n",
      "1060 [D loss: 0.212761]\n",
      "1061 [D loss: 0.210271]\n",
      "1062 [D loss: 0.213623]\n",
      "1063 [D loss: 0.201632]\n",
      "1064 [D loss: 0.206849]\n",
      "1065 [D loss: 0.222771]\n",
      "1066 [D loss: 0.217429]\n",
      "1067 [D loss: 0.308525]\n",
      "1068 [D loss: 0.228270]\n",
      "1069 [D loss: 0.218105]\n",
      "1070 [D loss: 0.210846]\n",
      "1071 [D loss: 0.219194]\n",
      "1072 [D loss: 0.206721]\n",
      "1073 [D loss: 0.240937]\n",
      "1074 [D loss: 0.202787]\n",
      "1075 [D loss: 0.220824]\n",
      "1076 [D loss: 0.217868]\n",
      "1077 [D loss: 0.205270]\n",
      "1078 [D loss: 0.230251]\n",
      "1079 [D loss: 0.208094]\n",
      "1080 [D loss: 0.206624]\n",
      "1081 [D loss: 0.229599]\n",
      "1082 [D loss: 0.203782]\n",
      "1083 [D loss: 0.200886]\n",
      "1084 [D loss: 0.215246]\n",
      "1085 [D loss: 0.210374]\n",
      "1086 [D loss: 0.213966]\n",
      "1087 [D loss: 0.207818]\n",
      "1088 [D loss: 0.200619]\n",
      "1089 [D loss: 0.206428]\n",
      "1090 [D loss: 0.203702]\n",
      "1091 [D loss: 0.269867]\n",
      "1092 [D loss: 0.205313]\n",
      "1093 [D loss: 0.212987]\n",
      "1094 [D loss: 0.212530]\n",
      "1095 [D loss: 0.210747]\n",
      "1096 [D loss: 0.224829]\n",
      "1097 [D loss: 0.203773]\n",
      "1098 [D loss: 0.210539]\n",
      "1099 [D loss: 0.205691]\n",
      "1100 [D loss: 0.214672]\n",
      "1101 [D loss: 0.201548]\n",
      "1102 [D loss: 0.202941]\n",
      "1103 [D loss: 0.199582]\n",
      "1104 [D loss: 0.209604]\n",
      "1105 [D loss: 0.207684]\n",
      "1106 [D loss: 0.200227]\n",
      "1107 [D loss: 0.203956]\n",
      "1108 [D loss: 0.199255]\n",
      "1109 [D loss: 0.209672]\n",
      "1110 [D loss: 0.206533]\n",
      "1111 [D loss: 0.208628]\n",
      "1112 [D loss: 0.208068]\n",
      "1113 [D loss: 0.212196]\n",
      "1114 [D loss: 0.211761]\n",
      "1115 [D loss: 0.202617]\n",
      "1116 [D loss: 0.207689]\n",
      "1117 [D loss: 0.214567]\n",
      "1118 [D loss: 0.216566]\n",
      "1119 [D loss: 0.208433]\n",
      "1120 [D loss: 0.202126]\n",
      "1121 [D loss: 0.213231]\n",
      "1122 [D loss: 0.208531]\n",
      "1123 [D loss: 0.208757]\n",
      "1124 [D loss: 0.195687]\n",
      "1125 [D loss: 0.206512]\n",
      "1126 [D loss: 0.218324]\n",
      "1127 [D loss: 0.212251]\n",
      "1128 [D loss: 0.203222]\n",
      "1129 [D loss: 0.201059]\n",
      "1130 [D loss: 0.200004]\n",
      "1131 [D loss: 0.219568]\n",
      "1132 [D loss: 0.201177]\n",
      "1133 [D loss: 0.205188]\n",
      "1134 [D loss: 0.209285]\n",
      "1135 [D loss: 0.203821]\n",
      "1136 [D loss: 0.219659]\n",
      "1137 [D loss: 0.207217]\n",
      "1138 [D loss: 0.199577]\n",
      "1139 [D loss: 0.199769]\n",
      "1140 [D loss: 0.211135]\n",
      "1141 [D loss: 0.199095]\n",
      "1142 [D loss: 0.249485]\n",
      "1143 [D loss: 0.196369]\n",
      "1144 [D loss: 0.198910]\n",
      "1145 [D loss: 0.210795]\n",
      "1146 [D loss: 0.201309]\n",
      "1147 [D loss: 0.206795]\n",
      "1148 [D loss: 0.202565]\n",
      "1149 [D loss: 0.199664]\n",
      "1150 [D loss: 0.205323]\n",
      "1151 [D loss: 0.196542]\n",
      "1152 [D loss: 0.195662]\n",
      "1153 [D loss: 0.204819]\n",
      "1154 [D loss: 0.210633]\n",
      "1155 [D loss: 0.228336]\n",
      "1156 [D loss: 0.194284]\n",
      "1157 [D loss: 0.205456]\n",
      "1158 [D loss: 0.203175]\n",
      "1159 [D loss: 0.203030]\n",
      "1160 [D loss: 0.198773]\n",
      "1161 [D loss: 0.215910]\n",
      "1162 [D loss: 0.208627]\n",
      "1163 [D loss: 0.204437]\n",
      "1164 [D loss: 0.195628]\n",
      "1165 [D loss: 0.192606]\n",
      "1166 [D loss: 0.205208]\n",
      "1167 [D loss: 0.206129]\n",
      "1168 [D loss: 0.194279]\n",
      "1169 [D loss: 0.194459]\n",
      "1170 [D loss: 0.196759]\n",
      "1171 [D loss: 0.194687]\n",
      "1172 [D loss: 0.191141]\n",
      "1173 [D loss: 0.196413]\n",
      "1174 [D loss: 0.198137]\n",
      "1175 [D loss: 0.199636]\n",
      "1176 [D loss: 0.215270]\n",
      "1177 [D loss: 0.213410]\n",
      "1178 [D loss: 0.194846]\n",
      "1179 [D loss: 0.196142]\n",
      "1180 [D loss: 0.195400]\n",
      "1181 [D loss: 0.187104]\n",
      "1182 [D loss: 0.199137]\n",
      "1183 [D loss: 0.200145]\n",
      "1184 [D loss: 0.205363]\n",
      "1185 [D loss: 0.187756]\n",
      "1186 [D loss: 0.203307]\n",
      "1187 [D loss: 0.218187]\n",
      "1188 [D loss: 0.202546]\n",
      "1189 [D loss: 0.195016]\n",
      "1190 [D loss: 0.195456]\n",
      "1191 [D loss: 0.199659]\n",
      "1192 [D loss: 0.192244]\n",
      "1193 [D loss: 0.198835]\n",
      "1194 [D loss: 0.199106]\n",
      "1195 [D loss: 0.192559]\n",
      "1196 [D loss: 0.202711]\n",
      "1197 [D loss: 0.193071]\n",
      "1198 [D loss: 0.230539]\n",
      "1199 [D loss: 0.209100]\n",
      "1200 [D loss: 0.202679]\n",
      "1201 [D loss: 0.203481]\n",
      "1202 [D loss: 0.200839]\n",
      "1203 [D loss: 0.197950]\n",
      "1204 [D loss: 0.191290]\n",
      "1205 [D loss: 0.230627]\n",
      "1206 [D loss: 0.191439]\n",
      "1207 [D loss: 0.193446]\n",
      "1208 [D loss: 0.199184]\n",
      "1209 [D loss: 0.195730]\n",
      "1210 [D loss: 0.192722]\n",
      "1211 [D loss: 0.202618]\n",
      "1212 [D loss: 0.184652]\n",
      "1213 [D loss: 0.188370]\n",
      "1214 [D loss: 0.193754]\n",
      "1215 [D loss: 0.210509]\n",
      "1216 [D loss: 0.181384]\n",
      "1217 [D loss: 0.198362]\n",
      "1218 [D loss: 0.296266]\n",
      "1219 [D loss: 0.198003]\n",
      "1220 [D loss: 0.201682]\n",
      "1221 [D loss: 0.194846]\n",
      "1222 [D loss: 0.194867]\n",
      "1223 [D loss: 0.206777]\n",
      "1224 [D loss: 0.198391]\n",
      "1225 [D loss: 0.201278]\n",
      "1226 [D loss: 0.197491]\n",
      "1227 [D loss: 0.196049]\n",
      "1228 [D loss: 0.190470]\n",
      "1229 [D loss: 0.205853]\n",
      "1230 [D loss: 0.189815]\n",
      "1231 [D loss: 0.180852]\n",
      "1232 [D loss: 0.187143]\n",
      "1233 [D loss: 0.193947]\n",
      "1234 [D loss: 0.185685]\n",
      "1235 [D loss: 0.191697]\n",
      "1236 [D loss: 0.186049]\n",
      "1237 [D loss: 0.192763]\n",
      "1238 [D loss: 0.196111]\n",
      "1239 [D loss: 0.198747]\n",
      "1240 [D loss: 0.187004]\n",
      "1241 [D loss: 0.193573]\n",
      "1242 [D loss: 0.195184]\n",
      "1243 [D loss: 0.190318]\n",
      "1244 [D loss: 0.189159]\n",
      "1245 [D loss: 0.186837]\n",
      "1246 [D loss: 0.204732]\n",
      "1247 [D loss: 0.188978]\n",
      "1248 [D loss: 0.199242]\n",
      "1249 [D loss: 0.199814]\n",
      "1250 [D loss: 0.188098]\n",
      "1251 [D loss: 0.199428]\n",
      "1252 [D loss: 0.186972]\n",
      "1253 [D loss: 0.192830]\n",
      "1254 [D loss: 0.184945]\n",
      "1255 [D loss: 0.201158]\n",
      "1256 [D loss: 0.189668]\n",
      "1257 [D loss: 0.186818]\n",
      "1258 [D loss: 0.201738]\n",
      "1259 [D loss: 0.185521]\n",
      "1260 [D loss: 0.186968]\n",
      "1261 [D loss: 0.187854]\n",
      "1262 [D loss: 0.188512]\n",
      "1263 [D loss: 0.179169]\n",
      "1264 [D loss: 0.191218]\n",
      "1265 [D loss: 0.181828]\n",
      "1266 [D loss: 0.188411]\n",
      "1267 [D loss: 0.186715]\n",
      "1268 [D loss: 0.189188]\n",
      "1269 [D loss: 0.188300]\n",
      "1270 [D loss: 0.186143]\n",
      "1271 [D loss: 0.183513]\n",
      "1272 [D loss: 0.185604]\n",
      "1273 [D loss: 0.189580]\n",
      "1274 [D loss: 0.186191]\n",
      "1275 [D loss: 0.191147]\n",
      "1276 [D loss: 0.183049]\n",
      "1277 [D loss: 0.199910]\n",
      "1278 [D loss: 0.191860]\n",
      "1279 [D loss: 0.195444]\n",
      "1280 [D loss: 0.182607]\n",
      "1281 [D loss: 0.184521]\n",
      "1282 [D loss: 0.187537]\n",
      "1283 [D loss: 0.187043]\n",
      "1284 [D loss: 0.189412]\n",
      "1285 [D loss: 0.177073]\n",
      "1286 [D loss: 0.181646]\n",
      "1287 [D loss: 0.181807]\n",
      "1288 [D loss: 0.188076]\n",
      "1289 [D loss: 0.188334]\n",
      "1290 [D loss: 0.180788]\n",
      "1291 [D loss: 0.202425]\n",
      "1292 [D loss: 0.178489]\n",
      "1293 [D loss: 0.188302]\n",
      "1294 [D loss: 0.217629]\n",
      "1295 [D loss: 0.183562]\n",
      "1296 [D loss: 0.176493]\n",
      "1297 [D loss: 0.180253]\n",
      "1298 [D loss: 0.187626]\n",
      "1299 [D loss: 0.177846]\n",
      "1300 [D loss: 0.190919]\n",
      "1301 [D loss: 0.199746]\n",
      "1302 [D loss: 0.183595]\n",
      "1303 [D loss: 0.189112]\n",
      "1304 [D loss: 0.188158]\n",
      "1305 [D loss: 0.189202]\n",
      "1306 [D loss: 0.174216]\n",
      "1307 [D loss: 0.246237]\n",
      "1308 [D loss: 0.182077]\n",
      "1309 [D loss: 0.178796]\n",
      "1310 [D loss: 0.180219]\n",
      "1311 [D loss: 0.179212]\n",
      "1312 [D loss: 0.175092]\n",
      "1313 [D loss: 0.191529]\n",
      "1314 [D loss: 0.181749]\n",
      "1315 [D loss: 0.177338]\n",
      "1316 [D loss: 0.182427]\n",
      "1317 [D loss: 0.177922]\n",
      "1318 [D loss: 0.177571]\n",
      "1319 [D loss: 0.189127]\n",
      "1320 [D loss: 0.183067]\n",
      "1321 [D loss: 0.180417]\n",
      "1322 [D loss: 0.193288]\n",
      "1323 [D loss: 0.181013]\n",
      "1324 [D loss: 0.179497]\n",
      "1325 [D loss: 0.177886]\n",
      "1326 [D loss: 0.182714]\n",
      "1327 [D loss: 0.184562]\n",
      "1328 [D loss: 0.173933]\n",
      "1329 [D loss: 0.176711]\n",
      "1330 [D loss: 0.181885]\n",
      "1331 [D loss: 0.185720]\n",
      "1332 [D loss: 0.189979]\n",
      "1333 [D loss: 0.219815]\n",
      "1334 [D loss: 0.172401]\n",
      "1335 [D loss: 0.181704]\n",
      "1336 [D loss: 0.169755]\n",
      "1337 [D loss: 0.189730]\n",
      "1338 [D loss: 0.173860]\n",
      "1339 [D loss: 0.188651]\n",
      "1340 [D loss: 0.178972]\n",
      "1341 [D loss: 0.170931]\n",
      "1342 [D loss: 0.176587]\n",
      "1343 [D loss: 0.197514]\n",
      "1344 [D loss: 0.184023]\n",
      "1345 [D loss: 0.173965]\n",
      "1346 [D loss: 0.176269]\n",
      "1347 [D loss: 0.170836]\n",
      "1348 [D loss: 0.179832]\n",
      "1349 [D loss: 0.177284]\n",
      "1350 [D loss: 0.183250]\n",
      "1351 [D loss: 0.171393]\n",
      "1352 [D loss: 0.176057]\n",
      "1353 [D loss: 0.174466]\n",
      "1354 [D loss: 0.188143]\n",
      "1355 [D loss: 0.183166]\n",
      "1356 [D loss: 0.173681]\n",
      "1357 [D loss: 0.182223]\n",
      "1358 [D loss: 0.197392]\n",
      "1359 [D loss: 0.176684]\n",
      "1360 [D loss: 0.172060]\n",
      "1361 [D loss: 0.174074]\n",
      "1362 [D loss: 0.169234]\n",
      "1363 [D loss: 0.175006]\n",
      "1364 [D loss: 0.171993]\n",
      "1365 [D loss: 0.174084]\n",
      "1366 [D loss: 0.175241]\n",
      "1367 [D loss: 0.179721]\n",
      "1368 [D loss: 0.170936]\n",
      "1369 [D loss: 0.179961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370 [D loss: 0.173201]\n",
      "1371 [D loss: 0.183789]\n",
      "1372 [D loss: 0.191526]\n",
      "1373 [D loss: 0.170926]\n",
      "1374 [D loss: 0.170532]\n",
      "1375 [D loss: 0.176957]\n",
      "1376 [D loss: 0.168597]\n",
      "1377 [D loss: 0.179179]\n",
      "1378 [D loss: 0.171248]\n",
      "1379 [D loss: 0.178018]\n",
      "1380 [D loss: 0.169137]\n",
      "1381 [D loss: 0.174729]\n",
      "1382 [D loss: 0.187421]\n",
      "1383 [D loss: 0.172448]\n",
      "1384 [D loss: 0.176062]\n",
      "1385 [D loss: 0.177595]\n",
      "1386 [D loss: 0.179332]\n",
      "1387 [D loss: 0.184663]\n",
      "1388 [D loss: 0.184386]\n",
      "1389 [D loss: 0.184330]\n",
      "1390 [D loss: 0.177455]\n",
      "1391 [D loss: 0.170531]\n",
      "1392 [D loss: 0.167825]\n",
      "1393 [D loss: 0.182198]\n",
      "1394 [D loss: 0.165150]\n",
      "1395 [D loss: 0.166549]\n",
      "1396 [D loss: 0.168568]\n",
      "1397 [D loss: 0.182131]\n",
      "1398 [D loss: 0.168667]\n",
      "1399 [D loss: 0.167456]\n",
      "1400 [D loss: 0.174079]\n",
      "1401 [D loss: 0.179087]\n",
      "1402 [D loss: 0.176983]\n",
      "1403 [D loss: 0.170827]\n",
      "1404 [D loss: 0.167206]\n",
      "1405 [D loss: 0.182979]\n",
      "1406 [D loss: 0.165452]\n",
      "1407 [D loss: 0.171900]\n",
      "1408 [D loss: 0.177457]\n",
      "1409 [D loss: 0.171263]\n",
      "1410 [D loss: 0.200337]\n",
      "1411 [D loss: 0.171983]\n",
      "1412 [D loss: 0.166461]\n",
      "1413 [D loss: 0.172570]\n",
      "1414 [D loss: 0.189787]\n",
      "1415 [D loss: 0.173479]\n",
      "1416 [D loss: 0.175148]\n",
      "1417 [D loss: 0.186031]\n",
      "1418 [D loss: 0.181493]\n",
      "1419 [D loss: 0.167429]\n",
      "1420 [D loss: 0.172615]\n",
      "1421 [D loss: 0.177358]\n",
      "1422 [D loss: 0.177225]\n",
      "1423 [D loss: 0.176751]\n",
      "1424 [D loss: 0.186732]\n",
      "1425 [D loss: 0.171570]\n",
      "1426 [D loss: 0.165975]\n",
      "1427 [D loss: 0.171070]\n",
      "1428 [D loss: 0.159642]\n",
      "1429 [D loss: 0.180698]\n",
      "1430 [D loss: 0.170892]\n",
      "1431 [D loss: 0.178346]\n",
      "1432 [D loss: 0.175061]\n",
      "1433 [D loss: 0.185081]\n",
      "1434 [D loss: 0.184816]\n",
      "1435 [D loss: 0.167226]\n",
      "1436 [D loss: 0.172876]\n",
      "1437 [D loss: 0.167126]\n",
      "1438 [D loss: 0.164021]\n",
      "1439 [D loss: 0.160094]\n",
      "1440 [D loss: 0.173090]\n",
      "1441 [D loss: 0.173865]\n",
      "1442 [D loss: 0.171773]\n",
      "1443 [D loss: 0.165553]\n",
      "1444 [D loss: 0.167491]\n",
      "1445 [D loss: 0.164211]\n",
      "1446 [D loss: 0.163953]\n",
      "1447 [D loss: 0.164253]\n",
      "1448 [D loss: 0.170612]\n",
      "1449 [D loss: 0.174611]\n",
      "1450 [D loss: 0.165363]\n",
      "1451 [D loss: 0.164331]\n",
      "1452 [D loss: 0.166541]\n",
      "1453 [D loss: 0.158875]\n",
      "1454 [D loss: 0.188853]\n",
      "1455 [D loss: 0.168669]\n",
      "1456 [D loss: 0.172636]\n",
      "1457 [D loss: 0.163841]\n",
      "1458 [D loss: 0.161810]\n",
      "1459 [D loss: 0.165367]\n",
      "1460 [D loss: 0.166132]\n",
      "1461 [D loss: 0.167265]\n",
      "1462 [D loss: 0.165192]\n",
      "1463 [D loss: 0.166133]\n",
      "1464 [D loss: 0.170997]\n",
      "1465 [D loss: 0.173947]\n",
      "1466 [D loss: 0.171692]\n",
      "1467 [D loss: 0.168970]\n",
      "1468 [D loss: 0.166978]\n",
      "1469 [D loss: 0.163363]\n",
      "1470 [D loss: 0.163908]\n",
      "1471 [D loss: 0.168897]\n",
      "1472 [D loss: 0.186966]\n",
      "1473 [D loss: 0.163649]\n",
      "1474 [D loss: 0.158738]\n",
      "1475 [D loss: 0.165989]\n",
      "1476 [D loss: 0.237158]\n",
      "1477 [D loss: 0.175018]\n",
      "1478 [D loss: 0.163590]\n",
      "1479 [D loss: 0.164985]\n",
      "1480 [D loss: 0.156825]\n",
      "1481 [D loss: 0.166414]\n",
      "1482 [D loss: 0.170111]\n",
      "1483 [D loss: 0.164502]\n",
      "1484 [D loss: 0.157363]\n",
      "1485 [D loss: 0.160407]\n",
      "1486 [D loss: 0.173447]\n",
      "1487 [D loss: 0.160052]\n",
      "1488 [D loss: 0.166108]\n",
      "1489 [D loss: 0.163112]\n",
      "1490 [D loss: 0.166373]\n",
      "1491 [D loss: 0.160768]\n",
      "1492 [D loss: 0.153207]\n",
      "1493 [D loss: 0.164036]\n",
      "1494 [D loss: 0.163023]\n",
      "1495 [D loss: 0.161583]\n",
      "1496 [D loss: 0.155405]\n",
      "1497 [D loss: 0.159217]\n",
      "1498 [D loss: 0.161266]\n",
      "1499 [D loss: 0.166043]\n",
      "1500 [D loss: 0.159616]\n",
      "1501 [D loss: 0.157588]\n",
      "1502 [D loss: 0.156637]\n",
      "1503 [D loss: 0.172189]\n",
      "1504 [D loss: 0.151650]\n",
      "1505 [D loss: 0.169888]\n",
      "1506 [D loss: 0.162751]\n",
      "1507 [D loss: 0.172132]\n",
      "1508 [D loss: 0.165912]\n",
      "1509 [D loss: 0.155212]\n",
      "1510 [D loss: 0.160176]\n",
      "1511 [D loss: 0.162803]\n",
      "1512 [D loss: 0.165469]\n",
      "1513 [D loss: 0.163423]\n",
      "1514 [D loss: 0.152208]\n",
      "1515 [D loss: 0.161205]\n",
      "1516 [D loss: 0.160851]\n",
      "1517 [D loss: 0.167747]\n",
      "1518 [D loss: 0.156621]\n",
      "1519 [D loss: 0.184429]\n",
      "1520 [D loss: 0.157819]\n",
      "1521 [D loss: 0.167031]\n",
      "1522 [D loss: 0.187284]\n",
      "1523 [D loss: 0.158723]\n",
      "1524 [D loss: 0.166625]\n",
      "1525 [D loss: 0.169197]\n",
      "1526 [D loss: 0.160059]\n",
      "1527 [D loss: 0.169296]\n",
      "1528 [D loss: 0.162624]\n",
      "1529 [D loss: 0.177811]\n",
      "1530 [D loss: 0.160418]\n",
      "1531 [D loss: 0.161894]\n",
      "1532 [D loss: 0.155333]\n",
      "1533 [D loss: 0.156234]\n",
      "1534 [D loss: 0.162491]\n",
      "1535 [D loss: 0.168020]\n",
      "1536 [D loss: 0.158644]\n",
      "1537 [D loss: 0.169333]\n",
      "1538 [D loss: 0.160286]\n",
      "1539 [D loss: 0.165999]\n",
      "1540 [D loss: 0.153088]\n",
      "1541 [D loss: 0.178547]\n",
      "1542 [D loss: 0.173440]\n",
      "1543 [D loss: 0.165025]\n",
      "1544 [D loss: 0.158526]\n",
      "1545 [D loss: 0.167722]\n",
      "1546 [D loss: 0.157638]\n",
      "1547 [D loss: 0.156851]\n",
      "1548 [D loss: 0.159225]\n",
      "1549 [D loss: 0.151848]\n",
      "1550 [D loss: 0.148898]\n",
      "1551 [D loss: 0.157857]\n",
      "1552 [D loss: 0.156653]\n",
      "1553 [D loss: 0.159781]\n",
      "1554 [D loss: 0.159016]\n",
      "1555 [D loss: 0.165807]\n",
      "1556 [D loss: 0.169409]\n",
      "1557 [D loss: 0.152660]\n",
      "1558 [D loss: 0.156540]\n",
      "1559 [D loss: 0.166879]\n",
      "1560 [D loss: 0.158863]\n",
      "1561 [D loss: 0.158021]\n",
      "1562 [D loss: 0.158822]\n",
      "1563 [D loss: 0.156938]\n",
      "1564 [D loss: 0.167343]\n",
      "1565 [D loss: 0.152542]\n",
      "1566 [D loss: 0.156745]\n",
      "1567 [D loss: 0.161077]\n",
      "1568 [D loss: 0.148346]\n",
      "1569 [D loss: 0.149685]\n",
      "1570 [D loss: 0.168684]\n",
      "1571 [D loss: 0.152356]\n",
      "1572 [D loss: 0.181540]\n",
      "1573 [D loss: 0.159983]\n",
      "1574 [D loss: 0.153994]\n",
      "1575 [D loss: 0.154750]\n",
      "1576 [D loss: 0.159453]\n",
      "1577 [D loss: 0.153346]\n",
      "1578 [D loss: 0.157376]\n",
      "1579 [D loss: 0.151835]\n",
      "1580 [D loss: 0.157239]\n",
      "1581 [D loss: 0.181899]\n",
      "1582 [D loss: 0.154415]\n",
      "1583 [D loss: 0.211169]\n",
      "1584 [D loss: 0.162699]\n",
      "1585 [D loss: 0.155590]\n",
      "1586 [D loss: 0.152162]\n",
      "1587 [D loss: 0.153253]\n",
      "1588 [D loss: 0.153966]\n",
      "1589 [D loss: 0.156001]\n",
      "1590 [D loss: 0.152298]\n",
      "1591 [D loss: 0.170405]\n",
      "1592 [D loss: 0.151851]\n",
      "1593 [D loss: 0.145666]\n",
      "1594 [D loss: 0.153544]\n",
      "1595 [D loss: 0.153933]\n",
      "1596 [D loss: 0.165336]\n",
      "1597 [D loss: 0.164844]\n",
      "1598 [D loss: 0.161752]\n",
      "1599 [D loss: 0.157342]\n",
      "1600 [D loss: 0.151381]\n",
      "1601 [D loss: 0.148898]\n",
      "1602 [D loss: 0.151054]\n",
      "1603 [D loss: 0.149678]\n",
      "1604 [D loss: 0.151291]\n",
      "1605 [D loss: 0.166395]\n",
      "1606 [D loss: 0.152548]\n",
      "1607 [D loss: 0.164678]\n",
      "1608 [D loss: 0.151498]\n",
      "1609 [D loss: 0.150892]\n",
      "1610 [D loss: 0.154399]\n",
      "1611 [D loss: 0.144770]\n",
      "1612 [D loss: 0.158896]\n",
      "1613 [D loss: 0.172548]\n",
      "1614 [D loss: 0.155811]\n",
      "1615 [D loss: 0.151268]\n",
      "1616 [D loss: 0.178394]\n",
      "1617 [D loss: 0.143938]\n",
      "1618 [D loss: 0.148276]\n",
      "1619 [D loss: 0.152604]\n",
      "1620 [D loss: 0.155521]\n",
      "1621 [D loss: 0.147473]\n",
      "1622 [D loss: 0.143351]\n",
      "1623 [D loss: 0.153957]\n",
      "1624 [D loss: 0.146698]\n",
      "1625 [D loss: 0.166270]\n",
      "1626 [D loss: 0.155269]\n",
      "1627 [D loss: 0.148031]\n",
      "1628 [D loss: 0.149829]\n",
      "1629 [D loss: 0.155235]\n",
      "1630 [D loss: 0.147231]\n",
      "1631 [D loss: 0.152081]\n",
      "1632 [D loss: 0.152722]\n",
      "1633 [D loss: 0.145009]\n",
      "1634 [D loss: 0.143284]\n",
      "1635 [D loss: 0.160435]\n",
      "1636 [D loss: 0.152787]\n",
      "1637 [D loss: 0.148525]\n",
      "1638 [D loss: 0.153753]\n",
      "1639 [D loss: 0.153112]\n",
      "1640 [D loss: 0.151966]\n",
      "1641 [D loss: 0.164665]\n",
      "1642 [D loss: 0.144890]\n",
      "1643 [D loss: 0.147041]\n",
      "1644 [D loss: 0.148792]\n",
      "1645 [D loss: 0.167641]\n",
      "1646 [D loss: 0.154341]\n",
      "1647 [D loss: 0.158045]\n",
      "1648 [D loss: 0.157859]\n",
      "1649 [D loss: 0.148276]\n",
      "1650 [D loss: 0.149698]\n",
      "1651 [D loss: 0.143155]\n",
      "1652 [D loss: 0.172915]\n",
      "1653 [D loss: 0.150793]\n",
      "1654 [D loss: 0.142845]\n",
      "1655 [D loss: 0.146665]\n",
      "1656 [D loss: 0.147725]\n",
      "1657 [D loss: 0.150607]\n",
      "1658 [D loss: 0.144691]\n",
      "1659 [D loss: 0.143869]\n",
      "1660 [D loss: 0.140116]\n",
      "1661 [D loss: 0.143116]\n",
      "1662 [D loss: 0.145007]\n",
      "1663 [D loss: 0.148207]\n",
      "1664 [D loss: 0.141965]\n",
      "1665 [D loss: 0.149224]\n",
      "1666 [D loss: 0.145120]\n",
      "1667 [D loss: 0.152070]\n",
      "1668 [D loss: 0.146740]\n",
      "1669 [D loss: 0.148959]\n",
      "1670 [D loss: 0.141196]\n",
      "1671 [D loss: 0.146912]\n",
      "1672 [D loss: 0.146793]\n",
      "1673 [D loss: 0.161692]\n",
      "1674 [D loss: 0.149056]\n",
      "1675 [D loss: 0.164657]\n",
      "1676 [D loss: 0.144546]\n",
      "1677 [D loss: 0.146984]\n",
      "1678 [D loss: 0.147563]\n",
      "1679 [D loss: 0.144390]\n",
      "1680 [D loss: 0.163244]\n",
      "1681 [D loss: 0.142134]\n",
      "1682 [D loss: 0.149604]\n",
      "1683 [D loss: 0.146421]\n",
      "1684 [D loss: 0.150442]\n",
      "1685 [D loss: 0.143344]\n",
      "1686 [D loss: 0.144739]\n",
      "1687 [D loss: 0.141332]\n",
      "1688 [D loss: 0.139091]\n",
      "1689 [D loss: 0.152601]\n",
      "1690 [D loss: 0.269091]\n",
      "1691 [D loss: 0.138156]\n",
      "1692 [D loss: 0.148504]\n",
      "1693 [D loss: 0.150625]\n",
      "1694 [D loss: 0.150705]\n",
      "1695 [D loss: 0.145229]\n",
      "1696 [D loss: 0.172218]\n",
      "1697 [D loss: 0.148798]\n",
      "1698 [D loss: 0.147377]\n",
      "1699 [D loss: 0.139248]\n",
      "1700 [D loss: 0.148119]\n",
      "1701 [D loss: 0.145078]\n",
      "1702 [D loss: 0.144776]\n",
      "1703 [D loss: 0.145677]\n",
      "1704 [D loss: 0.142582]\n",
      "1705 [D loss: 0.142509]\n",
      "1706 [D loss: 0.138727]\n",
      "1707 [D loss: 0.151616]\n",
      "1708 [D loss: 0.153959]\n",
      "1709 [D loss: 0.140672]\n",
      "1710 [D loss: 0.162791]\n",
      "1711 [D loss: 0.156868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712 [D loss: 0.138219]\n",
      "1713 [D loss: 0.142521]\n",
      "1714 [D loss: 0.140823]\n",
      "1715 [D loss: 0.151038]\n",
      "1716 [D loss: 0.137495]\n",
      "1717 [D loss: 0.136055]\n",
      "1718 [D loss: 0.139768]\n",
      "1719 [D loss: 0.142040]\n",
      "1720 [D loss: 0.162698]\n",
      "1721 [D loss: 0.140292]\n",
      "1722 [D loss: 0.165212]\n",
      "1723 [D loss: 0.138037]\n",
      "1724 [D loss: 0.135628]\n",
      "1725 [D loss: 0.142089]\n",
      "1726 [D loss: 0.135447]\n",
      "1727 [D loss: 0.148231]\n",
      "1728 [D loss: 0.147539]\n",
      "1729 [D loss: 0.143690]\n",
      "1730 [D loss: 0.138327]\n",
      "1731 [D loss: 0.134403]\n",
      "1732 [D loss: 0.137175]\n",
      "1733 [D loss: 0.143948]\n",
      "1734 [D loss: 0.130857]\n",
      "1735 [D loss: 0.139430]\n",
      "1736 [D loss: 0.159192]\n",
      "1737 [D loss: 0.146272]\n",
      "1738 [D loss: 0.137325]\n",
      "1739 [D loss: 0.142312]\n",
      "1740 [D loss: 0.153664]\n",
      "1741 [D loss: 0.150267]\n",
      "1742 [D loss: 0.182753]\n",
      "1743 [D loss: 0.144195]\n",
      "1744 [D loss: 0.132311]\n",
      "1745 [D loss: 0.135225]\n",
      "1746 [D loss: 0.146960]\n",
      "1747 [D loss: 0.144899]\n",
      "1748 [D loss: 0.135320]\n",
      "1749 [D loss: 0.147367]\n",
      "1750 [D loss: 0.141773]\n",
      "1751 [D loss: 0.154700]\n",
      "1752 [D loss: 0.145195]\n",
      "1753 [D loss: 0.138332]\n",
      "1754 [D loss: 0.142018]\n",
      "1755 [D loss: 0.145324]\n",
      "1756 [D loss: 0.133571]\n",
      "1757 [D loss: 0.139752]\n",
      "1758 [D loss: 0.131574]\n",
      "1759 [D loss: 0.137945]\n",
      "1760 [D loss: 0.140018]\n",
      "1761 [D loss: 0.140773]\n",
      "1762 [D loss: 0.140173]\n",
      "1763 [D loss: 0.138563]\n",
      "1764 [D loss: 0.135895]\n",
      "1765 [D loss: 0.130700]\n",
      "1766 [D loss: 0.130358]\n",
      "1767 [D loss: 0.153698]\n",
      "1768 [D loss: 0.142581]\n",
      "1769 [D loss: 0.156519]\n",
      "1770 [D loss: 0.134975]\n",
      "1771 [D loss: 0.137769]\n",
      "1772 [D loss: 0.135355]\n",
      "1773 [D loss: 0.130776]\n",
      "1774 [D loss: 0.133320]\n",
      "1775 [D loss: 0.135323]\n",
      "1776 [D loss: 0.143035]\n",
      "1777 [D loss: 0.137035]\n",
      "1778 [D loss: 0.140140]\n",
      "1779 [D loss: 0.149044]\n",
      "1780 [D loss: 0.135544]\n",
      "1781 [D loss: 0.132489]\n",
      "1782 [D loss: 0.144202]\n",
      "1783 [D loss: 0.149903]\n",
      "1784 [D loss: 0.141297]\n",
      "1785 [D loss: 0.135964]\n",
      "1786 [D loss: 0.143680]\n",
      "1787 [D loss: 0.140320]\n",
      "1788 [D loss: 0.133983]\n",
      "1789 [D loss: 0.130798]\n",
      "1790 [D loss: 0.141966]\n",
      "1791 [D loss: 0.148244]\n",
      "1792 [D loss: 0.143143]\n",
      "1793 [D loss: 0.152139]\n",
      "1794 [D loss: 0.158836]\n",
      "1795 [D loss: 0.144909]\n",
      "1796 [D loss: 0.141006]\n",
      "1797 [D loss: 0.133626]\n",
      "1798 [D loss: 0.133357]\n",
      "1799 [D loss: 0.149370]\n",
      "1800 [D loss: 0.136952]\n",
      "1801 [D loss: 0.147781]\n",
      "1802 [D loss: 0.145314]\n",
      "1803 [D loss: 0.128526]\n",
      "1804 [D loss: 0.134898]\n",
      "1805 [D loss: 0.148968]\n",
      "1806 [D loss: 0.134359]\n",
      "1807 [D loss: 0.147121]\n",
      "1808 [D loss: 0.135425]\n",
      "1809 [D loss: 0.143417]\n",
      "1810 [D loss: 0.133438]\n",
      "1811 [D loss: 0.151281]\n",
      "1812 [D loss: 0.132789]\n",
      "1813 [D loss: 0.144651]\n",
      "1814 [D loss: 0.128258]\n",
      "1815 [D loss: 0.129132]\n",
      "1816 [D loss: 0.133508]\n",
      "1817 [D loss: 0.136090]\n",
      "1818 [D loss: 0.148075]\n",
      "1819 [D loss: 0.132552]\n",
      "1820 [D loss: 0.133701]\n",
      "1821 [D loss: 0.132870]\n",
      "1822 [D loss: 0.145786]\n",
      "1823 [D loss: 0.134404]\n",
      "1824 [D loss: 0.132127]\n",
      "1825 [D loss: 0.138582]\n",
      "1826 [D loss: 0.135211]\n",
      "1827 [D loss: 0.146192]\n",
      "1828 [D loss: 0.134237]\n",
      "1829 [D loss: 0.142005]\n",
      "1830 [D loss: 0.140554]\n",
      "1831 [D loss: 0.137467]\n",
      "1832 [D loss: 0.137143]\n",
      "1833 [D loss: 0.138219]\n",
      "1834 [D loss: 0.132914]\n",
      "1835 [D loss: 0.145969]\n",
      "1836 [D loss: 0.132750]\n",
      "1837 [D loss: 0.123577]\n",
      "1838 [D loss: 0.133353]\n",
      "1839 [D loss: 0.127257]\n",
      "1840 [D loss: 0.135067]\n",
      "1841 [D loss: 0.144482]\n",
      "1842 [D loss: 0.125990]\n",
      "1843 [D loss: 0.129542]\n",
      "1844 [D loss: 0.139613]\n",
      "1845 [D loss: 0.128123]\n",
      "1846 [D loss: 0.135910]\n",
      "1847 [D loss: 0.129626]\n",
      "1848 [D loss: 0.145289]\n",
      "1849 [D loss: 0.131956]\n",
      "1850 [D loss: 0.166607]\n",
      "1851 [D loss: 0.130008]\n",
      "1852 [D loss: 0.143970]\n",
      "1853 [D loss: 0.130959]\n",
      "1854 [D loss: 0.139918]\n",
      "1855 [D loss: 0.147604]\n",
      "1856 [D loss: 0.131269]\n",
      "1857 [D loss: 0.125248]\n",
      "1858 [D loss: 0.144389]\n",
      "1859 [D loss: 0.128809]\n",
      "1860 [D loss: 0.132229]\n",
      "1861 [D loss: 0.122841]\n",
      "1862 [D loss: 0.135073]\n",
      "1863 [D loss: 0.127465]\n",
      "1864 [D loss: 0.132502]\n",
      "1865 [D loss: 0.133093]\n",
      "1866 [D loss: 0.130556]\n",
      "1867 [D loss: 0.127701]\n",
      "1868 [D loss: 0.135625]\n",
      "1869 [D loss: 0.139950]\n",
      "1870 [D loss: 0.149824]\n",
      "1871 [D loss: 0.131355]\n",
      "1872 [D loss: 0.134813]\n",
      "1873 [D loss: 0.127517]\n",
      "1874 [D loss: 0.134609]\n",
      "1875 [D loss: 0.247339]\n",
      "1876 [D loss: 0.135713]\n",
      "1877 [D loss: 0.138921]\n",
      "1878 [D loss: 0.122759]\n",
      "1879 [D loss: 0.131215]\n",
      "1880 [D loss: 0.136673]\n",
      "1881 [D loss: 0.129862]\n",
      "1882 [D loss: 0.142951]\n",
      "1883 [D loss: 0.134467]\n",
      "1884 [D loss: 0.130745]\n",
      "1885 [D loss: 0.126489]\n",
      "1886 [D loss: 0.143454]\n",
      "1887 [D loss: 0.125077]\n",
      "1888 [D loss: 0.129592]\n",
      "1889 [D loss: 0.125191]\n",
      "1890 [D loss: 0.121057]\n",
      "1891 [D loss: 0.136653]\n",
      "1892 [D loss: 0.128474]\n",
      "1893 [D loss: 0.129753]\n",
      "1894 [D loss: 0.129760]\n",
      "1895 [D loss: 0.137243]\n",
      "1896 [D loss: 0.143486]\n",
      "1897 [D loss: 0.127145]\n",
      "1898 [D loss: 0.122913]\n",
      "1899 [D loss: 0.124660]\n",
      "1900 [D loss: 0.124341]\n",
      "1901 [D loss: 0.130746]\n",
      "1902 [D loss: 0.124861]\n",
      "1903 [D loss: 0.123225]\n",
      "1904 [D loss: 0.139770]\n",
      "1905 [D loss: 0.124973]\n",
      "1906 [D loss: 0.141821]\n",
      "1907 [D loss: 0.132253]\n",
      "1908 [D loss: 0.141155]\n",
      "1909 [D loss: 0.142427]\n",
      "1910 [D loss: 0.131176]\n",
      "1911 [D loss: 0.143717]\n",
      "1912 [D loss: 0.129464]\n",
      "1913 [D loss: 0.123620]\n",
      "1914 [D loss: 0.139206]\n",
      "1915 [D loss: 0.131243]\n",
      "1916 [D loss: 0.137656]\n",
      "1917 [D loss: 0.142361]\n",
      "1918 [D loss: 0.143813]\n",
      "1919 [D loss: 0.126043]\n",
      "1920 [D loss: 0.128521]\n",
      "1921 [D loss: 0.135184]\n",
      "1922 [D loss: 0.148097]\n",
      "1923 [D loss: 0.122546]\n",
      "1924 [D loss: 0.129586]\n",
      "1925 [D loss: 0.124459]\n",
      "1926 [D loss: 0.126241]\n",
      "1927 [D loss: 0.131742]\n",
      "1928 [D loss: 0.128476]\n",
      "1929 [D loss: 0.127023]\n",
      "1930 [D loss: 0.129352]\n",
      "1931 [D loss: 0.145575]\n",
      "1932 [D loss: 0.123217]\n",
      "1933 [D loss: 0.140131]\n",
      "1934 [D loss: 0.126647]\n",
      "1935 [D loss: 0.127020]\n",
      "1936 [D loss: 0.136987]\n",
      "1937 [D loss: 0.123064]\n",
      "1938 [D loss: 0.122559]\n",
      "1939 [D loss: 0.136080]\n",
      "1940 [D loss: 0.129130]\n",
      "1941 [D loss: 0.132701]\n",
      "1942 [D loss: 0.118875]\n",
      "1943 [D loss: 0.126609]\n",
      "1944 [D loss: 0.125373]\n",
      "1945 [D loss: 0.127284]\n",
      "1946 [D loss: 0.125451]\n",
      "1947 [D loss: 0.120249]\n",
      "1948 [D loss: 0.142478]\n",
      "1949 [D loss: 0.122506]\n",
      "1950 [D loss: 0.120029]\n",
      "1951 [D loss: 0.120667]\n",
      "1952 [D loss: 0.135782]\n",
      "1953 [D loss: 0.122657]\n",
      "1954 [D loss: 0.129879]\n",
      "1955 [D loss: 0.125794]\n",
      "1956 [D loss: 0.118776]\n",
      "1957 [D loss: 0.119335]\n",
      "1958 [D loss: 0.115601]\n",
      "1959 [D loss: 0.125194]\n",
      "1960 [D loss: 0.122502]\n",
      "1961 [D loss: 0.124772]\n",
      "1962 [D loss: 0.124843]\n",
      "1963 [D loss: 0.123112]\n",
      "1964 [D loss: 0.129672]\n",
      "1965 [D loss: 0.118584]\n",
      "1966 [D loss: 0.125057]\n",
      "1967 [D loss: 0.128471]\n",
      "1968 [D loss: 0.119683]\n",
      "1969 [D loss: 0.124945]\n",
      "1970 [D loss: 0.125660]\n",
      "1971 [D loss: 0.119296]\n",
      "1972 [D loss: 0.121928]\n",
      "1973 [D loss: 0.130604]\n",
      "1974 [D loss: 0.119433]\n",
      "1975 [D loss: 0.121794]\n",
      "1976 [D loss: 0.116160]\n",
      "1977 [D loss: 0.124758]\n",
      "1978 [D loss: 0.122614]\n",
      "1979 [D loss: 0.124089]\n",
      "1980 [D loss: 0.122211]\n",
      "1981 [D loss: 0.123283]\n",
      "1982 [D loss: 0.123362]\n",
      "1983 [D loss: 0.115172]\n",
      "1984 [D loss: 0.118394]\n",
      "1985 [D loss: 0.118265]\n",
      "1986 [D loss: 0.120885]\n",
      "1987 [D loss: 0.122464]\n",
      "1988 [D loss: 0.132842]\n",
      "1989 [D loss: 0.123112]\n",
      "1990 [D loss: 0.121070]\n",
      "1991 [D loss: 0.122674]\n",
      "1992 [D loss: 0.126852]\n",
      "1993 [D loss: 0.127434]\n",
      "1994 [D loss: 0.144978]\n",
      "1995 [D loss: 0.121249]\n",
      "1996 [D loss: 0.122946]\n",
      "1997 [D loss: 0.119474]\n",
      "1998 [D loss: 0.122423]\n",
      "1999 [D loss: 0.120593]\n",
      "2000 [D loss: 0.127525]\n",
      "2001 [D loss: 0.129411]\n",
      "2002 [D loss: 0.117624]\n",
      "2003 [D loss: 0.131367]\n",
      "2004 [D loss: 0.164796]\n",
      "2005 [D loss: 0.126429]\n",
      "2006 [D loss: 0.125808]\n",
      "2007 [D loss: 0.120783]\n",
      "2008 [D loss: 0.126565]\n",
      "2009 [D loss: 0.118012]\n",
      "2010 [D loss: 0.125943]\n",
      "2011 [D loss: 0.120054]\n",
      "2012 [D loss: 0.118388]\n",
      "2013 [D loss: 0.123116]\n",
      "2014 [D loss: 0.121139]\n",
      "2015 [D loss: 0.129736]\n",
      "2016 [D loss: 0.118151]\n",
      "2017 [D loss: 0.125557]\n",
      "2018 [D loss: 0.120417]\n",
      "2019 [D loss: 0.116113]\n",
      "2020 [D loss: 0.118633]\n",
      "2021 [D loss: 0.115658]\n",
      "2022 [D loss: 0.137815]\n",
      "2023 [D loss: 0.127810]\n",
      "2024 [D loss: 0.196209]\n",
      "2025 [D loss: 0.115379]\n",
      "2026 [D loss: 0.126061]\n",
      "2027 [D loss: 0.124348]\n",
      "2028 [D loss: 0.118450]\n",
      "2029 [D loss: 0.118816]\n",
      "2030 [D loss: 0.114621]\n",
      "2031 [D loss: 0.132724]\n",
      "2032 [D loss: 0.127522]\n",
      "2033 [D loss: 0.114696]\n",
      "2034 [D loss: 0.124204]\n",
      "2035 [D loss: 0.118622]\n",
      "2036 [D loss: 0.121589]\n",
      "2037 [D loss: 0.123417]\n",
      "2038 [D loss: 0.116730]\n",
      "2039 [D loss: 0.132220]\n",
      "2040 [D loss: 0.117684]\n",
      "2041 [D loss: 0.115830]\n",
      "2042 [D loss: 0.119110]\n",
      "2043 [D loss: 0.131042]\n",
      "2044 [D loss: 0.126576]\n",
      "2045 [D loss: 0.216476]\n",
      "2046 [D loss: 0.127748]\n",
      "2047 [D loss: 0.114626]\n",
      "2048 [D loss: 0.124823]\n",
      "2049 [D loss: 0.118255]\n",
      "2050 [D loss: 0.118434]\n",
      "2051 [D loss: 0.125156]\n",
      "2052 [D loss: 0.117584]\n",
      "2053 [D loss: 0.122689]\n",
      "2054 [D loss: 0.112036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055 [D loss: 0.113704]\n",
      "2056 [D loss: 0.131793]\n",
      "2057 [D loss: 0.121421]\n",
      "2058 [D loss: 0.117584]\n",
      "2059 [D loss: 0.130651]\n",
      "2060 [D loss: 0.130534]\n",
      "2061 [D loss: 0.126701]\n",
      "2062 [D loss: 0.118520]\n",
      "2063 [D loss: 0.119789]\n",
      "2064 [D loss: 0.120922]\n",
      "2065 [D loss: 0.111520]\n",
      "2066 [D loss: 0.113853]\n",
      "2067 [D loss: 0.129886]\n",
      "2068 [D loss: 0.111952]\n",
      "2069 [D loss: 0.122714]\n",
      "2070 [D loss: 0.112466]\n",
      "2071 [D loss: 0.112289]\n",
      "2072 [D loss: 0.126785]\n",
      "2073 [D loss: 0.117215]\n",
      "2074 [D loss: 0.126566]\n",
      "2075 [D loss: 0.115612]\n",
      "2076 [D loss: 0.119097]\n",
      "2077 [D loss: 0.114297]\n",
      "2078 [D loss: 0.116598]\n",
      "2079 [D loss: 0.116808]\n",
      "2080 [D loss: 0.115695]\n",
      "2081 [D loss: 0.132155]\n",
      "2082 [D loss: 0.125988]\n",
      "2083 [D loss: 0.124806]\n",
      "2084 [D loss: 0.116805]\n",
      "2085 [D loss: 0.122999]\n",
      "2086 [D loss: 0.113583]\n",
      "2087 [D loss: 0.130351]\n",
      "2088 [D loss: 0.119271]\n",
      "2089 [D loss: 0.112186]\n",
      "2090 [D loss: 0.121044]\n",
      "2091 [D loss: 0.116867]\n",
      "2092 [D loss: 0.135394]\n",
      "2093 [D loss: 0.113575]\n",
      "2094 [D loss: 0.123381]\n",
      "2095 [D loss: 0.121722]\n",
      "2096 [D loss: 0.121713]\n",
      "2097 [D loss: 0.118660]\n",
      "2098 [D loss: 0.118657]\n",
      "2099 [D loss: 0.121381]\n",
      "2100 [D loss: 0.111017]\n",
      "2101 [D loss: 0.114795]\n",
      "2102 [D loss: 0.125167]\n",
      "2103 [D loss: 0.122410]\n",
      "2104 [D loss: 0.112757]\n",
      "2105 [D loss: 0.121932]\n",
      "2106 [D loss: 0.119358]\n",
      "2107 [D loss: 0.122051]\n",
      "2108 [D loss: 0.115702]\n",
      "2109 [D loss: 0.116664]\n",
      "2110 [D loss: 0.113260]\n",
      "2111 [D loss: 0.114612]\n",
      "2112 [D loss: 0.110735]\n",
      "2113 [D loss: 0.129505]\n",
      "2114 [D loss: 0.114445]\n",
      "2115 [D loss: 0.110510]\n",
      "2116 [D loss: 0.117749]\n",
      "2117 [D loss: 0.132097]\n",
      "2118 [D loss: 0.119411]\n",
      "2119 [D loss: 0.108892]\n",
      "2120 [D loss: 0.116782]\n",
      "2121 [D loss: 0.112691]\n",
      "2122 [D loss: 0.117237]\n",
      "2123 [D loss: 0.110782]\n",
      "2124 [D loss: 0.115183]\n",
      "2125 [D loss: 0.115974]\n",
      "2126 [D loss: 0.135329]\n",
      "2127 [D loss: 0.117930]\n",
      "2128 [D loss: 0.120538]\n",
      "2129 [D loss: 0.113290]\n",
      "2130 [D loss: 0.117183]\n",
      "2131 [D loss: 0.109498]\n",
      "2132 [D loss: 0.118382]\n",
      "2133 [D loss: 0.139487]\n",
      "2134 [D loss: 0.109620]\n",
      "2135 [D loss: 0.115235]\n",
      "2136 [D loss: 0.129547]\n",
      "2137 [D loss: 0.139605]\n",
      "2138 [D loss: 0.109816]\n",
      "2139 [D loss: 0.131019]\n",
      "2140 [D loss: 0.114370]\n",
      "2141 [D loss: 0.125234]\n",
      "2142 [D loss: 0.109657]\n",
      "2143 [D loss: 0.116361]\n",
      "2144 [D loss: 0.115734]\n",
      "2145 [D loss: 0.128184]\n",
      "2146 [D loss: 0.124638]\n",
      "2147 [D loss: 0.108411]\n",
      "2148 [D loss: 0.106020]\n",
      "2149 [D loss: 0.108748]\n",
      "2150 [D loss: 0.128070]\n",
      "2151 [D loss: 0.118002]\n",
      "2152 [D loss: 0.104398]\n",
      "2153 [D loss: 0.106228]\n",
      "2154 [D loss: 0.120537]\n",
      "2155 [D loss: 0.131151]\n",
      "2156 [D loss: 0.109561]\n",
      "2157 [D loss: 0.108925]\n",
      "2158 [D loss: 0.105238]\n",
      "2159 [D loss: 0.119902]\n",
      "2160 [D loss: 0.110488]\n",
      "2161 [D loss: 0.110919]\n",
      "2162 [D loss: 0.115572]\n",
      "2163 [D loss: 0.107467]\n",
      "2164 [D loss: 0.112367]\n",
      "2165 [D loss: 0.143411]\n",
      "2166 [D loss: 0.109498]\n",
      "2167 [D loss: 0.112645]\n",
      "2168 [D loss: 0.117020]\n",
      "2169 [D loss: 0.107089]\n",
      "2170 [D loss: 0.106817]\n",
      "2171 [D loss: 0.120047]\n",
      "2172 [D loss: 0.123556]\n",
      "2173 [D loss: 0.121187]\n",
      "2174 [D loss: 0.105801]\n",
      "2175 [D loss: 0.113418]\n",
      "2176 [D loss: 0.112570]\n",
      "2177 [D loss: 0.109456]\n",
      "2178 [D loss: 0.114732]\n",
      "2179 [D loss: 0.119152]\n",
      "2180 [D loss: 0.113276]\n",
      "2181 [D loss: 0.127300]\n",
      "2182 [D loss: 0.108765]\n",
      "2183 [D loss: 0.119482]\n",
      "2184 [D loss: 0.118409]\n",
      "2185 [D loss: 0.120838]\n",
      "2186 [D loss: 0.112582]\n",
      "2187 [D loss: 0.113900]\n",
      "2188 [D loss: 0.116716]\n",
      "2189 [D loss: 0.110760]\n",
      "2190 [D loss: 0.111747]\n",
      "2191 [D loss: 0.105874]\n",
      "2192 [D loss: 0.109255]\n",
      "2193 [D loss: 0.105611]\n",
      "2194 [D loss: 0.118650]\n",
      "2195 [D loss: 0.113482]\n",
      "2196 [D loss: 0.106272]\n",
      "2197 [D loss: 0.121273]\n",
      "2198 [D loss: 0.109613]\n",
      "2199 [D loss: 0.130867]\n",
      "2200 [D loss: 0.114229]\n",
      "2201 [D loss: 0.106492]\n",
      "2202 [D loss: 0.116814]\n",
      "2203 [D loss: 0.125144]\n",
      "2204 [D loss: 0.111463]\n",
      "2205 [D loss: 0.108472]\n",
      "2206 [D loss: 0.140718]\n",
      "2207 [D loss: 0.125155]\n",
      "2208 [D loss: 0.112514]\n",
      "2209 [D loss: 0.108812]\n",
      "2210 [D loss: 0.110325]\n",
      "2211 [D loss: 0.117074]\n",
      "2212 [D loss: 0.117133]\n",
      "2213 [D loss: 0.107027]\n",
      "2214 [D loss: 0.105142]\n",
      "2215 [D loss: 0.110751]\n",
      "2216 [D loss: 0.102403]\n",
      "2217 [D loss: 0.111903]\n",
      "2218 [D loss: 0.119475]\n",
      "2219 [D loss: 0.130441]\n",
      "2220 [D loss: 0.109692]\n",
      "2221 [D loss: 0.107896]\n",
      "2222 [D loss: 0.105281]\n",
      "2223 [D loss: 0.112711]\n",
      "2224 [D loss: 0.120267]\n",
      "2225 [D loss: 0.117388]\n",
      "2226 [D loss: 0.107033]\n",
      "2227 [D loss: 0.116141]\n",
      "2228 [D loss: 0.111535]\n",
      "2229 [D loss: 0.116401]\n",
      "2230 [D loss: 0.114732]\n",
      "2231 [D loss: 0.106036]\n",
      "2232 [D loss: 0.120722]\n",
      "2233 [D loss: 0.114608]\n",
      "2234 [D loss: 0.116327]\n",
      "2235 [D loss: 0.104033]\n",
      "2236 [D loss: 0.108690]\n",
      "2237 [D loss: 0.122202]\n",
      "2238 [D loss: 0.203303]\n",
      "2239 [D loss: 0.109674]\n",
      "2240 [D loss: 0.116991]\n",
      "2241 [D loss: 0.108271]\n",
      "2242 [D loss: 0.111988]\n",
      "2243 [D loss: 0.112626]\n",
      "2244 [D loss: 0.113114]\n",
      "2245 [D loss: 0.106126]\n",
      "2246 [D loss: 0.108329]\n",
      "2247 [D loss: 0.105024]\n",
      "2248 [D loss: 0.118306]\n",
      "2249 [D loss: 0.115694]\n",
      "2250 [D loss: 0.127182]\n",
      "2251 [D loss: 0.107678]\n",
      "2252 [D loss: 0.110727]\n",
      "2253 [D loss: 0.128304]\n",
      "2254 [D loss: 0.110604]\n",
      "2255 [D loss: 0.127549]\n",
      "2256 [D loss: 0.112224]\n",
      "2257 [D loss: 0.108355]\n",
      "2258 [D loss: 0.119581]\n",
      "2259 [D loss: 0.119168]\n",
      "2260 [D loss: 0.116853]\n",
      "2261 [D loss: 0.106748]\n",
      "2262 [D loss: 0.111090]\n",
      "2263 [D loss: 0.112264]\n",
      "2264 [D loss: 0.107273]\n",
      "2265 [D loss: 0.105056]\n",
      "2266 [D loss: 0.102756]\n",
      "2267 [D loss: 0.111695]\n",
      "2268 [D loss: 0.111799]\n",
      "2269 [D loss: 0.118500]\n",
      "2270 [D loss: 0.116617]\n",
      "2271 [D loss: 0.118234]\n",
      "2272 [D loss: 0.100747]\n",
      "2273 [D loss: 0.112925]\n",
      "2274 [D loss: 0.109869]\n",
      "2275 [D loss: 0.101758]\n",
      "2276 [D loss: 0.121440]\n",
      "2277 [D loss: 0.100474]\n",
      "2278 [D loss: 0.104400]\n",
      "2279 [D loss: 0.121942]\n",
      "2280 [D loss: 0.107991]\n",
      "2281 [D loss: 0.108219]\n",
      "2282 [D loss: 0.107534]\n",
      "2283 [D loss: 0.116674]\n",
      "2284 [D loss: 0.108532]\n",
      "2285 [D loss: 0.099443]\n",
      "2286 [D loss: 0.106142]\n",
      "2287 [D loss: 0.099814]\n",
      "2288 [D loss: 0.106168]\n",
      "2289 [D loss: 0.101217]\n",
      "2290 [D loss: 0.117775]\n",
      "2291 [D loss: 0.110596]\n",
      "2292 [D loss: 0.107907]\n",
      "2293 [D loss: 0.102652]\n",
      "2294 [D loss: 0.110104]\n",
      "2295 [D loss: 0.109746]\n",
      "2296 [D loss: 0.104908]\n",
      "2297 [D loss: 0.100888]\n",
      "2298 [D loss: 0.115966]\n",
      "2299 [D loss: 0.106832]\n",
      "2300 [D loss: 0.100389]\n",
      "2301 [D loss: 0.107209]\n",
      "2302 [D loss: 0.101766]\n",
      "2303 [D loss: 0.108544]\n",
      "2304 [D loss: 0.110182]\n",
      "2305 [D loss: 0.100540]\n",
      "2306 [D loss: 0.110024]\n",
      "2307 [D loss: 0.109222]\n",
      "2308 [D loss: 0.111905]\n",
      "2309 [D loss: 0.109903]\n",
      "2310 [D loss: 0.109627]\n",
      "2311 [D loss: 0.106210]\n",
      "2312 [D loss: 0.105549]\n",
      "2313 [D loss: 0.132943]\n",
      "2314 [D loss: 0.097366]\n",
      "2315 [D loss: 0.114078]\n",
      "2316 [D loss: 0.107310]\n",
      "2317 [D loss: 0.100691]\n",
      "2318 [D loss: 0.113070]\n",
      "2319 [D loss: 0.096418]\n",
      "2320 [D loss: 0.100821]\n",
      "2321 [D loss: 0.115961]\n",
      "2322 [D loss: 0.100933]\n",
      "2323 [D loss: 0.112421]\n",
      "2324 [D loss: 0.101695]\n",
      "2325 [D loss: 0.102267]\n",
      "2326 [D loss: 0.100464]\n",
      "2327 [D loss: 0.101227]\n",
      "2328 [D loss: 0.098113]\n",
      "2329 [D loss: 0.103987]\n",
      "2330 [D loss: 0.100308]\n",
      "2331 [D loss: 0.106192]\n",
      "2332 [D loss: 0.104169]\n",
      "2333 [D loss: 0.099879]\n",
      "2334 [D loss: 0.113483]\n",
      "2335 [D loss: 0.100814]\n",
      "2336 [D loss: 0.107691]\n",
      "2337 [D loss: 0.107549]\n",
      "2338 [D loss: 0.121783]\n",
      "2339 [D loss: 0.104815]\n",
      "2340 [D loss: 0.103384]\n",
      "2341 [D loss: 0.105190]\n",
      "2342 [D loss: 0.117383]\n",
      "2343 [D loss: 0.102854]\n",
      "2344 [D loss: 0.105569]\n",
      "2345 [D loss: 0.109432]\n",
      "2346 [D loss: 0.131559]\n",
      "2347 [D loss: 0.109187]\n",
      "2348 [D loss: 0.106865]\n",
      "2349 [D loss: 0.106567]\n",
      "2350 [D loss: 0.103318]\n",
      "2351 [D loss: 0.105366]\n",
      "2352 [D loss: 0.101584]\n",
      "2353 [D loss: 0.101842]\n",
      "2354 [D loss: 0.104250]\n",
      "2355 [D loss: 0.099676]\n",
      "2356 [D loss: 0.106131]\n",
      "2357 [D loss: 0.106090]\n",
      "2358 [D loss: 0.103362]\n",
      "2359 [D loss: 0.104310]\n",
      "2360 [D loss: 0.101697]\n",
      "2361 [D loss: 0.104553]\n",
      "2362 [D loss: 0.105151]\n",
      "2363 [D loss: 0.112228]\n",
      "2364 [D loss: 0.105497]\n",
      "2365 [D loss: 0.117127]\n",
      "2366 [D loss: 0.103903]\n",
      "2367 [D loss: 0.100685]\n",
      "2368 [D loss: 0.103903]\n",
      "2369 [D loss: 0.112268]\n",
      "2370 [D loss: 0.099944]\n",
      "2371 [D loss: 0.107134]\n",
      "2372 [D loss: 0.111064]\n",
      "2373 [D loss: 0.096947]\n",
      "2374 [D loss: 0.095896]\n",
      "2375 [D loss: 0.102087]\n",
      "2376 [D loss: 0.100243]\n",
      "2377 [D loss: 0.105305]\n",
      "2378 [D loss: 0.107088]\n",
      "2379 [D loss: 0.097139]\n",
      "2380 [D loss: 0.100187]\n",
      "2381 [D loss: 0.103091]\n",
      "2382 [D loss: 0.110083]\n",
      "2383 [D loss: 0.119215]\n",
      "2384 [D loss: 0.113000]\n",
      "2385 [D loss: 0.103323]\n",
      "2386 [D loss: 0.171355]\n",
      "2387 [D loss: 0.097525]\n",
      "2388 [D loss: 0.097873]\n",
      "2389 [D loss: 0.107775]\n",
      "2390 [D loss: 0.100826]\n",
      "2391 [D loss: 0.097850]\n",
      "2392 [D loss: 0.102604]\n",
      "2393 [D loss: 0.103381]\n",
      "2394 [D loss: 0.099308]\n",
      "2395 [D loss: 0.094510]\n",
      "2396 [D loss: 0.101761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397 [D loss: 0.130790]\n",
      "2398 [D loss: 0.101592]\n",
      "2399 [D loss: 0.107966]\n",
      "2400 [D loss: 0.098641]\n",
      "2401 [D loss: 0.099400]\n",
      "2402 [D loss: 0.097981]\n",
      "2403 [D loss: 0.107094]\n",
      "2404 [D loss: 0.112917]\n",
      "2405 [D loss: 0.091395]\n",
      "2406 [D loss: 0.099571]\n",
      "2407 [D loss: 0.099022]\n",
      "2408 [D loss: 0.114232]\n",
      "2409 [D loss: 0.106024]\n",
      "2410 [D loss: 0.101333]\n",
      "2411 [D loss: 0.097362]\n",
      "2412 [D loss: 0.099492]\n",
      "2413 [D loss: 0.112058]\n",
      "2414 [D loss: 0.095442]\n",
      "2415 [D loss: 0.099899]\n",
      "2416 [D loss: 0.099182]\n",
      "2417 [D loss: 0.093898]\n",
      "2418 [D loss: 0.100472]\n",
      "2419 [D loss: 0.099622]\n",
      "2420 [D loss: 0.092038]\n",
      "2421 [D loss: 0.100227]\n",
      "2422 [D loss: 0.095083]\n",
      "2423 [D loss: 0.109372]\n",
      "2424 [D loss: 0.089432]\n",
      "2425 [D loss: 0.097257]\n",
      "2426 [D loss: 0.100823]\n",
      "2427 [D loss: 0.106844]\n",
      "2428 [D loss: 0.097385]\n",
      "2429 [D loss: 0.099787]\n",
      "2430 [D loss: 0.102010]\n",
      "2431 [D loss: 0.107122]\n",
      "2432 [D loss: 0.108288]\n",
      "2433 [D loss: 0.094870]\n",
      "2434 [D loss: 0.100347]\n",
      "2435 [D loss: 0.156498]\n",
      "2436 [D loss: 0.097250]\n",
      "2437 [D loss: 0.091604]\n",
      "2438 [D loss: 0.095581]\n",
      "2439 [D loss: 0.095784]\n",
      "2440 [D loss: 0.106120]\n",
      "2441 [D loss: 0.103656]\n",
      "2442 [D loss: 0.098649]\n",
      "2443 [D loss: 0.097704]\n",
      "2444 [D loss: 0.092514]\n",
      "2445 [D loss: 0.095641]\n",
      "2446 [D loss: 0.100424]\n",
      "2447 [D loss: 0.100529]\n",
      "2448 [D loss: 0.097632]\n",
      "2449 [D loss: 0.099216]\n",
      "2450 [D loss: 0.106187]\n",
      "2451 [D loss: 0.106014]\n",
      "2452 [D loss: 0.117361]\n",
      "2453 [D loss: 0.092728]\n",
      "2454 [D loss: 0.092996]\n",
      "2455 [D loss: 0.110412]\n",
      "2456 [D loss: 0.100800]\n",
      "2457 [D loss: 0.115597]\n",
      "2458 [D loss: 0.095110]\n",
      "2459 [D loss: 0.106979]\n",
      "2460 [D loss: 0.099161]\n",
      "2461 [D loss: 0.097747]\n",
      "2462 [D loss: 0.104629]\n",
      "2463 [D loss: 0.097488]\n",
      "2464 [D loss: 0.103912]\n",
      "2465 [D loss: 0.091574]\n",
      "2466 [D loss: 0.098616]\n",
      "2467 [D loss: 0.097565]\n",
      "2468 [D loss: 0.100344]\n",
      "2469 [D loss: 0.099601]\n",
      "2470 [D loss: 0.107026]\n",
      "2471 [D loss: 0.099403]\n",
      "2472 [D loss: 0.094284]\n",
      "2473 [D loss: 0.127059]\n",
      "2474 [D loss: 0.090499]\n",
      "2475 [D loss: 0.103213]\n",
      "2476 [D loss: 0.110505]\n",
      "2477 [D loss: 0.114698]\n",
      "2478 [D loss: 0.091307]\n",
      "2479 [D loss: 0.093879]\n",
      "2480 [D loss: 0.109357]\n",
      "2481 [D loss: 0.101929]\n",
      "2482 [D loss: 0.096395]\n",
      "2483 [D loss: 0.092291]\n",
      "2484 [D loss: 0.095852]\n",
      "2485 [D loss: 0.100597]\n",
      "2486 [D loss: 0.095800]\n",
      "2487 [D loss: 0.098741]\n",
      "2488 [D loss: 0.091301]\n",
      "2489 [D loss: 0.103731]\n",
      "2490 [D loss: 0.107615]\n",
      "2491 [D loss: 0.102383]\n",
      "2492 [D loss: 0.093880]\n",
      "2493 [D loss: 0.106090]\n",
      "2494 [D loss: 0.093305]\n",
      "2495 [D loss: 0.109042]\n",
      "2496 [D loss: 0.096868]\n",
      "2497 [D loss: 0.107711]\n",
      "2498 [D loss: 0.093223]\n",
      "2499 [D loss: 0.104527]\n",
      "2500 [D loss: 0.099557]\n",
      "2501 [D loss: 0.095991]\n",
      "2502 [D loss: 0.096483]\n",
      "2503 [D loss: 0.095013]\n",
      "2504 [D loss: 0.094445]\n",
      "2505 [D loss: 0.096903]\n",
      "2506 [D loss: 0.108406]\n",
      "2507 [D loss: 0.097598]\n",
      "2508 [D loss: 0.092638]\n",
      "2509 [D loss: 0.102409]\n",
      "2510 [D loss: 0.090217]\n",
      "2511 [D loss: 0.103709]\n",
      "2512 [D loss: 0.095967]\n",
      "2513 [D loss: 0.105047]\n",
      "2514 [D loss: 0.091582]\n",
      "2515 [D loss: 0.110160]\n",
      "2516 [D loss: 0.103675]\n",
      "2517 [D loss: 0.099486]\n",
      "2518 [D loss: 0.088611]\n",
      "2519 [D loss: 0.090556]\n",
      "2520 [D loss: 0.105913]\n",
      "2521 [D loss: 0.095091]\n",
      "2522 [D loss: 0.093026]\n",
      "2523 [D loss: 0.086198]\n",
      "2524 [D loss: 0.096693]\n",
      "2525 [D loss: 0.095449]\n",
      "2526 [D loss: 0.089890]\n",
      "2527 [D loss: 0.101942]\n",
      "2528 [D loss: 0.099358]\n",
      "2529 [D loss: 0.093149]\n",
      "2530 [D loss: 0.092362]\n",
      "2531 [D loss: 0.108763]\n",
      "2532 [D loss: 0.100824]\n",
      "2533 [D loss: 0.093440]\n",
      "2534 [D loss: 0.093423]\n",
      "2535 [D loss: 0.116595]\n",
      "2536 [D loss: 0.099091]\n",
      "2537 [D loss: 0.090260]\n",
      "2538 [D loss: 0.093036]\n",
      "2539 [D loss: 0.107018]\n",
      "2540 [D loss: 0.098090]\n",
      "2541 [D loss: 0.093680]\n",
      "2542 [D loss: 0.094372]\n",
      "2543 [D loss: 0.095551]\n",
      "2544 [D loss: 0.086584]\n",
      "2545 [D loss: 0.092586]\n",
      "2546 [D loss: 0.096771]\n",
      "2547 [D loss: 0.099306]\n",
      "2548 [D loss: 0.108953]\n",
      "2549 [D loss: 0.122931]\n",
      "2550 [D loss: 0.089895]\n",
      "2551 [D loss: 0.119553]\n",
      "2552 [D loss: 0.094262]\n",
      "2553 [D loss: 0.089786]\n",
      "2554 [D loss: 0.095524]\n",
      "2555 [D loss: 0.093726]\n",
      "2556 [D loss: 0.103446]\n",
      "2557 [D loss: 0.095771]\n",
      "2558 [D loss: 0.108923]\n",
      "2559 [D loss: 0.100779]\n",
      "2560 [D loss: 0.093606]\n",
      "2561 [D loss: 0.101007]\n",
      "2562 [D loss: 0.090441]\n",
      "2563 [D loss: 0.093394]\n",
      "2564 [D loss: 0.093327]\n",
      "2565 [D loss: 0.099120]\n",
      "2566 [D loss: 0.093068]\n",
      "2567 [D loss: 0.106038]\n",
      "2568 [D loss: 0.103429]\n",
      "2569 [D loss: 0.090743]\n",
      "2570 [D loss: 0.092336]\n",
      "2571 [D loss: 0.093476]\n",
      "2572 [D loss: 0.116922]\n",
      "2573 [D loss: 0.087909]\n",
      "2574 [D loss: 0.089806]\n",
      "2575 [D loss: 0.100841]\n",
      "2576 [D loss: 0.089218]\n",
      "2577 [D loss: 0.093791]\n",
      "2578 [D loss: 0.100802]\n",
      "2579 [D loss: 0.098490]\n",
      "2580 [D loss: 0.096517]\n",
      "2581 [D loss: 0.090733]\n",
      "2582 [D loss: 0.088167]\n",
      "2583 [D loss: 0.118132]\n",
      "2584 [D loss: 0.105638]\n",
      "2585 [D loss: 0.089292]\n",
      "2586 [D loss: 0.098372]\n",
      "2587 [D loss: 0.090789]\n",
      "2588 [D loss: 0.090390]\n",
      "2589 [D loss: 0.089383]\n",
      "2590 [D loss: 0.085107]\n",
      "2591 [D loss: 0.097472]\n",
      "2592 [D loss: 0.088630]\n",
      "2593 [D loss: 0.092213]\n",
      "2594 [D loss: 0.093191]\n",
      "2595 [D loss: 0.094762]\n",
      "2596 [D loss: 0.088414]\n",
      "2597 [D loss: 0.097202]\n",
      "2598 [D loss: 0.111362]\n",
      "2599 [D loss: 0.089814]\n",
      "2600 [D loss: 0.091147]\n",
      "2601 [D loss: 0.094166]\n",
      "2602 [D loss: 0.099358]\n",
      "2603 [D loss: 0.098891]\n",
      "2604 [D loss: 0.091984]\n",
      "2605 [D loss: 0.092816]\n",
      "2606 [D loss: 0.098109]\n",
      "2607 [D loss: 0.087082]\n",
      "2608 [D loss: 0.103576]\n",
      "2609 [D loss: 0.112764]\n",
      "2610 [D loss: 0.092841]\n",
      "2611 [D loss: 0.086617]\n",
      "2612 [D loss: 0.087216]\n",
      "2613 [D loss: 0.094061]\n",
      "2614 [D loss: 0.089397]\n",
      "2615 [D loss: 0.092571]\n",
      "2616 [D loss: 0.111764]\n",
      "2617 [D loss: 0.091823]\n",
      "2618 [D loss: 0.100532]\n",
      "2619 [D loss: 0.098803]\n",
      "2620 [D loss: 0.097501]\n",
      "2621 [D loss: 0.100128]\n",
      "2622 [D loss: 0.101316]\n",
      "2623 [D loss: 0.092917]\n",
      "2624 [D loss: 0.088305]\n",
      "2625 [D loss: 0.086411]\n",
      "2626 [D loss: 0.097880]\n",
      "2627 [D loss: 0.095047]\n",
      "2628 [D loss: 0.095465]\n",
      "2629 [D loss: 0.086390]\n",
      "2630 [D loss: 0.099963]\n",
      "2631 [D loss: 0.086081]\n",
      "2632 [D loss: 0.095178]\n",
      "2633 [D loss: 0.102849]\n",
      "2634 [D loss: 0.092173]\n",
      "2635 [D loss: 0.097555]\n",
      "2636 [D loss: 0.102960]\n",
      "2637 [D loss: 0.090958]\n",
      "2638 [D loss: 0.089868]\n",
      "2639 [D loss: 0.088766]\n",
      "2640 [D loss: 0.094246]\n",
      "2641 [D loss: 0.086902]\n",
      "2642 [D loss: 0.091927]\n",
      "2643 [D loss: 0.089264]\n",
      "2644 [D loss: 0.097691]\n",
      "2645 [D loss: 0.089816]\n",
      "2646 [D loss: 0.094595]\n",
      "2647 [D loss: 0.100305]\n",
      "2648 [D loss: 0.085807]\n",
      "2649 [D loss: 0.095757]\n",
      "2650 [D loss: 0.090188]\n",
      "2651 [D loss: 0.094872]\n",
      "2652 [D loss: 0.083179]\n",
      "2653 [D loss: 0.185286]\n",
      "2654 [D loss: 0.098699]\n",
      "2655 [D loss: 0.090672]\n",
      "2656 [D loss: 0.099997]\n",
      "2657 [D loss: 0.083859]\n",
      "2658 [D loss: 0.087846]\n",
      "2659 [D loss: 0.087093]\n",
      "2660 [D loss: 0.090995]\n",
      "2661 [D loss: 0.099187]\n",
      "2662 [D loss: 0.090920]\n",
      "2663 [D loss: 0.097330]\n",
      "2664 [D loss: 0.096835]\n",
      "2665 [D loss: 0.103660]\n",
      "2666 [D loss: 0.082286]\n",
      "2667 [D loss: 0.090874]\n",
      "2668 [D loss: 0.082532]\n",
      "2669 [D loss: 0.093828]\n",
      "2670 [D loss: 0.097520]\n",
      "2671 [D loss: 0.089643]\n",
      "2672 [D loss: 0.107470]\n",
      "2673 [D loss: 0.100882]\n",
      "2674 [D loss: 0.096207]\n",
      "2675 [D loss: 0.088830]\n",
      "2676 [D loss: 0.099113]\n",
      "2677 [D loss: 0.092825]\n",
      "2678 [D loss: 0.098744]\n",
      "2679 [D loss: 0.099272]\n",
      "2680 [D loss: 0.087519]\n",
      "2681 [D loss: 0.086751]\n",
      "2682 [D loss: 0.100772]\n",
      "2683 [D loss: 0.090368]\n",
      "2684 [D loss: 0.087722]\n",
      "2685 [D loss: 0.084806]\n",
      "2686 [D loss: 0.088511]\n",
      "2687 [D loss: 0.089893]\n",
      "2688 [D loss: 0.095636]\n",
      "2689 [D loss: 0.085390]\n",
      "2690 [D loss: 0.094024]\n",
      "2691 [D loss: 0.108815]\n",
      "2692 [D loss: 0.083030]\n",
      "2693 [D loss: 0.094557]\n",
      "2694 [D loss: 0.088435]\n",
      "2695 [D loss: 0.095173]\n",
      "2696 [D loss: 0.085577]\n",
      "2697 [D loss: 0.124214]\n",
      "2698 [D loss: 0.090025]\n",
      "2699 [D loss: 0.091233]\n",
      "2700 [D loss: 0.084959]\n",
      "2701 [D loss: 0.092449]\n",
      "2702 [D loss: 0.083850]\n",
      "2703 [D loss: 0.089483]\n",
      "2704 [D loss: 0.089729]\n",
      "2705 [D loss: 0.086350]\n",
      "2706 [D loss: 0.088112]\n",
      "2707 [D loss: 0.083792]\n",
      "2708 [D loss: 0.082099]\n",
      "2709 [D loss: 0.086903]\n",
      "2710 [D loss: 0.085435]\n",
      "2711 [D loss: 0.093403]\n",
      "2712 [D loss: 0.085149]\n",
      "2713 [D loss: 0.101403]\n",
      "2714 [D loss: 0.101364]\n",
      "2715 [D loss: 0.092383]\n",
      "2716 [D loss: 0.086647]\n",
      "2717 [D loss: 0.092297]\n",
      "2718 [D loss: 0.089872]\n",
      "2719 [D loss: 0.084947]\n",
      "2720 [D loss: 0.090539]\n",
      "2721 [D loss: 0.081660]\n",
      "2722 [D loss: 0.087707]\n",
      "2723 [D loss: 0.086650]\n",
      "2724 [D loss: 0.089395]\n",
      "2725 [D loss: 0.098697]\n",
      "2726 [D loss: 0.082172]\n",
      "2727 [D loss: 0.104907]\n",
      "2728 [D loss: 0.091678]\n",
      "2729 [D loss: 0.086116]\n",
      "2730 [D loss: 0.083131]\n",
      "2731 [D loss: 0.090193]\n",
      "2732 [D loss: 0.094539]\n",
      "2733 [D loss: 0.115175]\n",
      "2734 [D loss: 0.083943]\n",
      "2735 [D loss: 0.085863]\n",
      "2736 [D loss: 0.085868]\n",
      "2737 [D loss: 0.089143]\n",
      "2738 [D loss: 0.095132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739 [D loss: 0.087376]\n",
      "2740 [D loss: 0.087921]\n",
      "2741 [D loss: 0.085179]\n",
      "2742 [D loss: 0.093956]\n",
      "2743 [D loss: 0.095700]\n",
      "2744 [D loss: 0.084828]\n",
      "2745 [D loss: 0.092068]\n",
      "2746 [D loss: 0.108109]\n",
      "2747 [D loss: 0.091764]\n",
      "2748 [D loss: 0.089959]\n",
      "2749 [D loss: 0.094359]\n",
      "2750 [D loss: 0.089328]\n",
      "2751 [D loss: 0.094382]\n",
      "2752 [D loss: 0.093653]\n",
      "2753 [D loss: 0.078456]\n",
      "2754 [D loss: 0.086518]\n",
      "2755 [D loss: 0.085249]\n",
      "2756 [D loss: 0.083401]\n",
      "2757 [D loss: 0.100475]\n",
      "2758 [D loss: 0.096003]\n",
      "2759 [D loss: 0.082706]\n",
      "2760 [D loss: 0.129122]\n",
      "2761 [D loss: 0.083108]\n",
      "2762 [D loss: 0.079806]\n",
      "2763 [D loss: 0.085056]\n",
      "2764 [D loss: 0.096065]\n",
      "2765 [D loss: 0.092121]\n",
      "2766 [D loss: 0.095020]\n",
      "2767 [D loss: 0.082395]\n",
      "2768 [D loss: 0.082772]\n",
      "2769 [D loss: 0.089564]\n",
      "2770 [D loss: 0.089297]\n",
      "2771 [D loss: 0.085790]\n",
      "2772 [D loss: 0.102006]\n",
      "2773 [D loss: 0.085879]\n",
      "2774 [D loss: 0.090611]\n",
      "2775 [D loss: 0.138562]\n",
      "2776 [D loss: 0.098809]\n",
      "2777 [D loss: 0.085164]\n",
      "2778 [D loss: 0.106259]\n",
      "2779 [D loss: 0.098825]\n",
      "2780 [D loss: 0.087599]\n",
      "2781 [D loss: 0.087280]\n",
      "2782 [D loss: 0.084820]\n",
      "2783 [D loss: 0.085003]\n",
      "2784 [D loss: 0.096060]\n",
      "2785 [D loss: 0.099202]\n",
      "2786 [D loss: 0.089913]\n",
      "2787 [D loss: 0.085719]\n",
      "2788 [D loss: 0.096161]\n",
      "2789 [D loss: 0.103063]\n",
      "2790 [D loss: 0.084767]\n",
      "2791 [D loss: 0.088679]\n",
      "2792 [D loss: 0.083154]\n",
      "2793 [D loss: 0.098764]\n",
      "2794 [D loss: 0.081602]\n",
      "2795 [D loss: 0.087767]\n",
      "2796 [D loss: 0.082398]\n",
      "2797 [D loss: 0.085231]\n",
      "2798 [D loss: 0.086226]\n",
      "2799 [D loss: 0.083775]\n",
      "2800 [D loss: 0.100306]\n",
      "2801 [D loss: 0.081465]\n",
      "2802 [D loss: 0.087811]\n",
      "2803 [D loss: 0.086013]\n",
      "2804 [D loss: 0.089946]\n",
      "2805 [D loss: 0.080755]\n",
      "2806 [D loss: 0.079989]\n",
      "2807 [D loss: 0.083178]\n",
      "2808 [D loss: 0.087943]\n",
      "2809 [D loss: 0.081019]\n",
      "2810 [D loss: 0.086351]\n",
      "2811 [D loss: 0.093164]\n",
      "2812 [D loss: 0.095333]\n",
      "2813 [D loss: 0.095776]\n",
      "2814 [D loss: 0.090532]\n",
      "2815 [D loss: 0.083831]\n",
      "2816 [D loss: 0.087501]\n",
      "2817 [D loss: 0.081248]\n",
      "2818 [D loss: 0.083761]\n",
      "2819 [D loss: 0.082478]\n",
      "2820 [D loss: 0.084878]\n",
      "2821 [D loss: 0.099466]\n",
      "2822 [D loss: 0.100641]\n",
      "2823 [D loss: 0.077956]\n",
      "2824 [D loss: 0.086319]\n",
      "2825 [D loss: 0.087682]\n",
      "2826 [D loss: 0.088098]\n",
      "2827 [D loss: 0.079898]\n",
      "2828 [D loss: 0.091395]\n",
      "2829 [D loss: 0.085169]\n",
      "2830 [D loss: 0.085124]\n",
      "2831 [D loss: 0.088482]\n",
      "2832 [D loss: 0.085345]\n",
      "2833 [D loss: 0.091390]\n",
      "2834 [D loss: 0.079989]\n",
      "2835 [D loss: 0.094319]\n",
      "2836 [D loss: 0.079429]\n",
      "2837 [D loss: 0.102058]\n",
      "2838 [D loss: 0.082073]\n",
      "2839 [D loss: 0.089621]\n",
      "2840 [D loss: 0.083146]\n",
      "2841 [D loss: 0.083342]\n",
      "2842 [D loss: 0.086175]\n",
      "2843 [D loss: 0.094274]\n",
      "2844 [D loss: 0.083789]\n",
      "2845 [D loss: 0.083463]\n",
      "2846 [D loss: 0.095309]\n",
      "2847 [D loss: 0.080763]\n",
      "2848 [D loss: 0.081839]\n",
      "2849 [D loss: 0.080902]\n",
      "2850 [D loss: 0.083823]\n",
      "2851 [D loss: 0.087306]\n",
      "2852 [D loss: 0.089864]\n",
      "2853 [D loss: 0.086554]\n",
      "2854 [D loss: 0.083345]\n",
      "2855 [D loss: 0.088878]\n",
      "2856 [D loss: 0.094647]\n",
      "2857 [D loss: 0.079565]\n",
      "2858 [D loss: 0.092483]\n",
      "2859 [D loss: 0.092567]\n",
      "2860 [D loss: 0.082059]\n",
      "2861 [D loss: 0.085801]\n",
      "2862 [D loss: 0.087769]\n",
      "2863 [D loss: 0.081830]\n",
      "2864 [D loss: 0.077575]\n",
      "2865 [D loss: 0.083803]\n",
      "2866 [D loss: 0.082365]\n",
      "2867 [D loss: 0.090790]\n",
      "2868 [D loss: 0.076499]\n",
      "2869 [D loss: 0.084539]\n",
      "2870 [D loss: 0.079022]\n",
      "2871 [D loss: 0.087041]\n",
      "2872 [D loss: 0.095875]\n",
      "2873 [D loss: 0.087747]\n",
      "2874 [D loss: 0.088918]\n",
      "2875 [D loss: 0.080255]\n",
      "2876 [D loss: 0.086523]\n",
      "2877 [D loss: 0.097548]\n",
      "2878 [D loss: 0.081000]\n",
      "2879 [D loss: 0.080699]\n",
      "2880 [D loss: 0.083271]\n",
      "2881 [D loss: 0.084878]\n",
      "2882 [D loss: 0.089406]\n",
      "2883 [D loss: 0.084607]\n",
      "2884 [D loss: 0.082308]\n",
      "2885 [D loss: 0.083369]\n",
      "2886 [D loss: 0.081992]\n",
      "2887 [D loss: 0.076210]\n",
      "2888 [D loss: 0.094113]\n",
      "2889 [D loss: 0.079090]\n",
      "2890 [D loss: 0.082645]\n",
      "2891 [D loss: 0.089458]\n",
      "2892 [D loss: 0.082793]\n",
      "2893 [D loss: 0.078754]\n",
      "2894 [D loss: 0.091933]\n",
      "2895 [D loss: 0.084509]\n",
      "2896 [D loss: 0.086996]\n",
      "2897 [D loss: 0.092250]\n",
      "2898 [D loss: 0.079052]\n",
      "2899 [D loss: 0.091620]\n",
      "2900 [D loss: 0.092059]\n",
      "2901 [D loss: 0.085243]\n",
      "2902 [D loss: 0.104157]\n",
      "2903 [D loss: 0.091533]\n",
      "2904 [D loss: 0.091866]\n",
      "2905 [D loss: 0.085012]\n",
      "2906 [D loss: 0.077672]\n",
      "2907 [D loss: 0.081184]\n",
      "2908 [D loss: 0.079168]\n",
      "2909 [D loss: 0.092411]\n",
      "2910 [D loss: 0.082661]\n",
      "2911 [D loss: 0.081451]\n",
      "2912 [D loss: 0.078551]\n",
      "2913 [D loss: 0.082176]\n",
      "2914 [D loss: 0.078970]\n",
      "2915 [D loss: 0.080899]\n",
      "2916 [D loss: 0.089979]\n",
      "2917 [D loss: 0.091861]\n",
      "2918 [D loss: 0.087125]\n",
      "2919 [D loss: 0.099623]\n",
      "2920 [D loss: 0.078594]\n",
      "2921 [D loss: 0.077334]\n",
      "2922 [D loss: 0.153944]\n",
      "2923 [D loss: 0.080327]\n",
      "2924 [D loss: 0.078763]\n",
      "2925 [D loss: 0.086512]\n",
      "2926 [D loss: 0.075490]\n",
      "2927 [D loss: 0.086023]\n",
      "2928 [D loss: 0.084468]\n",
      "2929 [D loss: 0.076784]\n",
      "2930 [D loss: 0.078778]\n",
      "2931 [D loss: 0.086988]\n",
      "2932 [D loss: 0.089285]\n",
      "2933 [D loss: 0.082148]\n",
      "2934 [D loss: 0.083444]\n",
      "2935 [D loss: 0.083619]\n",
      "2936 [D loss: 0.088053]\n",
      "2937 [D loss: 0.084807]\n",
      "2938 [D loss: 0.088148]\n",
      "2939 [D loss: 0.108239]\n",
      "2940 [D loss: 0.087115]\n",
      "2941 [D loss: 0.077632]\n",
      "2942 [D loss: 0.092384]\n",
      "2943 [D loss: 0.077259]\n",
      "2944 [D loss: 0.085389]\n",
      "2945 [D loss: 0.089084]\n",
      "2946 [D loss: 0.076863]\n",
      "2947 [D loss: 0.122737]\n",
      "2948 [D loss: 0.077530]\n",
      "2949 [D loss: 0.101148]\n",
      "2950 [D loss: 0.082704]\n",
      "2951 [D loss: 0.085688]\n",
      "2952 [D loss: 0.078190]\n",
      "2953 [D loss: 0.083329]\n",
      "2954 [D loss: 0.075391]\n",
      "2955 [D loss: 0.082792]\n",
      "2956 [D loss: 0.080511]\n",
      "2957 [D loss: 0.092598]\n",
      "2958 [D loss: 0.101274]\n",
      "2959 [D loss: 0.094490]\n",
      "2960 [D loss: 0.085766]\n",
      "2961 [D loss: 0.092712]\n",
      "2962 [D loss: 0.080445]\n",
      "2963 [D loss: 0.102707]\n",
      "2964 [D loss: 0.078505]\n",
      "2965 [D loss: 0.081125]\n",
      "2966 [D loss: 0.131291]\n",
      "2967 [D loss: 0.084542]\n",
      "2968 [D loss: 0.089806]\n",
      "2969 [D loss: 0.083044]\n",
      "2970 [D loss: 0.078152]\n",
      "2971 [D loss: 0.077539]\n",
      "2972 [D loss: 0.080949]\n",
      "2973 [D loss: 0.081620]\n",
      "2974 [D loss: 0.082875]\n",
      "2975 [D loss: 0.082997]\n",
      "2976 [D loss: 0.095530]\n",
      "2977 [D loss: 0.094181]\n",
      "2978 [D loss: 0.085216]\n",
      "2979 [D loss: 0.082458]\n",
      "2980 [D loss: 0.083796]\n",
      "2981 [D loss: 0.076676]\n",
      "2982 [D loss: 0.081841]\n",
      "2983 [D loss: 0.081760]\n",
      "2984 [D loss: 0.079100]\n",
      "2985 [D loss: 0.081234]\n",
      "2986 [D loss: 0.077492]\n",
      "2987 [D loss: 0.080302]\n",
      "2988 [D loss: 0.076782]\n",
      "2989 [D loss: 0.077921]\n",
      "2990 [D loss: 0.087769]\n",
      "2991 [D loss: 0.081204]\n",
      "2992 [D loss: 0.083516]\n",
      "2993 [D loss: 0.085368]\n",
      "2994 [D loss: 0.087119]\n",
      "2995 [D loss: 0.081112]\n",
      "2996 [D loss: 0.078932]\n",
      "2997 [D loss: 0.079044]\n",
      "2998 [D loss: 0.085216]\n",
      "2999 [D loss: 0.077518]\n",
      "3000 [D loss: 0.076474]\n",
      "3001 [D loss: 0.079688]\n",
      "3002 [D loss: 0.094506]\n",
      "3003 [D loss: 0.091626]\n",
      "3004 [D loss: 0.081704]\n",
      "3005 [D loss: 0.083572]\n",
      "3006 [D loss: 0.075676]\n",
      "3007 [D loss: 0.083349]\n",
      "3008 [D loss: 0.106331]\n",
      "3009 [D loss: 0.088448]\n",
      "3010 [D loss: 0.075140]\n",
      "3011 [D loss: 0.074386]\n",
      "3012 [D loss: 0.080654]\n",
      "3013 [D loss: 0.091612]\n",
      "3014 [D loss: 0.075710]\n",
      "3015 [D loss: 0.086055]\n",
      "3016 [D loss: 0.079138]\n",
      "3017 [D loss: 0.079988]\n",
      "3018 [D loss: 0.104265]\n",
      "3019 [D loss: 0.076947]\n",
      "3020 [D loss: 0.073741]\n",
      "3021 [D loss: 0.084273]\n",
      "3022 [D loss: 0.086158]\n",
      "3023 [D loss: 0.074030]\n",
      "3024 [D loss: 0.100253]\n",
      "3025 [D loss: 0.075591]\n",
      "3026 [D loss: 0.082378]\n",
      "3027 [D loss: 0.081959]\n",
      "3028 [D loss: 0.082686]\n",
      "3029 [D loss: 0.079704]\n",
      "3030 [D loss: 0.082912]\n",
      "3031 [D loss: 0.090191]\n",
      "3032 [D loss: 0.077274]\n",
      "3033 [D loss: 0.081953]\n",
      "3034 [D loss: 0.085230]\n",
      "3035 [D loss: 0.070678]\n",
      "3036 [D loss: 0.071838]\n",
      "3037 [D loss: 0.076953]\n",
      "3038 [D loss: 0.095803]\n",
      "3039 [D loss: 0.073895]\n",
      "3040 [D loss: 0.084338]\n",
      "3041 [D loss: 0.085789]\n",
      "3042 [D loss: 0.075981]\n",
      "3043 [D loss: 0.082129]\n",
      "3044 [D loss: 0.083791]\n",
      "3045 [D loss: 0.078688]\n",
      "3046 [D loss: 0.079918]\n",
      "3047 [D loss: 0.084806]\n",
      "3048 [D loss: 0.092080]\n",
      "3049 [D loss: 0.081609]\n",
      "3050 [D loss: 0.078139]\n",
      "3051 [D loss: 0.084991]\n",
      "3052 [D loss: 0.076580]\n",
      "3053 [D loss: 0.077723]\n",
      "3054 [D loss: 0.076287]\n",
      "3055 [D loss: 0.085512]\n",
      "3056 [D loss: 0.081566]\n",
      "3057 [D loss: 0.081801]\n",
      "3058 [D loss: 0.085449]\n",
      "3059 [D loss: 0.100052]\n",
      "3060 [D loss: 0.082515]\n",
      "3061 [D loss: 0.082524]\n",
      "3062 [D loss: 0.074328]\n",
      "3063 [D loss: 0.084912]\n",
      "3064 [D loss: 0.079538]\n",
      "3065 [D loss: 0.075014]\n",
      "3066 [D loss: 0.093694]\n",
      "3067 [D loss: 0.087555]\n",
      "3068 [D loss: 0.084879]\n",
      "3069 [D loss: 0.076095]\n",
      "3070 [D loss: 0.086526]\n",
      "3071 [D loss: 0.073447]\n",
      "3072 [D loss: 0.076050]\n",
      "3073 [D loss: 0.083584]\n",
      "3074 [D loss: 0.075516]\n",
      "3075 [D loss: 0.074000]\n",
      "3076 [D loss: 0.079131]\n",
      "3077 [D loss: 0.074988]\n",
      "3078 [D loss: 0.074136]\n",
      "3079 [D loss: 0.083177]\n",
      "3080 [D loss: 0.077591]\n",
      "3081 [D loss: 0.069285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3082 [D loss: 0.075813]\n",
      "3083 [D loss: 0.076121]\n",
      "3084 [D loss: 0.081430]\n",
      "3085 [D loss: 0.086103]\n",
      "3086 [D loss: 0.083156]\n",
      "3087 [D loss: 0.073696]\n",
      "3088 [D loss: 0.077320]\n",
      "3089 [D loss: 0.071791]\n",
      "3090 [D loss: 0.087245]\n",
      "3091 [D loss: 0.094174]\n",
      "3092 [D loss: 0.085636]\n",
      "3093 [D loss: 0.078124]\n",
      "3094 [D loss: 0.071504]\n",
      "3095 [D loss: 0.087078]\n",
      "3096 [D loss: 0.089222]\n",
      "3097 [D loss: 0.074176]\n",
      "3098 [D loss: 0.075070]\n",
      "3099 [D loss: 0.077217]\n",
      "3100 [D loss: 0.072647]\n",
      "3101 [D loss: 0.083948]\n",
      "3102 [D loss: 0.075948]\n",
      "3103 [D loss: 0.074642]\n",
      "3104 [D loss: 0.087164]\n",
      "3105 [D loss: 0.071938]\n",
      "3106 [D loss: 0.073475]\n",
      "3107 [D loss: 0.077331]\n",
      "3108 [D loss: 0.078782]\n",
      "3109 [D loss: 0.074335]\n",
      "3110 [D loss: 0.083174]\n",
      "3111 [D loss: 0.089078]\n",
      "3112 [D loss: 0.080669]\n",
      "3113 [D loss: 0.086186]\n",
      "3114 [D loss: 0.073823]\n",
      "3115 [D loss: 0.074039]\n",
      "3116 [D loss: 0.071380]\n",
      "3117 [D loss: 0.074647]\n",
      "3118 [D loss: 0.077565]\n",
      "3119 [D loss: 0.076694]\n",
      "3120 [D loss: 0.076804]\n",
      "3121 [D loss: 0.070010]\n",
      "3122 [D loss: 0.076723]\n",
      "3123 [D loss: 0.080635]\n",
      "3124 [D loss: 0.072003]\n",
      "3125 [D loss: 0.079501]\n",
      "3126 [D loss: 0.080714]\n",
      "3127 [D loss: 0.074092]\n",
      "3128 [D loss: 0.081974]\n",
      "3129 [D loss: 0.082100]\n",
      "3130 [D loss: 0.092183]\n",
      "3131 [D loss: 0.079594]\n",
      "3132 [D loss: 0.077129]\n",
      "3133 [D loss: 0.073902]\n",
      "3134 [D loss: 0.075412]\n",
      "3135 [D loss: 0.094006]\n",
      "3136 [D loss: 0.075401]\n",
      "3137 [D loss: 0.071234]\n",
      "3138 [D loss: 0.073848]\n",
      "3139 [D loss: 0.079940]\n",
      "3140 [D loss: 0.078441]\n",
      "3141 [D loss: 0.078053]\n",
      "3142 [D loss: 0.088949]\n",
      "3143 [D loss: 0.072186]\n",
      "3144 [D loss: 0.082011]\n",
      "3145 [D loss: 0.094219]\n",
      "3146 [D loss: 0.073224]\n",
      "3147 [D loss: 0.083057]\n",
      "3148 [D loss: 0.088701]\n",
      "3149 [D loss: 0.074535]\n",
      "3150 [D loss: 0.073534]\n",
      "3151 [D loss: 0.081275]\n",
      "3152 [D loss: 0.078101]\n",
      "3153 [D loss: 0.082690]\n",
      "3154 [D loss: 0.085021]\n",
      "3155 [D loss: 0.079087]\n",
      "3156 [D loss: 0.084626]\n",
      "3157 [D loss: 0.071745]\n",
      "3158 [D loss: 0.074013]\n",
      "3159 [D loss: 0.075953]\n",
      "3160 [D loss: 0.093343]\n",
      "3161 [D loss: 0.079046]\n",
      "3162 [D loss: 0.077684]\n",
      "3163 [D loss: 0.079716]\n",
      "3164 [D loss: 0.072589]\n",
      "3165 [D loss: 0.078044]\n",
      "3166 [D loss: 0.105283]\n",
      "3167 [D loss: 0.080219]\n",
      "3168 [D loss: 0.074314]\n",
      "3169 [D loss: 0.075419]\n",
      "3170 [D loss: 0.078322]\n",
      "3171 [D loss: 0.078393]\n",
      "3172 [D loss: 0.075664]\n",
      "3173 [D loss: 0.083639]\n",
      "3174 [D loss: 0.079277]\n",
      "3175 [D loss: 0.069975]\n",
      "3176 [D loss: 0.072987]\n",
      "3177 [D loss: 0.079929]\n",
      "3178 [D loss: 0.073768]\n",
      "3179 [D loss: 0.070656]\n",
      "3180 [D loss: 0.070835]\n",
      "3181 [D loss: 0.085252]\n",
      "3182 [D loss: 0.078033]\n",
      "3183 [D loss: 0.077568]\n",
      "3184 [D loss: 0.073536]\n",
      "3185 [D loss: 0.074530]\n",
      "3186 [D loss: 0.073693]\n",
      "3187 [D loss: 0.091024]\n",
      "3188 [D loss: 0.086837]\n",
      "3189 [D loss: 0.073873]\n",
      "3190 [D loss: 0.089796]\n",
      "3191 [D loss: 0.073474]\n",
      "3192 [D loss: 0.088504]\n",
      "3193 [D loss: 0.074513]\n",
      "3194 [D loss: 0.080621]\n",
      "3195 [D loss: 0.077631]\n",
      "3196 [D loss: 0.077812]\n",
      "3197 [D loss: 0.075077]\n",
      "3198 [D loss: 0.077781]\n",
      "3199 [D loss: 0.081991]\n",
      "3200 [D loss: 0.077474]\n",
      "3201 [D loss: 0.076828]\n",
      "3202 [D loss: 0.069714]\n",
      "3203 [D loss: 0.143284]\n",
      "3204 [D loss: 0.073938]\n",
      "3205 [D loss: 0.069952]\n",
      "3206 [D loss: 0.071863]\n",
      "3207 [D loss: 0.078321]\n",
      "3208 [D loss: 0.082907]\n",
      "3209 [D loss: 0.073832]\n",
      "3210 [D loss: 0.073368]\n",
      "3211 [D loss: 0.068041]\n",
      "3212 [D loss: 0.085550]\n",
      "3213 [D loss: 0.082739]\n",
      "3214 [D loss: 0.077236]\n",
      "3215 [D loss: 0.080470]\n",
      "3216 [D loss: 0.077269]\n",
      "3217 [D loss: 0.088501]\n",
      "3218 [D loss: 0.073197]\n",
      "3219 [D loss: 0.089604]\n",
      "3220 [D loss: 0.078471]\n",
      "3221 [D loss: 0.075095]\n",
      "3222 [D loss: 0.069816]\n",
      "3223 [D loss: 0.077666]\n",
      "3224 [D loss: 0.074996]\n",
      "3225 [D loss: 0.091565]\n",
      "3226 [D loss: 0.085109]\n",
      "3227 [D loss: 0.072808]\n",
      "3228 [D loss: 0.084138]\n",
      "3229 [D loss: 0.070052]\n",
      "3230 [D loss: 0.072284]\n",
      "3231 [D loss: 0.083030]\n",
      "3232 [D loss: 0.073497]\n",
      "3233 [D loss: 0.076774]\n",
      "3234 [D loss: 0.081248]\n",
      "3235 [D loss: 0.079261]\n",
      "3236 [D loss: 0.068394]\n",
      "3237 [D loss: 0.075359]\n",
      "3238 [D loss: 0.092617]\n",
      "3239 [D loss: 0.073054]\n",
      "3240 [D loss: 0.081873]\n",
      "3241 [D loss: 0.073688]\n",
      "3242 [D loss: 0.103620]\n",
      "3243 [D loss: 0.087741]\n",
      "3244 [D loss: 0.076221]\n",
      "3245 [D loss: 0.076485]\n",
      "3246 [D loss: 0.104933]\n",
      "3247 [D loss: 0.074269]\n",
      "3248 [D loss: 0.081533]\n",
      "3249 [D loss: 0.082974]\n",
      "3250 [D loss: 0.083032]\n",
      "3251 [D loss: 0.074378]\n",
      "3252 [D loss: 0.070745]\n",
      "3253 [D loss: 0.071499]\n",
      "3254 [D loss: 0.071886]\n",
      "3255 [D loss: 0.082570]\n",
      "3256 [D loss: 0.068455]\n",
      "3257 [D loss: 0.082951]\n",
      "3258 [D loss: 0.084625]\n",
      "3259 [D loss: 0.075538]\n",
      "3260 [D loss: 0.078805]\n",
      "3261 [D loss: 0.085729]\n",
      "3262 [D loss: 0.072128]\n",
      "3263 [D loss: 0.070747]\n",
      "3264 [D loss: 0.075190]\n",
      "3265 [D loss: 0.078344]\n",
      "3266 [D loss: 0.073592]\n",
      "3267 [D loss: 0.076900]\n",
      "3268 [D loss: 0.074434]\n",
      "3269 [D loss: 0.086404]\n",
      "3270 [D loss: 0.081420]\n",
      "3271 [D loss: 0.074074]\n",
      "3272 [D loss: 0.071130]\n",
      "3273 [D loss: 0.073061]\n",
      "3274 [D loss: 0.077026]\n",
      "3275 [D loss: 0.071204]\n",
      "3276 [D loss: 0.083098]\n",
      "3277 [D loss: 0.070905]\n",
      "3278 [D loss: 0.081961]\n",
      "3279 [D loss: 0.072080]\n",
      "3280 [D loss: 0.074017]\n",
      "3281 [D loss: 0.070537]\n",
      "3282 [D loss: 0.078450]\n",
      "3283 [D loss: 0.079396]\n",
      "3284 [D loss: 0.079183]\n",
      "3285 [D loss: 0.078596]\n",
      "3286 [D loss: 0.068878]\n",
      "3287 [D loss: 0.071260]\n",
      "3288 [D loss: 0.072091]\n",
      "3289 [D loss: 0.068464]\n",
      "3290 [D loss: 0.067282]\n",
      "3291 [D loss: 0.076289]\n",
      "3292 [D loss: 0.063636]\n",
      "3293 [D loss: 0.069019]\n",
      "3294 [D loss: 0.071489]\n",
      "3295 [D loss: 0.072344]\n",
      "3296 [D loss: 0.070928]\n",
      "3297 [D loss: 0.085680]\n",
      "3298 [D loss: 0.088602]\n",
      "3299 [D loss: 0.068402]\n",
      "3300 [D loss: 0.065952]\n",
      "3301 [D loss: 0.075187]\n",
      "3302 [D loss: 0.083797]\n",
      "3303 [D loss: 0.080606]\n",
      "3304 [D loss: 0.077873]\n",
      "3305 [D loss: 0.076012]\n",
      "3306 [D loss: 0.091667]\n",
      "3307 [D loss: 0.078820]\n",
      "3308 [D loss: 0.074488]\n",
      "3309 [D loss: 0.072051]\n",
      "3310 [D loss: 0.078945]\n",
      "3311 [D loss: 0.110400]\n",
      "3312 [D loss: 0.078079]\n",
      "3313 [D loss: 0.070318]\n",
      "3314 [D loss: 0.080793]\n",
      "3315 [D loss: 0.091663]\n",
      "3316 [D loss: 0.067797]\n",
      "3317 [D loss: 0.072288]\n",
      "3318 [D loss: 0.070789]\n",
      "3319 [D loss: 0.071039]\n",
      "3320 [D loss: 0.088823]\n",
      "3321 [D loss: 0.082405]\n",
      "3322 [D loss: 0.078313]\n",
      "3323 [D loss: 0.070648]\n",
      "3324 [D loss: 0.065604]\n",
      "3325 [D loss: 0.070352]\n",
      "3326 [D loss: 0.066965]\n",
      "3327 [D loss: 0.089481]\n",
      "3328 [D loss: 0.142845]\n",
      "3329 [D loss: 0.066862]\n",
      "3330 [D loss: 0.070760]\n",
      "3331 [D loss: 0.071796]\n",
      "3332 [D loss: 0.067178]\n",
      "3333 [D loss: 0.073672]\n",
      "3334 [D loss: 0.074163]\n",
      "3335 [D loss: 0.076218]\n",
      "3336 [D loss: 0.070043]\n",
      "3337 [D loss: 0.070861]\n",
      "3338 [D loss: 0.105647]\n",
      "3339 [D loss: 0.069448]\n",
      "3340 [D loss: 0.110178]\n",
      "3341 [D loss: 0.068773]\n",
      "3342 [D loss: 0.068925]\n",
      "3343 [D loss: 0.076216]\n",
      "3344 [D loss: 0.069845]\n",
      "3345 [D loss: 0.072848]\n",
      "3346 [D loss: 0.075213]\n",
      "3347 [D loss: 0.084825]\n",
      "3348 [D loss: 0.075890]\n",
      "3349 [D loss: 0.078240]\n",
      "3350 [D loss: 0.088649]\n",
      "3351 [D loss: 0.075659]\n",
      "3352 [D loss: 0.071819]\n",
      "3353 [D loss: 0.076178]\n",
      "3354 [D loss: 0.078783]\n",
      "3355 [D loss: 0.073471]\n",
      "3356 [D loss: 0.067929]\n",
      "3357 [D loss: 0.076122]\n",
      "3358 [D loss: 0.075452]\n",
      "3359 [D loss: 0.083055]\n",
      "3360 [D loss: 0.070701]\n",
      "3361 [D loss: 0.072451]\n",
      "3362 [D loss: 0.077856]\n",
      "3363 [D loss: 0.068326]\n",
      "3364 [D loss: 0.078642]\n",
      "3365 [D loss: 0.064970]\n",
      "3366 [D loss: 0.079075]\n",
      "3367 [D loss: 0.078888]\n",
      "3368 [D loss: 0.088100]\n",
      "3369 [D loss: 0.068923]\n",
      "3370 [D loss: 0.078796]\n",
      "3371 [D loss: 0.074859]\n",
      "3372 [D loss: 0.071237]\n",
      "3373 [D loss: 0.078452]\n",
      "3374 [D loss: 0.076199]\n",
      "3375 [D loss: 0.079572]\n",
      "3376 [D loss: 0.072768]\n",
      "3377 [D loss: 0.070349]\n",
      "3378 [D loss: 0.072117]\n",
      "3379 [D loss: 0.074152]\n",
      "3380 [D loss: 0.071215]\n",
      "3381 [D loss: 0.080512]\n",
      "3382 [D loss: 0.074361]\n",
      "3383 [D loss: 0.068727]\n",
      "3384 [D loss: 0.075923]\n",
      "3385 [D loss: 0.068261]\n",
      "3386 [D loss: 0.076565]\n",
      "3387 [D loss: 0.073044]\n",
      "3388 [D loss: 0.066551]\n",
      "3389 [D loss: 0.073943]\n",
      "3390 [D loss: 0.071690]\n",
      "3391 [D loss: 0.088044]\n",
      "3392 [D loss: 0.070336]\n",
      "3393 [D loss: 0.077496]\n",
      "3394 [D loss: 0.075086]\n",
      "3395 [D loss: 0.073866]\n",
      "3396 [D loss: 0.075076]\n",
      "3397 [D loss: 0.066698]\n",
      "3398 [D loss: 0.092850]\n",
      "3399 [D loss: 0.069357]\n",
      "3400 [D loss: 0.069896]\n",
      "3401 [D loss: 0.071159]\n",
      "3402 [D loss: 0.079781]\n",
      "3403 [D loss: 0.070856]\n",
      "3404 [D loss: 0.074420]\n",
      "3405 [D loss: 0.069539]\n",
      "3406 [D loss: 0.065984]\n",
      "3407 [D loss: 0.068261]\n",
      "3408 [D loss: 0.076732]\n",
      "3409 [D loss: 0.068840]\n",
      "3410 [D loss: 0.068608]\n",
      "3411 [D loss: 0.065397]\n",
      "3412 [D loss: 0.081284]\n",
      "3413 [D loss: 0.084050]\n",
      "3414 [D loss: 0.064851]\n",
      "3415 [D loss: 0.077624]\n",
      "3416 [D loss: 0.069069]\n",
      "3417 [D loss: 0.073677]\n",
      "3418 [D loss: 0.070769]\n",
      "3419 [D loss: 0.074672]\n",
      "3420 [D loss: 0.074999]\n",
      "3421 [D loss: 0.071658]\n",
      "3422 [D loss: 0.069394]\n",
      "3423 [D loss: 0.069518]\n",
      "3424 [D loss: 0.086839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3425 [D loss: 0.067857]\n",
      "3426 [D loss: 0.068776]\n",
      "3427 [D loss: 0.089280]\n",
      "3428 [D loss: 0.073010]\n",
      "3429 [D loss: 0.070535]\n",
      "3430 [D loss: 0.072737]\n",
      "3431 [D loss: 0.076834]\n",
      "3432 [D loss: 0.082865]\n",
      "3433 [D loss: 0.076740]\n",
      "3434 [D loss: 0.066410]\n",
      "3435 [D loss: 0.074508]\n",
      "3436 [D loss: 0.075676]\n",
      "3437 [D loss: 0.076536]\n",
      "3438 [D loss: 0.064797]\n",
      "3439 [D loss: 0.073579]\n",
      "3440 [D loss: 0.077106]\n",
      "3441 [D loss: 0.067659]\n",
      "3442 [D loss: 0.088067]\n",
      "3443 [D loss: 0.068826]\n",
      "3444 [D loss: 0.075469]\n",
      "3445 [D loss: 0.071770]\n",
      "3446 [D loss: 0.065723]\n",
      "3447 [D loss: 0.067162]\n",
      "3448 [D loss: 0.070173]\n",
      "3449 [D loss: 0.069123]\n",
      "3450 [D loss: 0.066201]\n",
      "3451 [D loss: 0.069046]\n",
      "3452 [D loss: 0.068539]\n",
      "3453 [D loss: 0.067551]\n",
      "3454 [D loss: 0.072046]\n",
      "3455 [D loss: 0.075789]\n",
      "3456 [D loss: 0.081814]\n",
      "3457 [D loss: 0.068574]\n",
      "3458 [D loss: 0.074137]\n",
      "3459 [D loss: 0.063670]\n",
      "3460 [D loss: 0.066202]\n",
      "3461 [D loss: 0.071024]\n",
      "3462 [D loss: 0.070990]\n",
      "3463 [D loss: 0.070266]\n",
      "3464 [D loss: 0.066096]\n",
      "3465 [D loss: 0.073608]\n",
      "3466 [D loss: 0.066363]\n",
      "3467 [D loss: 0.071166]\n",
      "3468 [D loss: 0.064044]\n",
      "3469 [D loss: 0.091388]\n",
      "3470 [D loss: 0.066463]\n",
      "3471 [D loss: 0.069435]\n",
      "3472 [D loss: 0.075183]\n",
      "3473 [D loss: 0.082526]\n",
      "3474 [D loss: 0.060603]\n",
      "3475 [D loss: 0.069168]\n",
      "3476 [D loss: 0.075983]\n",
      "3477 [D loss: 0.067086]\n",
      "3478 [D loss: 0.067137]\n",
      "3479 [D loss: 0.073632]\n",
      "3480 [D loss: 0.080860]\n",
      "3481 [D loss: 0.074914]\n",
      "3482 [D loss: 0.072952]\n",
      "3483 [D loss: 0.064442]\n",
      "3484 [D loss: 0.086964]\n",
      "3485 [D loss: 0.082586]\n",
      "3486 [D loss: 0.062088]\n",
      "3487 [D loss: 0.074353]\n",
      "3488 [D loss: 0.074206]\n",
      "3489 [D loss: 0.067024]\n",
      "3490 [D loss: 0.072363]\n",
      "3491 [D loss: 0.066668]\n",
      "3492 [D loss: 0.086731]\n",
      "3493 [D loss: 0.066154]\n",
      "3494 [D loss: 0.068212]\n",
      "3495 [D loss: 0.081527]\n",
      "3496 [D loss: 0.067202]\n",
      "3497 [D loss: 0.081266]\n",
      "3498 [D loss: 0.066866]\n",
      "3499 [D loss: 0.071007]\n",
      "3500 [D loss: 0.087981]\n",
      "3501 [D loss: 0.071881]\n",
      "3502 [D loss: 0.063588]\n",
      "3503 [D loss: 0.067554]\n",
      "3504 [D loss: 0.063030]\n",
      "3505 [D loss: 0.087915]\n",
      "3506 [D loss: 0.076629]\n",
      "3507 [D loss: 0.067381]\n",
      "3508 [D loss: 0.071967]\n",
      "3509 [D loss: 0.067628]\n",
      "3510 [D loss: 0.062008]\n",
      "3511 [D loss: 0.063393]\n",
      "3512 [D loss: 0.066815]\n",
      "3513 [D loss: 0.078373]\n",
      "3514 [D loss: 0.070515]\n",
      "3515 [D loss: 0.079331]\n",
      "3516 [D loss: 0.075087]\n",
      "3517 [D loss: 0.064917]\n",
      "3518 [D loss: 0.072700]\n",
      "3519 [D loss: 0.070520]\n",
      "3520 [D loss: 0.086879]\n",
      "3521 [D loss: 0.066679]\n",
      "3522 [D loss: 0.069161]\n",
      "3523 [D loss: 0.062660]\n",
      "3524 [D loss: 0.066240]\n",
      "3525 [D loss: 0.070109]\n",
      "3526 [D loss: 0.069872]\n",
      "3527 [D loss: 0.068135]\n",
      "3528 [D loss: 0.080558]\n",
      "3529 [D loss: 0.066367]\n",
      "3530 [D loss: 0.066788]\n",
      "3531 [D loss: 0.067187]\n",
      "3532 [D loss: 0.075909]\n",
      "3533 [D loss: 0.063738]\n",
      "3534 [D loss: 0.066730]\n",
      "3535 [D loss: 0.075357]\n",
      "3536 [D loss: 0.069932]\n",
      "3537 [D loss: 0.074621]\n",
      "3538 [D loss: 0.083901]\n",
      "3539 [D loss: 0.068486]\n",
      "3540 [D loss: 0.064677]\n",
      "3541 [D loss: 0.068187]\n",
      "3542 [D loss: 0.063627]\n",
      "3543 [D loss: 0.066200]\n",
      "3544 [D loss: 0.079495]\n",
      "3545 [D loss: 0.069642]\n",
      "3546 [D loss: 0.068658]\n",
      "3547 [D loss: 0.075565]\n",
      "3548 [D loss: 0.060843]\n",
      "3549 [D loss: 0.065837]\n",
      "3550 [D loss: 0.070774]\n",
      "3551 [D loss: 0.076734]\n",
      "3552 [D loss: 0.074022]\n",
      "3553 [D loss: 0.070156]\n",
      "3554 [D loss: 0.071439]\n",
      "3555 [D loss: 0.064768]\n",
      "3556 [D loss: 0.065246]\n",
      "3557 [D loss: 0.062867]\n",
      "3558 [D loss: 0.061152]\n",
      "3559 [D loss: 0.069186]\n",
      "3560 [D loss: 0.076257]\n",
      "3561 [D loss: 0.067153]\n",
      "3562 [D loss: 0.066952]\n",
      "3563 [D loss: 0.071676]\n",
      "3564 [D loss: 0.062184]\n",
      "3565 [D loss: 0.062353]\n",
      "3566 [D loss: 0.060055]\n",
      "3567 [D loss: 0.076748]\n",
      "3568 [D loss: 0.064930]\n",
      "3569 [D loss: 0.065217]\n",
      "3570 [D loss: 0.068363]\n",
      "3571 [D loss: 0.072952]\n",
      "3572 [D loss: 0.074043]\n",
      "3573 [D loss: 0.070227]\n",
      "3574 [D loss: 0.061484]\n",
      "3575 [D loss: 0.084202]\n",
      "3576 [D loss: 0.064276]\n",
      "3577 [D loss: 0.071011]\n",
      "3578 [D loss: 0.067283]\n",
      "3579 [D loss: 0.065102]\n",
      "3580 [D loss: 0.066277]\n",
      "3581 [D loss: 0.068933]\n",
      "3582 [D loss: 0.081779]\n",
      "3583 [D loss: 0.073761]\n",
      "3584 [D loss: 0.080945]\n",
      "3585 [D loss: 0.063049]\n",
      "3586 [D loss: 0.070801]\n",
      "3587 [D loss: 0.072691]\n",
      "3588 [D loss: 0.064985]\n",
      "3589 [D loss: 0.070859]\n",
      "3590 [D loss: 0.068124]\n",
      "3591 [D loss: 0.068270]\n",
      "3592 [D loss: 0.075763]\n",
      "3593 [D loss: 0.065982]\n",
      "3594 [D loss: 0.071303]\n",
      "3595 [D loss: 0.064139]\n",
      "3596 [D loss: 0.073462]\n",
      "3597 [D loss: 0.062253]\n",
      "3598 [D loss: 0.074692]\n",
      "3599 [D loss: 0.067222]\n",
      "3600 [D loss: 0.063758]\n",
      "3601 [D loss: 0.080815]\n",
      "3602 [D loss: 0.077687]\n",
      "3603 [D loss: 0.069980]\n",
      "3604 [D loss: 0.074183]\n",
      "3605 [D loss: 0.063725]\n",
      "3606 [D loss: 0.065552]\n",
      "3607 [D loss: 0.062772]\n",
      "3608 [D loss: 0.064207]\n",
      "3609 [D loss: 0.067689]\n",
      "3610 [D loss: 0.067576]\n",
      "3611 [D loss: 0.072573]\n",
      "3612 [D loss: 0.079412]\n",
      "3613 [D loss: 0.068108]\n",
      "3614 [D loss: 0.064411]\n",
      "3615 [D loss: 0.063100]\n",
      "3616 [D loss: 0.061742]\n",
      "3617 [D loss: 0.064285]\n",
      "3618 [D loss: 0.139448]\n",
      "3619 [D loss: 0.070115]\n",
      "3620 [D loss: 0.072602]\n",
      "3621 [D loss: 0.066108]\n",
      "3622 [D loss: 0.061630]\n",
      "3623 [D loss: 0.068624]\n",
      "3624 [D loss: 0.072090]\n",
      "3625 [D loss: 0.063113]\n",
      "3626 [D loss: 0.065462]\n",
      "3627 [D loss: 0.076842]\n",
      "3628 [D loss: 0.066203]\n",
      "3629 [D loss: 0.072660]\n",
      "3630 [D loss: 0.061945]\n",
      "3631 [D loss: 0.072981]\n",
      "3632 [D loss: 0.065678]\n",
      "3633 [D loss: 0.066650]\n",
      "3634 [D loss: 0.070903]\n",
      "3635 [D loss: 0.080505]\n",
      "3636 [D loss: 0.066188]\n",
      "3637 [D loss: 0.066331]\n",
      "3638 [D loss: 0.078800]\n",
      "3639 [D loss: 0.065720]\n",
      "3640 [D loss: 0.067084]\n",
      "3641 [D loss: 0.062751]\n",
      "3642 [D loss: 0.080520]\n",
      "3643 [D loss: 0.069674]\n",
      "3644 [D loss: 0.071847]\n",
      "3645 [D loss: 0.061947]\n",
      "3646 [D loss: 0.064608]\n",
      "3647 [D loss: 0.076998]\n",
      "3648 [D loss: 0.071475]\n",
      "3649 [D loss: 0.064397]\n",
      "3650 [D loss: 0.083708]\n",
      "3651 [D loss: 0.070673]\n",
      "3652 [D loss: 0.067204]\n",
      "3653 [D loss: 0.078784]\n",
      "3654 [D loss: 0.068499]\n",
      "3655 [D loss: 0.065099]\n",
      "3656 [D loss: 0.084131]\n",
      "3657 [D loss: 0.067561]\n",
      "3658 [D loss: 0.066186]\n",
      "3659 [D loss: 0.075711]\n",
      "3660 [D loss: 0.072103]\n",
      "3661 [D loss: 0.062143]\n",
      "3662 [D loss: 0.063522]\n",
      "3663 [D loss: 0.062893]\n",
      "3664 [D loss: 0.069962]\n",
      "3665 [D loss: 0.067129]\n",
      "3666 [D loss: 0.071634]\n",
      "3667 [D loss: 0.071940]\n",
      "3668 [D loss: 0.069792]\n",
      "3669 [D loss: 0.076802]\n",
      "3670 [D loss: 0.061100]\n",
      "3671 [D loss: 0.061715]\n",
      "3672 [D loss: 0.065852]\n",
      "3673 [D loss: 0.063987]\n",
      "3674 [D loss: 0.080604]\n",
      "3675 [D loss: 0.068928]\n",
      "3676 [D loss: 0.077409]\n",
      "3677 [D loss: 0.067374]\n",
      "3678 [D loss: 0.065177]\n",
      "3679 [D loss: 0.074066]\n",
      "3680 [D loss: 0.061953]\n",
      "3681 [D loss: 0.070756]\n",
      "3682 [D loss: 0.061983]\n",
      "3683 [D loss: 0.067128]\n",
      "3684 [D loss: 0.060494]\n",
      "3685 [D loss: 0.064717]\n",
      "3686 [D loss: 0.078074]\n",
      "3687 [D loss: 0.076084]\n",
      "3688 [D loss: 0.068108]\n",
      "3689 [D loss: 0.080623]\n",
      "3690 [D loss: 0.065784]\n",
      "3691 [D loss: 0.078140]\n",
      "3692 [D loss: 0.070743]\n",
      "3693 [D loss: 0.078295]\n",
      "3694 [D loss: 0.062871]\n",
      "3695 [D loss: 0.062820]\n",
      "3696 [D loss: 0.073989]\n",
      "3697 [D loss: 0.066167]\n",
      "3698 [D loss: 0.062875]\n",
      "3699 [D loss: 0.069303]\n",
      "3700 [D loss: 0.067062]\n",
      "3701 [D loss: 0.060289]\n",
      "3702 [D loss: 0.064002]\n",
      "3703 [D loss: 0.071729]\n",
      "3704 [D loss: 0.061666]\n",
      "3705 [D loss: 0.061367]\n",
      "3706 [D loss: 0.062640]\n",
      "3707 [D loss: 0.059274]\n",
      "3708 [D loss: 0.059684]\n",
      "3709 [D loss: 0.066842]\n",
      "3710 [D loss: 0.068525]\n",
      "3711 [D loss: 0.065925]\n",
      "3712 [D loss: 0.063148]\n",
      "3713 [D loss: 0.104179]\n",
      "3714 [D loss: 0.063249]\n",
      "3715 [D loss: 0.064425]\n",
      "3716 [D loss: 0.062767]\n",
      "3717 [D loss: 0.067140]\n",
      "3718 [D loss: 0.060828]\n",
      "3719 [D loss: 0.064192]\n",
      "3720 [D loss: 0.061362]\n",
      "3721 [D loss: 0.064401]\n",
      "3722 [D loss: 0.074965]\n",
      "3723 [D loss: 0.073138]\n",
      "3724 [D loss: 0.064440]\n",
      "3725 [D loss: 0.057860]\n",
      "3726 [D loss: 0.064552]\n",
      "3727 [D loss: 0.063334]\n",
      "3728 [D loss: 0.059401]\n",
      "3729 [D loss: 0.063254]\n",
      "3730 [D loss: 0.066353]\n",
      "3731 [D loss: 0.074170]\n",
      "3732 [D loss: 0.061785]\n",
      "3733 [D loss: 0.070735]\n",
      "3734 [D loss: 0.065579]\n",
      "3735 [D loss: 0.061976]\n",
      "3736 [D loss: 0.059317]\n",
      "3737 [D loss: 0.068579]\n",
      "3738 [D loss: 0.065019]\n",
      "3739 [D loss: 0.061084]\n",
      "3740 [D loss: 0.071520]\n",
      "3741 [D loss: 0.065335]\n",
      "3742 [D loss: 0.060037]\n",
      "3743 [D loss: 0.077884]\n",
      "3744 [D loss: 0.069119]\n",
      "3745 [D loss: 0.068634]\n",
      "3746 [D loss: 0.069089]\n",
      "3747 [D loss: 0.097428]\n",
      "3748 [D loss: 0.077973]\n",
      "3749 [D loss: 0.074886]\n",
      "3750 [D loss: 0.083701]\n",
      "3751 [D loss: 0.070884]\n",
      "3752 [D loss: 0.068139]\n",
      "3753 [D loss: 0.056132]\n",
      "3754 [D loss: 0.069722]\n",
      "3755 [D loss: 0.060424]\n",
      "3756 [D loss: 0.078427]\n",
      "3757 [D loss: 0.088440]\n",
      "3758 [D loss: 0.071530]\n",
      "3759 [D loss: 0.060107]\n",
      "3760 [D loss: 0.063800]\n",
      "3761 [D loss: 0.063070]\n",
      "3762 [D loss: 0.060141]\n",
      "3763 [D loss: 0.068848]\n",
      "3764 [D loss: 0.066680]\n",
      "3765 [D loss: 0.068763]\n",
      "3766 [D loss: 0.066905]\n",
      "3767 [D loss: 0.088279]\n",
      "3768 [D loss: 0.080517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3769 [D loss: 0.061372]\n",
      "3770 [D loss: 0.069626]\n",
      "3771 [D loss: 0.070463]\n",
      "3772 [D loss: 0.075045]\n",
      "3773 [D loss: 0.068924]\n",
      "3774 [D loss: 0.059648]\n",
      "3775 [D loss: 0.059809]\n",
      "3776 [D loss: 0.067094]\n",
      "3777 [D loss: 0.069309]\n",
      "3778 [D loss: 0.071714]\n",
      "3779 [D loss: 0.061105]\n",
      "3780 [D loss: 0.069299]\n",
      "3781 [D loss: 0.069466]\n",
      "3782 [D loss: 0.063277]\n",
      "3783 [D loss: 0.069674]\n",
      "3784 [D loss: 0.066097]\n",
      "3785 [D loss: 0.061351]\n",
      "3786 [D loss: 0.055794]\n",
      "3787 [D loss: 0.067854]\n",
      "3788 [D loss: 0.080144]\n",
      "3789 [D loss: 0.065080]\n",
      "3790 [D loss: 0.064857]\n",
      "3791 [D loss: 0.075425]\n",
      "3792 [D loss: 0.063513]\n",
      "3793 [D loss: 0.068430]\n",
      "3794 [D loss: 0.063267]\n",
      "3795 [D loss: 0.080427]\n",
      "3796 [D loss: 0.058870]\n",
      "3797 [D loss: 0.070705]\n",
      "3798 [D loss: 0.060380]\n",
      "3799 [D loss: 0.061332]\n",
      "3800 [D loss: 0.061034]\n",
      "3801 [D loss: 0.073192]\n",
      "3802 [D loss: 0.058497]\n",
      "3803 [D loss: 0.067975]\n",
      "3804 [D loss: 0.070438]\n",
      "3805 [D loss: 0.065465]\n",
      "3806 [D loss: 0.063098]\n",
      "3807 [D loss: 0.060914]\n",
      "3808 [D loss: 0.074345]\n",
      "3809 [D loss: 0.064475]\n",
      "3810 [D loss: 0.068593]\n",
      "3811 [D loss: 0.063191]\n",
      "3812 [D loss: 0.058279]\n",
      "3813 [D loss: 0.072660]\n",
      "3814 [D loss: 0.063824]\n",
      "3815 [D loss: 0.071942]\n",
      "3816 [D loss: 0.072239]\n",
      "3817 [D loss: 0.075899]\n",
      "3818 [D loss: 0.059794]\n",
      "3819 [D loss: 0.068509]\n",
      "3820 [D loss: 0.070890]\n",
      "3821 [D loss: 0.064500]\n",
      "3822 [D loss: 0.060142]\n",
      "3823 [D loss: 0.061659]\n",
      "3824 [D loss: 0.059306]\n",
      "3825 [D loss: 0.071439]\n",
      "3826 [D loss: 0.066205]\n",
      "3827 [D loss: 0.066969]\n",
      "3828 [D loss: 0.058986]\n",
      "3829 [D loss: 0.068364]\n",
      "3830 [D loss: 0.067528]\n",
      "3831 [D loss: 0.063510]\n",
      "3832 [D loss: 0.069135]\n",
      "3833 [D loss: 0.151056]\n",
      "3834 [D loss: 0.089081]\n",
      "3835 [D loss: 0.061813]\n",
      "3836 [D loss: 0.070073]\n",
      "3837 [D loss: 0.071268]\n",
      "3838 [D loss: 0.068598]\n",
      "3839 [D loss: 0.076539]\n",
      "3840 [D loss: 0.061384]\n",
      "3841 [D loss: 0.071741]\n",
      "3842 [D loss: 0.112688]\n",
      "3843 [D loss: 0.058179]\n",
      "3844 [D loss: 0.072118]\n",
      "3845 [D loss: 0.062800]\n",
      "3846 [D loss: 0.063644]\n",
      "3847 [D loss: 0.061166]\n",
      "3848 [D loss: 0.070558]\n",
      "3849 [D loss: 0.072033]\n",
      "3850 [D loss: 0.060925]\n",
      "3851 [D loss: 0.062479]\n",
      "3852 [D loss: 0.069425]\n",
      "3853 [D loss: 0.057993]\n",
      "3854 [D loss: 0.062417]\n",
      "3855 [D loss: 0.059208]\n",
      "3856 [D loss: 0.060195]\n",
      "3857 [D loss: 0.061839]\n",
      "3858 [D loss: 0.080596]\n",
      "3859 [D loss: 0.063157]\n",
      "3860 [D loss: 0.063471]\n",
      "3861 [D loss: 0.077802]\n",
      "3862 [D loss: 0.064662]\n",
      "3863 [D loss: 0.059716]\n",
      "3864 [D loss: 0.058044]\n",
      "3865 [D loss: 0.073227]\n",
      "3866 [D loss: 0.063862]\n",
      "3867 [D loss: 0.070293]\n",
      "3868 [D loss: 0.058473]\n",
      "3869 [D loss: 0.064780]\n",
      "3870 [D loss: 0.068422]\n",
      "3871 [D loss: 0.059052]\n",
      "3872 [D loss: 0.062185]\n",
      "3873 [D loss: 0.057507]\n",
      "3874 [D loss: 0.068513]\n",
      "3875 [D loss: 0.065323]\n",
      "3876 [D loss: 0.082069]\n",
      "3877 [D loss: 0.059587]\n",
      "3878 [D loss: 0.060965]\n",
      "3879 [D loss: 0.061632]\n",
      "3880 [D loss: 0.070825]\n",
      "3881 [D loss: 0.062947]\n",
      "3882 [D loss: 0.062195]\n",
      "3883 [D loss: 0.062547]\n",
      "3884 [D loss: 0.076147]\n",
      "3885 [D loss: 0.061001]\n",
      "3886 [D loss: 0.096427]\n",
      "3887 [D loss: 0.064377]\n",
      "3888 [D loss: 0.066487]\n",
      "3889 [D loss: 0.069999]\n",
      "3890 [D loss: 0.064381]\n",
      "3891 [D loss: 0.064579]\n",
      "3892 [D loss: 0.062828]\n",
      "3893 [D loss: 0.058027]\n",
      "3894 [D loss: 0.060288]\n",
      "3895 [D loss: 0.064240]\n",
      "3896 [D loss: 0.066080]\n",
      "3897 [D loss: 0.075483]\n",
      "3898 [D loss: 0.066421]\n",
      "3899 [D loss: 0.068161]\n",
      "3900 [D loss: 0.059333]\n",
      "3901 [D loss: 0.062162]\n",
      "3902 [D loss: 0.061749]\n",
      "3903 [D loss: 0.063661]\n",
      "3904 [D loss: 0.069683]\n",
      "3905 [D loss: 0.061701]\n",
      "3906 [D loss: 0.059803]\n",
      "3907 [D loss: 0.056788]\n",
      "3908 [D loss: 0.061225]\n",
      "3909 [D loss: 0.057565]\n",
      "3910 [D loss: 0.071170]\n",
      "3911 [D loss: 0.057328]\n",
      "3912 [D loss: 0.061429]\n",
      "3913 [D loss: 0.065727]\n",
      "3914 [D loss: 0.057243]\n",
      "3915 [D loss: 0.061644]\n",
      "3916 [D loss: 0.063141]\n",
      "3917 [D loss: 0.066138]\n",
      "3918 [D loss: 0.068813]\n",
      "3919 [D loss: 0.067008]\n",
      "3920 [D loss: 0.068071]\n",
      "3921 [D loss: 0.064083]\n",
      "3922 [D loss: 0.091596]\n",
      "3923 [D loss: 0.058153]\n",
      "3924 [D loss: 0.069392]\n",
      "3925 [D loss: 0.062268]\n",
      "3926 [D loss: 0.060712]\n",
      "3927 [D loss: 0.058812]\n",
      "3928 [D loss: 0.056908]\n",
      "3929 [D loss: 0.063882]\n",
      "3930 [D loss: 0.057588]\n",
      "3931 [D loss: 0.055259]\n",
      "3932 [D loss: 0.059220]\n",
      "3933 [D loss: 0.062626]\n",
      "3934 [D loss: 0.060635]\n",
      "3935 [D loss: 0.054405]\n",
      "3936 [D loss: 0.061960]\n",
      "3937 [D loss: 0.065236]\n",
      "3938 [D loss: 0.060379]\n",
      "3939 [D loss: 0.061509]\n",
      "3940 [D loss: 0.066098]\n",
      "3941 [D loss: 0.060054]\n",
      "3942 [D loss: 0.056214]\n",
      "3943 [D loss: 0.064850]\n",
      "3944 [D loss: 0.073842]\n",
      "3945 [D loss: 0.062527]\n",
      "3946 [D loss: 0.069087]\n",
      "3947 [D loss: 0.063215]\n",
      "3948 [D loss: 0.063986]\n",
      "3949 [D loss: 0.071559]\n",
      "3950 [D loss: 0.063259]\n",
      "3951 [D loss: 0.066695]\n",
      "3952 [D loss: 0.066726]\n",
      "3953 [D loss: 0.065411]\n",
      "3954 [D loss: 0.057385]\n",
      "3955 [D loss: 0.068937]\n",
      "3956 [D loss: 0.061083]\n",
      "3957 [D loss: 0.060383]\n",
      "3958 [D loss: 0.068594]\n",
      "3959 [D loss: 0.063401]\n",
      "3960 [D loss: 0.068992]\n",
      "3961 [D loss: 0.055543]\n",
      "3962 [D loss: 0.063340]\n",
      "3963 [D loss: 0.061093]\n",
      "3964 [D loss: 0.059020]\n",
      "3965 [D loss: 0.053679]\n",
      "3966 [D loss: 0.060292]\n",
      "3967 [D loss: 0.064981]\n",
      "3968 [D loss: 0.059642]\n",
      "3969 [D loss: 0.054565]\n",
      "3970 [D loss: 0.056830]\n",
      "3971 [D loss: 0.067085]\n",
      "3972 [D loss: 0.071181]\n",
      "3973 [D loss: 0.056737]\n",
      "3974 [D loss: 0.058509]\n",
      "3975 [D loss: 0.067406]\n",
      "3976 [D loss: 0.076109]\n",
      "3977 [D loss: 0.058651]\n",
      "3978 [D loss: 0.054490]\n",
      "3979 [D loss: 0.070911]\n",
      "3980 [D loss: 0.057192]\n",
      "3981 [D loss: 0.061030]\n",
      "3982 [D loss: 0.063849]\n",
      "3983 [D loss: 0.063435]\n",
      "3984 [D loss: 0.069967]\n",
      "3985 [D loss: 0.062884]\n",
      "3986 [D loss: 0.073642]\n",
      "3987 [D loss: 0.074895]\n",
      "3988 [D loss: 0.057090]\n",
      "3989 [D loss: 0.070130]\n",
      "3990 [D loss: 0.057707]\n",
      "3991 [D loss: 0.056395]\n",
      "3992 [D loss: 0.072812]\n",
      "3993 [D loss: 0.066063]\n",
      "3994 [D loss: 0.060452]\n",
      "3995 [D loss: 0.070042]\n",
      "3996 [D loss: 0.088533]\n",
      "3997 [D loss: 0.056596]\n",
      "3998 [D loss: 0.060861]\n",
      "3999 [D loss: 0.060783]\n",
      "4000 [D loss: 0.055129]\n",
      "4001 [D loss: 0.066622]\n",
      "4002 [D loss: 0.070270]\n",
      "4003 [D loss: 0.056818]\n",
      "4004 [D loss: 0.060882]\n",
      "4005 [D loss: 0.059837]\n",
      "4006 [D loss: 0.056530]\n",
      "4007 [D loss: 0.073034]\n",
      "4008 [D loss: 0.057419]\n",
      "4009 [D loss: 0.055659]\n",
      "4010 [D loss: 0.060364]\n",
      "4011 [D loss: 0.066018]\n",
      "4012 [D loss: 0.059828]\n",
      "4013 [D loss: 0.060533]\n",
      "4014 [D loss: 0.056267]\n",
      "4015 [D loss: 0.055042]\n",
      "4016 [D loss: 0.054805]\n",
      "4017 [D loss: 0.065548]\n",
      "4018 [D loss: 0.059541]\n",
      "4019 [D loss: 0.060283]\n",
      "4020 [D loss: 0.060558]\n",
      "4021 [D loss: 0.059283]\n",
      "4022 [D loss: 0.061521]\n",
      "4023 [D loss: 0.075938]\n",
      "4024 [D loss: 0.055294]\n",
      "4025 [D loss: 0.063862]\n",
      "4026 [D loss: 0.056001]\n",
      "4027 [D loss: 0.060388]\n",
      "4028 [D loss: 0.061657]\n",
      "4029 [D loss: 0.061058]\n",
      "4030 [D loss: 0.071412]\n",
      "4031 [D loss: 0.065761]\n",
      "4032 [D loss: 0.069151]\n",
      "4033 [D loss: 0.059350]\n",
      "4034 [D loss: 0.064203]\n",
      "4035 [D loss: 0.065411]\n",
      "4036 [D loss: 0.061132]\n",
      "4037 [D loss: 0.055979]\n",
      "4038 [D loss: 0.064845]\n",
      "4039 [D loss: 0.061987]\n",
      "4040 [D loss: 0.058403]\n",
      "4041 [D loss: 0.056996]\n",
      "4042 [D loss: 0.061663]\n",
      "4043 [D loss: 0.054863]\n",
      "4044 [D loss: 0.055849]\n",
      "4045 [D loss: 0.058851]\n",
      "4046 [D loss: 0.058537]\n",
      "4047 [D loss: 0.058020]\n",
      "4048 [D loss: 0.068148]\n",
      "4049 [D loss: 0.057016]\n",
      "4050 [D loss: 0.070880]\n",
      "4051 [D loss: 0.070256]\n",
      "4052 [D loss: 0.057309]\n",
      "4053 [D loss: 0.060935]\n",
      "4054 [D loss: 0.058100]\n",
      "4055 [D loss: 0.088640]\n",
      "4056 [D loss: 0.060898]\n",
      "4057 [D loss: 0.070840]\n",
      "4058 [D loss: 0.062905]\n",
      "4059 [D loss: 0.053757]\n",
      "4060 [D loss: 0.058761]\n",
      "4061 [D loss: 0.060248]\n",
      "4062 [D loss: 0.060513]\n",
      "4063 [D loss: 0.052727]\n",
      "4064 [D loss: 0.057561]\n",
      "4065 [D loss: 0.068062]\n",
      "4066 [D loss: 0.060857]\n",
      "4067 [D loss: 0.069625]\n",
      "4068 [D loss: 0.057948]\n",
      "4069 [D loss: 0.057669]\n",
      "4070 [D loss: 0.074944]\n",
      "4071 [D loss: 0.070647]\n",
      "4072 [D loss: 0.066283]\n",
      "4073 [D loss: 0.060513]\n",
      "4074 [D loss: 0.072978]\n",
      "4075 [D loss: 0.060704]\n",
      "4076 [D loss: 0.072319]\n",
      "4077 [D loss: 0.061680]\n",
      "4078 [D loss: 0.054597]\n",
      "4079 [D loss: 0.066160]\n",
      "4080 [D loss: 0.064018]\n",
      "4081 [D loss: 0.068033]\n",
      "4082 [D loss: 0.074849]\n",
      "4083 [D loss: 0.066145]\n",
      "4084 [D loss: 0.060193]\n",
      "4085 [D loss: 0.063435]\n",
      "4086 [D loss: 0.066510]\n",
      "4087 [D loss: 0.053954]\n",
      "4088 [D loss: 0.061061]\n",
      "4089 [D loss: 0.056098]\n",
      "4090 [D loss: 0.057801]\n",
      "4091 [D loss: 0.050774]\n",
      "4092 [D loss: 0.058447]\n",
      "4093 [D loss: 0.056474]\n",
      "4094 [D loss: 0.073702]\n",
      "4095 [D loss: 0.064621]\n",
      "4096 [D loss: 0.058266]\n",
      "4097 [D loss: 0.067015]\n",
      "4098 [D loss: 0.056753]\n",
      "4099 [D loss: 0.063603]\n",
      "4100 [D loss: 0.063974]\n",
      "4101 [D loss: 0.055242]\n",
      "4102 [D loss: 0.063401]\n",
      "4103 [D loss: 0.059562]\n",
      "4104 [D loss: 0.056773]\n",
      "4105 [D loss: 0.063386]\n",
      "4106 [D loss: 0.059256]\n",
      "4107 [D loss: 0.072094]\n",
      "4108 [D loss: 0.059438]\n",
      "4109 [D loss: 0.058685]\n",
      "4110 [D loss: 0.056187]\n",
      "4111 [D loss: 0.056235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4112 [D loss: 0.059605]\n",
      "4113 [D loss: 0.056897]\n",
      "4114 [D loss: 0.068356]\n",
      "4115 [D loss: 0.062765]\n",
      "4116 [D loss: 0.064354]\n",
      "4117 [D loss: 0.058903]\n",
      "4118 [D loss: 0.066395]\n",
      "4119 [D loss: 0.059398]\n",
      "4120 [D loss: 0.066744]\n",
      "4121 [D loss: 0.075409]\n",
      "4122 [D loss: 0.058267]\n",
      "4123 [D loss: 0.057947]\n",
      "4124 [D loss: 0.056233]\n",
      "4125 [D loss: 0.170255]\n",
      "4126 [D loss: 0.061189]\n",
      "4127 [D loss: 0.059532]\n",
      "4128 [D loss: 0.064129]\n",
      "4129 [D loss: 0.060612]\n",
      "4130 [D loss: 0.073809]\n",
      "4131 [D loss: 0.062019]\n",
      "4132 [D loss: 0.053660]\n",
      "4133 [D loss: 0.055453]\n",
      "4134 [D loss: 0.058052]\n",
      "4135 [D loss: 0.058014]\n",
      "4136 [D loss: 0.052880]\n",
      "4137 [D loss: 0.083998]\n",
      "4138 [D loss: 0.054033]\n",
      "4139 [D loss: 0.052508]\n",
      "4140 [D loss: 0.069026]\n",
      "4141 [D loss: 0.066959]\n",
      "4142 [D loss: 0.072583]\n",
      "4143 [D loss: 0.057379]\n",
      "4144 [D loss: 0.052328]\n",
      "4145 [D loss: 0.055534]\n",
      "4146 [D loss: 0.063395]\n",
      "4147 [D loss: 0.057041]\n",
      "4148 [D loss: 0.059654]\n",
      "4149 [D loss: 0.055940]\n",
      "4150 [D loss: 0.054483]\n",
      "4151 [D loss: 0.053250]\n",
      "4152 [D loss: 0.060648]\n",
      "4153 [D loss: 0.069667]\n",
      "4154 [D loss: 0.053036]\n",
      "4155 [D loss: 0.059471]\n",
      "4156 [D loss: 0.053647]\n",
      "4157 [D loss: 0.066715]\n",
      "4158 [D loss: 0.057293]\n",
      "4159 [D loss: 0.055107]\n",
      "4160 [D loss: 0.058603]\n",
      "4161 [D loss: 0.095838]\n",
      "4162 [D loss: 0.053165]\n",
      "4163 [D loss: 0.062296]\n",
      "4164 [D loss: 0.071576]\n",
      "4165 [D loss: 0.052824]\n",
      "4166 [D loss: 0.062179]\n",
      "4167 [D loss: 0.060225]\n",
      "4168 [D loss: 0.071818]\n",
      "4169 [D loss: 0.077238]\n",
      "4170 [D loss: 0.056713]\n",
      "4171 [D loss: 0.068944]\n",
      "4172 [D loss: 0.072458]\n",
      "4173 [D loss: 0.055704]\n",
      "4174 [D loss: 0.053247]\n",
      "4175 [D loss: 0.058372]\n",
      "4176 [D loss: 0.063931]\n",
      "4177 [D loss: 0.060608]\n",
      "4178 [D loss: 0.054308]\n",
      "4179 [D loss: 0.058375]\n",
      "4180 [D loss: 0.057420]\n",
      "4181 [D loss: 0.063667]\n",
      "4182 [D loss: 0.056906]\n",
      "4183 [D loss: 0.057060]\n",
      "4184 [D loss: 0.065185]\n",
      "4185 [D loss: 0.055209]\n",
      "4186 [D loss: 0.066493]\n",
      "4187 [D loss: 0.056813]\n",
      "4188 [D loss: 0.054487]\n",
      "4189 [D loss: 0.062619]\n",
      "4190 [D loss: 0.058296]\n",
      "4191 [D loss: 0.052974]\n",
      "4192 [D loss: 0.054911]\n",
      "4193 [D loss: 0.059315]\n",
      "4194 [D loss: 0.055684]\n",
      "4195 [D loss: 0.069002]\n",
      "4196 [D loss: 0.055451]\n",
      "4197 [D loss: 0.054318]\n",
      "4198 [D loss: 0.065128]\n",
      "4199 [D loss: 0.058773]\n",
      "4200 [D loss: 0.062012]\n",
      "4201 [D loss: 0.053514]\n",
      "4202 [D loss: 0.064170]\n",
      "4203 [D loss: 0.052445]\n",
      "4204 [D loss: 0.060443]\n",
      "4205 [D loss: 0.083471]\n",
      "4206 [D loss: 0.060875]\n",
      "4207 [D loss: 0.069180]\n",
      "4208 [D loss: 0.057767]\n",
      "4209 [D loss: 0.061676]\n",
      "4210 [D loss: 0.061722]\n",
      "4211 [D loss: 0.059870]\n",
      "4212 [D loss: 0.059568]\n",
      "4213 [D loss: 0.071817]\n",
      "4214 [D loss: 0.059214]\n",
      "4215 [D loss: 0.061197]\n",
      "4216 [D loss: 0.059784]\n",
      "4217 [D loss: 0.069151]\n",
      "4218 [D loss: 0.058109]\n",
      "4219 [D loss: 0.063275]\n",
      "4220 [D loss: 0.065212]\n",
      "4221 [D loss: 0.055786]\n",
      "4222 [D loss: 0.058038]\n",
      "4223 [D loss: 0.070077]\n",
      "4224 [D loss: 0.061026]\n",
      "4225 [D loss: 0.068734]\n",
      "4226 [D loss: 0.058703]\n",
      "4227 [D loss: 0.057540]\n",
      "4228 [D loss: 0.052967]\n",
      "4229 [D loss: 0.068887]\n",
      "4230 [D loss: 0.056145]\n",
      "4231 [D loss: 0.055451]\n",
      "4232 [D loss: 0.055463]\n",
      "4233 [D loss: 0.054462]\n",
      "4234 [D loss: 0.051843]\n",
      "4235 [D loss: 0.059066]\n",
      "4236 [D loss: 0.064807]\n",
      "4237 [D loss: 0.057307]\n",
      "4238 [D loss: 0.065328]\n",
      "4239 [D loss: 0.054494]\n",
      "4240 [D loss: 0.067201]\n",
      "4241 [D loss: 0.058131]\n",
      "4242 [D loss: 0.053088]\n",
      "4243 [D loss: 0.060201]\n",
      "4244 [D loss: 0.057748]\n",
      "4245 [D loss: 0.063798]\n",
      "4246 [D loss: 0.070867]\n",
      "4247 [D loss: 0.053251]\n",
      "4248 [D loss: 0.059203]\n",
      "4249 [D loss: 0.055420]\n",
      "4250 [D loss: 0.059321]\n",
      "4251 [D loss: 0.060061]\n",
      "4252 [D loss: 0.059311]\n",
      "4253 [D loss: 0.054498]\n",
      "4254 [D loss: 0.061740]\n",
      "4255 [D loss: 0.059088]\n",
      "4256 [D loss: 0.052317]\n",
      "4257 [D loss: 0.060841]\n",
      "4258 [D loss: 0.057855]\n",
      "4259 [D loss: 0.064916]\n",
      "4260 [D loss: 0.061916]\n",
      "4261 [D loss: 0.057456]\n",
      "4262 [D loss: 0.064697]\n",
      "4263 [D loss: 0.058131]\n",
      "4264 [D loss: 0.062783]\n",
      "4265 [D loss: 0.048720]\n",
      "4266 [D loss: 0.060434]\n",
      "4267 [D loss: 0.056717]\n",
      "4268 [D loss: 0.060302]\n",
      "4269 [D loss: 0.061879]\n",
      "4270 [D loss: 0.052478]\n",
      "4271 [D loss: 0.059353]\n",
      "4272 [D loss: 0.064450]\n",
      "4273 [D loss: 0.056223]\n",
      "4274 [D loss: 0.062779]\n",
      "4275 [D loss: 0.061078]\n",
      "4276 [D loss: 0.054639]\n",
      "4277 [D loss: 0.059974]\n",
      "4278 [D loss: 0.054740]\n",
      "4279 [D loss: 0.060044]\n",
      "4280 [D loss: 0.055481]\n",
      "4281 [D loss: 0.055965]\n",
      "4282 [D loss: 0.075048]\n",
      "4283 [D loss: 0.055078]\n",
      "4284 [D loss: 0.056310]\n",
      "4285 [D loss: 0.065647]\n",
      "4286 [D loss: 0.071502]\n",
      "4287 [D loss: 0.069990]\n",
      "4288 [D loss: 0.054050]\n",
      "4289 [D loss: 0.058455]\n",
      "4290 [D loss: 0.054329]\n",
      "4291 [D loss: 0.059872]\n",
      "4292 [D loss: 0.057276]\n",
      "4293 [D loss: 0.061989]\n",
      "4294 [D loss: 0.062827]\n",
      "4295 [D loss: 0.055721]\n",
      "4296 [D loss: 0.059663]\n",
      "4297 [D loss: 0.076193]\n",
      "4298 [D loss: 0.063608]\n",
      "4299 [D loss: 0.061406]\n",
      "4300 [D loss: 0.062532]\n",
      "4301 [D loss: 0.058492]\n",
      "4302 [D loss: 0.053845]\n",
      "4303 [D loss: 0.062800]\n",
      "4304 [D loss: 0.063030]\n",
      "4305 [D loss: 0.065699]\n",
      "4306 [D loss: 0.056005]\n",
      "4307 [D loss: 0.053146]\n",
      "4308 [D loss: 0.063430]\n",
      "4309 [D loss: 0.056554]\n",
      "4310 [D loss: 0.057438]\n",
      "4311 [D loss: 0.064063]\n",
      "4312 [D loss: 0.058904]\n",
      "4313 [D loss: 0.060057]\n",
      "4314 [D loss: 0.056100]\n",
      "4315 [D loss: 0.071431]\n",
      "4316 [D loss: 0.057535]\n",
      "4317 [D loss: 0.053669]\n",
      "4318 [D loss: 0.053903]\n",
      "4319 [D loss: 0.066784]\n",
      "4320 [D loss: 0.051408]\n",
      "4321 [D loss: 0.056014]\n",
      "4322 [D loss: 0.055422]\n",
      "4323 [D loss: 0.058643]\n",
      "4324 [D loss: 0.094196]\n",
      "4325 [D loss: 0.072302]\n",
      "4326 [D loss: 0.059731]\n",
      "4327 [D loss: 0.073518]\n",
      "4328 [D loss: 0.066718]\n",
      "4329 [D loss: 0.058083]\n",
      "4330 [D loss: 0.064761]\n",
      "4331 [D loss: 0.057637]\n",
      "4332 [D loss: 0.052264]\n",
      "4333 [D loss: 0.053289]\n",
      "4334 [D loss: 0.057277]\n",
      "4335 [D loss: 0.055419]\n",
      "4336 [D loss: 0.057917]\n",
      "4337 [D loss: 0.058412]\n",
      "4338 [D loss: 0.057472]\n",
      "4339 [D loss: 0.052010]\n",
      "4340 [D loss: 0.061803]\n",
      "4341 [D loss: 0.053270]\n",
      "4342 [D loss: 0.070683]\n",
      "4343 [D loss: 0.057312]\n",
      "4344 [D loss: 0.063667]\n",
      "4345 [D loss: 0.058188]\n",
      "4346 [D loss: 0.060872]\n",
      "4347 [D loss: 0.055666]\n",
      "4348 [D loss: 0.054621]\n",
      "4349 [D loss: 0.051397]\n",
      "4350 [D loss: 0.058280]\n",
      "4351 [D loss: 0.055243]\n",
      "4352 [D loss: 0.061208]\n",
      "4353 [D loss: 0.051308]\n",
      "4354 [D loss: 0.056346]\n",
      "4355 [D loss: 0.078551]\n",
      "4356 [D loss: 0.055889]\n",
      "4357 [D loss: 0.065391]\n",
      "4358 [D loss: 0.074228]\n",
      "4359 [D loss: 0.057342]\n",
      "4360 [D loss: 0.062298]\n",
      "4361 [D loss: 0.066920]\n",
      "4362 [D loss: 0.056282]\n",
      "4363 [D loss: 0.056960]\n",
      "4364 [D loss: 0.053586]\n",
      "4365 [D loss: 0.060299]\n",
      "4366 [D loss: 0.058543]\n",
      "4367 [D loss: 0.061416]\n",
      "4368 [D loss: 0.062489]\n",
      "4369 [D loss: 0.058466]\n",
      "4370 [D loss: 0.061575]\n",
      "4371 [D loss: 0.050966]\n",
      "4372 [D loss: 0.057972]\n",
      "4373 [D loss: 0.054593]\n",
      "4374 [D loss: 0.078693]\n",
      "4375 [D loss: 0.068063]\n",
      "4376 [D loss: 0.053515]\n",
      "4377 [D loss: 0.063690]\n",
      "4378 [D loss: 0.050073]\n",
      "4379 [D loss: 0.052285]\n",
      "4380 [D loss: 0.060321]\n",
      "4381 [D loss: 0.063119]\n",
      "4382 [D loss: 0.059372]\n",
      "4383 [D loss: 0.054732]\n",
      "4384 [D loss: 0.050421]\n",
      "4385 [D loss: 0.057959]\n",
      "4386 [D loss: 0.049530]\n",
      "4387 [D loss: 0.057350]\n",
      "4388 [D loss: 0.051158]\n",
      "4389 [D loss: 0.056065]\n",
      "4390 [D loss: 0.052577]\n",
      "4391 [D loss: 0.058951]\n",
      "4392 [D loss: 0.057986]\n",
      "4393 [D loss: 0.062570]\n",
      "4394 [D loss: 0.062679]\n",
      "4395 [D loss: 0.057598]\n",
      "4396 [D loss: 0.051547]\n",
      "4397 [D loss: 0.063847]\n",
      "4398 [D loss: 0.054622]\n",
      "4399 [D loss: 0.066042]\n",
      "4400 [D loss: 0.060733]\n",
      "4401 [D loss: 0.062621]\n",
      "4402 [D loss: 0.050929]\n",
      "4403 [D loss: 0.061279]\n",
      "4404 [D loss: 0.078186]\n",
      "4405 [D loss: 0.051690]\n",
      "4406 [D loss: 0.060326]\n",
      "4407 [D loss: 0.054007]\n",
      "4408 [D loss: 0.062723]\n",
      "4409 [D loss: 0.048893]\n",
      "4410 [D loss: 0.053094]\n",
      "4411 [D loss: 0.058741]\n",
      "4412 [D loss: 0.054077]\n",
      "4413 [D loss: 0.053378]\n",
      "4414 [D loss: 0.049460]\n",
      "4415 [D loss: 0.056029]\n",
      "4416 [D loss: 0.054296]\n",
      "4417 [D loss: 0.054265]\n",
      "4418 [D loss: 0.048776]\n",
      "4419 [D loss: 0.056385]\n",
      "4420 [D loss: 0.056461]\n",
      "4421 [D loss: 0.061565]\n",
      "4422 [D loss: 0.060258]\n",
      "4423 [D loss: 0.056758]\n",
      "4424 [D loss: 0.068177]\n",
      "4425 [D loss: 0.049636]\n",
      "4426 [D loss: 0.057159]\n",
      "4427 [D loss: 0.056445]\n",
      "4428 [D loss: 0.056913]\n",
      "4429 [D loss: 0.058855]\n",
      "4430 [D loss: 0.055623]\n",
      "4431 [D loss: 0.064732]\n",
      "4432 [D loss: 0.063127]\n",
      "4433 [D loss: 0.052238]\n",
      "4434 [D loss: 0.055523]\n",
      "4435 [D loss: 0.066889]\n",
      "4436 [D loss: 0.051311]\n",
      "4437 [D loss: 0.050608]\n",
      "4438 [D loss: 0.078914]\n",
      "4439 [D loss: 0.057499]\n",
      "4440 [D loss: 0.058023]\n",
      "4441 [D loss: 0.067238]\n",
      "4442 [D loss: 0.052306]\n",
      "4443 [D loss: 0.063724]\n",
      "4444 [D loss: 0.054838]\n",
      "4445 [D loss: 0.052753]\n",
      "4446 [D loss: 0.054088]\n",
      "4447 [D loss: 0.056586]\n",
      "4448 [D loss: 0.061389]\n",
      "4449 [D loss: 0.053265]\n",
      "4450 [D loss: 0.051804]\n",
      "4451 [D loss: 0.052553]\n",
      "4452 [D loss: 0.064751]\n",
      "4453 [D loss: 0.113756]\n",
      "4454 [D loss: 0.051375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4455 [D loss: 0.050221]\n",
      "4456 [D loss: 0.057728]\n",
      "4457 [D loss: 0.051914]\n",
      "4458 [D loss: 0.070288]\n",
      "4459 [D loss: 0.054628]\n",
      "4460 [D loss: 0.049156]\n",
      "4461 [D loss: 0.050154]\n",
      "4462 [D loss: 0.054322]\n",
      "4463 [D loss: 0.056412]\n",
      "4464 [D loss: 0.054834]\n",
      "4465 [D loss: 0.064015]\n",
      "4466 [D loss: 0.055726]\n",
      "4467 [D loss: 0.049288]\n",
      "4468 [D loss: 0.051707]\n",
      "4469 [D loss: 0.050139]\n",
      "4470 [D loss: 0.053871]\n",
      "4471 [D loss: 0.049876]\n",
      "4472 [D loss: 0.050911]\n",
      "4473 [D loss: 0.049165]\n",
      "4474 [D loss: 0.056839]\n",
      "4475 [D loss: 0.065285]\n",
      "4476 [D loss: 0.055012]\n",
      "4477 [D loss: 0.054598]\n",
      "4478 [D loss: 0.051834]\n",
      "4479 [D loss: 0.052420]\n",
      "4480 [D loss: 0.055180]\n",
      "4481 [D loss: 0.054118]\n",
      "4482 [D loss: 0.055770]\n",
      "4483 [D loss: 0.059617]\n",
      "4484 [D loss: 0.056394]\n",
      "4485 [D loss: 0.058260]\n",
      "4486 [D loss: 0.055937]\n",
      "4487 [D loss: 0.060226]\n",
      "4488 [D loss: 0.064578]\n",
      "4489 [D loss: 0.063196]\n",
      "4490 [D loss: 0.052043]\n",
      "4491 [D loss: 0.051104]\n",
      "4492 [D loss: 0.051533]\n",
      "4493 [D loss: 0.049383]\n",
      "4494 [D loss: 0.067831]\n",
      "4495 [D loss: 0.058461]\n",
      "4496 [D loss: 0.061548]\n",
      "4497 [D loss: 0.051094]\n",
      "4498 [D loss: 0.050138]\n",
      "4499 [D loss: 0.061650]\n",
      "4500 [D loss: 0.057958]\n",
      "4501 [D loss: 0.051096]\n",
      "4502 [D loss: 0.067512]\n",
      "4503 [D loss: 0.057807]\n",
      "4504 [D loss: 0.060075]\n",
      "4505 [D loss: 0.061757]\n",
      "4506 [D loss: 0.060653]\n",
      "4507 [D loss: 0.074408]\n",
      "4508 [D loss: 0.057649]\n",
      "4509 [D loss: 0.053872]\n",
      "4510 [D loss: 0.051694]\n",
      "4511 [D loss: 0.053061]\n",
      "4512 [D loss: 0.068428]\n",
      "4513 [D loss: 0.052266]\n",
      "4514 [D loss: 0.051595]\n",
      "4515 [D loss: 0.063014]\n",
      "4516 [D loss: 0.065070]\n",
      "4517 [D loss: 0.052174]\n",
      "4518 [D loss: 0.065744]\n",
      "4519 [D loss: 0.052609]\n",
      "4520 [D loss: 0.057862]\n",
      "4521 [D loss: 0.067109]\n",
      "4522 [D loss: 0.053264]\n",
      "4523 [D loss: 0.062833]\n",
      "4524 [D loss: 0.061098]\n",
      "4525 [D loss: 0.052777]\n",
      "4526 [D loss: 0.054668]\n",
      "4527 [D loss: 0.055100]\n",
      "4528 [D loss: 0.056936]\n",
      "4529 [D loss: 0.065597]\n",
      "4530 [D loss: 0.057790]\n",
      "4531 [D loss: 0.111439]\n",
      "4532 [D loss: 0.062457]\n",
      "4533 [D loss: 0.049903]\n",
      "4534 [D loss: 0.057939]\n",
      "4535 [D loss: 0.066121]\n",
      "4536 [D loss: 0.050874]\n",
      "4537 [D loss: 0.054016]\n",
      "4538 [D loss: 0.063403]\n",
      "4539 [D loss: 0.048635]\n",
      "4540 [D loss: 0.056577]\n",
      "4541 [D loss: 0.052804]\n",
      "4542 [D loss: 0.055886]\n",
      "4543 [D loss: 0.050164]\n",
      "4544 [D loss: 0.050842]\n",
      "4545 [D loss: 0.050541]\n",
      "4546 [D loss: 0.047670]\n",
      "4547 [D loss: 0.055631]\n",
      "4548 [D loss: 0.058549]\n",
      "4549 [D loss: 0.054295]\n",
      "4550 [D loss: 0.074011]\n",
      "4551 [D loss: 0.055432]\n",
      "4552 [D loss: 0.055861]\n",
      "4553 [D loss: 0.051428]\n",
      "4554 [D loss: 0.060187]\n",
      "4555 [D loss: 0.056597]\n",
      "4556 [D loss: 0.069801]\n",
      "4557 [D loss: 0.056919]\n",
      "4558 [D loss: 0.055946]\n",
      "4559 [D loss: 0.052002]\n",
      "4560 [D loss: 0.051191]\n",
      "4561 [D loss: 0.053455]\n",
      "4562 [D loss: 0.062555]\n",
      "4563 [D loss: 0.057723]\n",
      "4564 [D loss: 0.058912]\n",
      "4565 [D loss: 0.053673]\n",
      "4566 [D loss: 0.054004]\n",
      "4567 [D loss: 0.053548]\n",
      "4568 [D loss: 0.056735]\n",
      "4569 [D loss: 0.050882]\n",
      "4570 [D loss: 0.053172]\n",
      "4571 [D loss: 0.066391]\n",
      "4572 [D loss: 0.058738]\n",
      "4573 [D loss: 0.055125]\n",
      "4574 [D loss: 0.051866]\n",
      "4575 [D loss: 0.061402]\n",
      "4576 [D loss: 0.054157]\n",
      "4577 [D loss: 0.057879]\n",
      "4578 [D loss: 0.053320]\n",
      "4579 [D loss: 0.053884]\n",
      "4580 [D loss: 0.056800]\n",
      "4581 [D loss: 0.053043]\n",
      "4582 [D loss: 0.053651]\n",
      "4583 [D loss: 0.056820]\n",
      "4584 [D loss: 0.049813]\n",
      "4585 [D loss: 0.062394]\n",
      "4586 [D loss: 0.048846]\n",
      "4587 [D loss: 0.050594]\n",
      "4588 [D loss: 0.063698]\n",
      "4589 [D loss: 0.052045]\n",
      "4590 [D loss: 0.056311]\n",
      "4591 [D loss: 0.051858]\n",
      "4592 [D loss: 0.051755]\n",
      "4593 [D loss: 0.054478]\n",
      "4594 [D loss: 0.055267]\n",
      "4595 [D loss: 0.051515]\n",
      "4596 [D loss: 0.055731]\n",
      "4597 [D loss: 0.049788]\n",
      "4598 [D loss: 0.048979]\n",
      "4599 [D loss: 0.056598]\n",
      "4600 [D loss: 0.070182]\n",
      "4601 [D loss: 0.070762]\n",
      "4602 [D loss: 0.052765]\n",
      "4603 [D loss: 0.054989]\n",
      "4604 [D loss: 0.059051]\n",
      "4605 [D loss: 0.068363]\n",
      "4606 [D loss: 0.060001]\n",
      "4607 [D loss: 0.047549]\n",
      "4608 [D loss: 0.056018]\n",
      "4609 [D loss: 0.056361]\n",
      "4610 [D loss: 0.053211]\n",
      "4611 [D loss: 0.049090]\n",
      "4612 [D loss: 0.050770]\n",
      "4613 [D loss: 0.054208]\n",
      "4614 [D loss: 0.055604]\n",
      "4615 [D loss: 0.050089]\n",
      "4616 [D loss: 0.062744]\n",
      "4617 [D loss: 0.055572]\n",
      "4618 [D loss: 0.061803]\n",
      "4619 [D loss: 0.055302]\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder():\n",
    "    \"\"\"An Autoencoder with deep fully-connected neural nets.\n",
    "\n",
    "    Training Data: MNIST Handwritten Digits (28x28 images)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.img_dim = self.img_rows * self.img_cols\n",
    "        self.latent_dim = 128 # The dimension of the data embedding\n",
    "\n",
    "        optimizer = Adam(learning_rate=0.0002, b1=0.5)\n",
    "        loss_function = SquareLoss\n",
    "\n",
    "        self.encoder = self.build_encoder(optimizer, loss_function)\n",
    "        self.decoder = self.build_decoder(optimizer, loss_function)\n",
    "\n",
    "        self.autoencoder = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n",
    "        self.autoencoder.layers.extend(self.encoder.layers)\n",
    "        self.autoencoder.layers.extend(self.decoder.layers)\n",
    "\n",
    "        print ()\n",
    "        self.autoencoder.summary(name=\"Variational Autoencoder\")\n",
    "\n",
    "    def build_encoder(self, optimizer, loss_function):\n",
    "\n",
    "        encoder = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n",
    "        encoder.add(Dense(512, input_shape=(self.img_dim,)))\n",
    "        encoder.add(Activation('leaky_relu'))\n",
    "        encoder.add(BatchNormalization(momentum=0.8))\n",
    "        encoder.add(Dense(256))\n",
    "        encoder.add(Activation('leaky_relu'))\n",
    "        encoder.add(BatchNormalization(momentum=0.8))\n",
    "        encoder.add(Dense(self.latent_dim))\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def build_decoder(self, optimizer, loss_function):\n",
    "\n",
    "        decoder = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n",
    "        decoder.add(Dense(256, input_shape=(self.latent_dim,)))\n",
    "        decoder.add(Activation('leaky_relu'))\n",
    "        decoder.add(BatchNormalization(momentum=0.8))\n",
    "        decoder.add(Dense(512))\n",
    "        decoder.add(Activation('leaky_relu'))\n",
    "        decoder.add(BatchNormalization(momentum=0.8))\n",
    "        decoder.add(Dense(self.img_dim))\n",
    "        decoder.add(Activation('tanh'))\n",
    "\n",
    "        return decoder\n",
    "\n",
    "    def train(self, n_epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        mnist = datasets.fetch_mldata('MNIST original')\n",
    "\n",
    "        X = mnist.data\n",
    "        y = mnist.target\n",
    "\n",
    "        # Rescale [-1, 1]\n",
    "        X = (X.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "            imgs = X[idx]\n",
    "\n",
    "            # Train the Autoencoder\n",
    "            loss, _ = self.autoencoder.train_on_batch(imgs, imgs)\n",
    "\n",
    "            # Display the progress\n",
    "            print (\"%d [D loss: %f]\" % (epoch, loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch, X)\n",
    "\n",
    "    def save_imgs(self, epoch, X):\n",
    "        r, c = 5, 5 # Grid size\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X.shape[0], r*c)\n",
    "        imgs = X[idx]\n",
    "        # Generate images and reshape to image shape\n",
    "        gen_imgs = self.autoencoder.predict(imgs).reshape((-1, self.img_rows, self.img_cols))\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        plt.suptitle(\"Autoencoder\")\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"ae_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ae = Autoencoder()\n",
    "    ae.train(n_epochs=200000, batch_size=64, save_interval=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
